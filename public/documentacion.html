<!DOCTYPE html>
<!-- saved from url=(0064)https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview -->
<html lang="en" class="light" style="color-scheme: light;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link rel="preload" href="https://deepwiki.com/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"><link rel="preload" href="https://deepwiki.com/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"><link rel="stylesheet" href="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/de70bee13400563f.css" data-precedence="next"><link rel="stylesheet" href="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/abd485da6d9b13f7.css" data-precedence="next"><link rel="preload" as="script" fetchpriority="low" href="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/webpack-acbbbb548492d4a6.js"><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/4bd1b696-cebf68b71ed1e85d.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/1684-3537a54455345a31.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/main-app-8ab5af3d6b81086e.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/b1298b8d-549c141f97a3b262.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/378e5a93-3b0f971d3611a8a5.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/f7f68e2d-40290491c524df5c.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/4420-863691215dce8f1b.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/6417-34cc3208366c5e5f.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/3224-7e9887ea92eab174.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/6967-c4b815e71e97ed18.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/4348-824485747071bae4.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/layout-7e3a468900582ca8.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/7bf36345-06f80506190927ed.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/c16f53c3-1a60b9b77b3e1d4b.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/2249-342d7235b3a68051.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/9970-31fea4ade6367f07.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/1769-6bbc7ae2dcadfa9c.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/655-b5574efc1f81bad2.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/4154-f7634cd651686b21.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/6835-f6c6803cb93f7a72.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/6638-d6e730ba183d02e2.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/4870-eef7f9c14ec0bbe8.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/page-dd78b4aea7a92e3b.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/3449-11980c1727988a9a.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/2307-135a4a3deb6dd18b.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/736-daf66278216745a2.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/layout-fdd52767083d8076.js" async=""></script><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/polyfills-42372ed130431b0a.js" nomodule=""></script><style type="text/css">[data-sonner-toaster][dir=ltr],html[dir=ltr]{--toast-icon-margin-start:-3px;--toast-icon-margin-end:4px;--toast-svg-margin-start:-1px;--toast-svg-margin-end:0px;--toast-button-margin-start:auto;--toast-button-margin-end:0;--toast-close-button-start:0;--toast-close-button-end:unset;--toast-close-button-transform:translate(-35%, -35%)}[data-sonner-toaster][dir=rtl],html[dir=rtl]{--toast-icon-margin-start:4px;--toast-icon-margin-end:-3px;--toast-svg-margin-start:0px;--toast-svg-margin-end:-1px;--toast-button-margin-start:0;--toast-button-margin-end:auto;--toast-close-button-start:unset;--toast-close-button-end:0;--toast-close-button-transform:translate(35%, -35%)}[data-sonner-toaster]{position:fixed;width:var(--width);font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;--gray1:hsl(0, 0%, 99%);--gray2:hsl(0, 0%, 97.3%);--gray3:hsl(0, 0%, 95.1%);--gray4:hsl(0, 0%, 93%);--gray5:hsl(0, 0%, 90.9%);--gray6:hsl(0, 0%, 88.7%);--gray7:hsl(0, 0%, 85.8%);--gray8:hsl(0, 0%, 78%);--gray9:hsl(0, 0%, 56.1%);--gray10:hsl(0, 0%, 52.3%);--gray11:hsl(0, 0%, 43.5%);--gray12:hsl(0, 0%, 9%);--border-radius:8px;box-sizing:border-box;padding:0;margin:0;list-style:none;outline:0;z-index:999999999;transition:transform .4s ease}@media (hover:none) and (pointer:coarse){[data-sonner-toaster][data-lifted=true]{transform:none}}[data-sonner-toaster][data-x-position=right]{right:var(--offset-right)}[data-sonner-toaster][data-x-position=left]{left:var(--offset-left)}[data-sonner-toaster][data-x-position=center]{left:50%;transform:translateX(-50%)}[data-sonner-toaster][data-y-position=top]{top:var(--offset-top)}[data-sonner-toaster][data-y-position=bottom]{bottom:var(--offset-bottom)}[data-sonner-toast]{--y:translateY(100%);--lift-amount:calc(var(--lift) * var(--gap));z-index:var(--z-index);position:absolute;opacity:0;transform:var(--y);touch-action:none;transition:transform .4s,opacity .4s,height .4s,box-shadow .2s;box-sizing:border-box;outline:0;overflow-wrap:anywhere}[data-sonner-toast][data-styled=true]{padding:16px;background:var(--normal-bg);border:1px solid var(--normal-border);color:var(--normal-text);border-radius:var(--border-radius);box-shadow:0 4px 12px rgba(0,0,0,.1);width:var(--width);font-size:13px;display:flex;align-items:center;gap:6px}[data-sonner-toast]:focus-visible{box-shadow:0 4px 12px rgba(0,0,0,.1),0 0 0 2px rgba(0,0,0,.2)}[data-sonner-toast][data-y-position=top]{top:0;--y:translateY(-100%);--lift:1;--lift-amount:calc(1 * var(--gap))}[data-sonner-toast][data-y-position=bottom]{bottom:0;--y:translateY(100%);--lift:-1;--lift-amount:calc(var(--lift) * var(--gap))}[data-sonner-toast][data-styled=true] [data-description]{font-weight:400;line-height:1.4;color:#3f3f3f}[data-rich-colors=true][data-sonner-toast][data-styled=true] [data-description]{color:inherit}[data-sonner-toaster][data-sonner-theme=dark] [data-description]{color:#e8e8e8}[data-sonner-toast][data-styled=true] [data-title]{font-weight:500;line-height:1.5;color:inherit}[data-sonner-toast][data-styled=true] [data-icon]{display:flex;height:16px;width:16px;position:relative;justify-content:flex-start;align-items:center;flex-shrink:0;margin-left:var(--toast-icon-margin-start);margin-right:var(--toast-icon-margin-end)}[data-sonner-toast][data-promise=true] [data-icon]>svg{opacity:0;transform:scale(.8);transform-origin:center;animation:sonner-fade-in .3s ease forwards}[data-sonner-toast][data-styled=true] [data-icon]>*{flex-shrink:0}[data-sonner-toast][data-styled=true] [data-icon] svg{margin-left:var(--toast-svg-margin-start);margin-right:var(--toast-svg-margin-end)}[data-sonner-toast][data-styled=true] [data-content]{display:flex;flex-direction:column;gap:2px}[data-sonner-toast][data-styled=true] [data-button]{border-radius:4px;padding-left:8px;padding-right:8px;height:24px;font-size:12px;color:var(--normal-bg);background:var(--normal-text);margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end);border:none;font-weight:500;cursor:pointer;outline:0;display:flex;align-items:center;flex-shrink:0;transition:opacity .4s,box-shadow .2s}[data-sonner-toast][data-styled=true] [data-button]:focus-visible{box-shadow:0 0 0 2px rgba(0,0,0,.4)}[data-sonner-toast][data-styled=true] [data-button]:first-of-type{margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end)}[data-sonner-toast][data-styled=true] [data-cancel]{color:var(--normal-text);background:rgba(0,0,0,.08)}[data-sonner-toaster][data-sonner-theme=dark] [data-sonner-toast][data-styled=true] [data-cancel]{background:rgba(255,255,255,.3)}[data-sonner-toast][data-styled=true] [data-close-button]{position:absolute;left:var(--toast-close-button-start);right:var(--toast-close-button-end);top:0;height:20px;width:20px;display:flex;justify-content:center;align-items:center;padding:0;color:var(--gray12);background:var(--normal-bg);border:1px solid var(--gray4);transform:var(--toast-close-button-transform);border-radius:50%;cursor:pointer;z-index:1;transition:opacity .1s,background .2s,border-color .2s}[data-sonner-toast][data-styled=true] [data-close-button]:focus-visible{box-shadow:0 4px 12px rgba(0,0,0,.1),0 0 0 2px rgba(0,0,0,.2)}[data-sonner-toast][data-styled=true] [data-disabled=true]{cursor:not-allowed}[data-sonner-toast][data-styled=true]:hover [data-close-button]:hover{background:var(--gray2);border-color:var(--gray5)}[data-sonner-toast][data-swiping=true]::before{content:'';position:absolute;left:-100%;right:-100%;height:100%;z-index:-1}[data-sonner-toast][data-y-position=top][data-swiping=true]::before{bottom:50%;transform:scaleY(3) translateY(50%)}[data-sonner-toast][data-y-position=bottom][data-swiping=true]::before{top:50%;transform:scaleY(3) translateY(-50%)}[data-sonner-toast][data-swiping=false][data-removed=true]::before{content:'';position:absolute;inset:0;transform:scaleY(2)}[data-sonner-toast][data-expanded=true]::after{content:'';position:absolute;left:0;height:calc(var(--gap) + 1px);bottom:100%;width:100%}[data-sonner-toast][data-mounted=true]{--y:translateY(0);opacity:1}[data-sonner-toast][data-expanded=false][data-front=false]{--scale:var(--toasts-before) * 0.05 + 1;--y:translateY(calc(var(--lift-amount) * var(--toasts-before))) scale(calc(-1 * var(--scale)));height:var(--front-toast-height)}[data-sonner-toast]>*{transition:opacity .4s}[data-sonner-toast][data-x-position=right]{right:0}[data-sonner-toast][data-x-position=left]{left:0}[data-sonner-toast][data-expanded=false][data-front=false][data-styled=true]>*{opacity:0}[data-sonner-toast][data-visible=false]{opacity:0;pointer-events:none}[data-sonner-toast][data-mounted=true][data-expanded=true]{--y:translateY(calc(var(--lift) * var(--offset)));height:var(--initial-height)}[data-sonner-toast][data-removed=true][data-front=true][data-swipe-out=false]{--y:translateY(calc(var(--lift) * -100%));opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=true]{--y:translateY(calc(var(--lift) * var(--offset) + var(--lift) * -100%));opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=false]{--y:translateY(40%);opacity:0;transition:transform .5s,opacity .2s}[data-sonner-toast][data-removed=true][data-front=false]::before{height:calc(var(--initial-height) + 20%)}[data-sonner-toast][data-swiping=true]{transform:var(--y) translateY(var(--swipe-amount-y,0)) translateX(var(--swipe-amount-x,0));transition:none}[data-sonner-toast][data-swiped=true]{user-select:none}[data-sonner-toast][data-swipe-out=true][data-y-position=bottom],[data-sonner-toast][data-swipe-out=true][data-y-position=top]{animation-duration:.2s;animation-timing-function:ease-out;animation-fill-mode:forwards}[data-sonner-toast][data-swipe-out=true][data-swipe-direction=left]{animation-name:swipe-out-left}[data-sonner-toast][data-swipe-out=true][data-swipe-direction=right]{animation-name:swipe-out-right}[data-sonner-toast][data-swipe-out=true][data-swipe-direction=up]{animation-name:swipe-out-up}[data-sonner-toast][data-swipe-out=true][data-swipe-direction=down]{animation-name:swipe-out-down}@keyframes swipe-out-left{from{transform:var(--y) translateX(var(--swipe-amount-x));opacity:1}to{transform:var(--y) translateX(calc(var(--swipe-amount-x) - 100%));opacity:0}}@keyframes swipe-out-right{from{transform:var(--y) translateX(var(--swipe-amount-x));opacity:1}to{transform:var(--y) translateX(calc(var(--swipe-amount-x) + 100%));opacity:0}}@keyframes swipe-out-up{from{transform:var(--y) translateY(var(--swipe-amount-y));opacity:1}to{transform:var(--y) translateY(calc(var(--swipe-amount-y) - 100%));opacity:0}}@keyframes swipe-out-down{from{transform:var(--y) translateY(var(--swipe-amount-y));opacity:1}to{transform:var(--y) translateY(calc(var(--swipe-amount-y) + 100%));opacity:0}}@media (max-width:600px){[data-sonner-toaster]{position:fixed;right:var(--mobile-offset-right);left:var(--mobile-offset-left);width:100%}[data-sonner-toaster][dir=rtl]{left:calc(var(--mobile-offset-left) * -1)}[data-sonner-toaster] [data-sonner-toast]{left:0;right:0;width:calc(100% - var(--mobile-offset-left) * 2)}[data-sonner-toaster][data-x-position=left]{left:var(--mobile-offset-left)}[data-sonner-toaster][data-y-position=bottom]{bottom:var(--mobile-offset-bottom)}[data-sonner-toaster][data-y-position=top]{top:var(--mobile-offset-top)}[data-sonner-toaster][data-x-position=center]{left:var(--mobile-offset-left);right:var(--mobile-offset-right);transform:none}}[data-sonner-toaster][data-sonner-theme=light]{--normal-bg:#fff;--normal-border:var(--gray4);--normal-text:var(--gray12);--success-bg:hsl(143, 85%, 96%);--success-border:hsl(145, 92%, 87%);--success-text:hsl(140, 100%, 27%);--info-bg:hsl(208, 100%, 97%);--info-border:hsl(221, 91%, 93%);--info-text:hsl(210, 92%, 45%);--warning-bg:hsl(49, 100%, 97%);--warning-border:hsl(49, 91%, 84%);--warning-text:hsl(31, 92%, 45%);--error-bg:hsl(359, 100%, 97%);--error-border:hsl(359, 100%, 94%);--error-text:hsl(360, 100%, 45%)}[data-sonner-toaster][data-sonner-theme=light] [data-sonner-toast][data-invert=true]{--normal-bg:#000;--normal-border:hsl(0, 0%, 20%);--normal-text:var(--gray1)}[data-sonner-toaster][data-sonner-theme=dark] [data-sonner-toast][data-invert=true]{--normal-bg:#fff;--normal-border:var(--gray3);--normal-text:var(--gray12)}[data-sonner-toaster][data-sonner-theme=dark]{--normal-bg:#000;--normal-bg-hover:hsl(0, 0%, 12%);--normal-border:hsl(0, 0%, 20%);--normal-border-hover:hsl(0, 0%, 25%);--normal-text:var(--gray1);--success-bg:hsl(150, 100%, 6%);--success-border:hsl(147, 100%, 12%);--success-text:hsl(150, 86%, 65%);--info-bg:hsl(215, 100%, 6%);--info-border:hsl(223, 43%, 17%);--info-text:hsl(216, 87%, 65%);--warning-bg:hsl(64, 100%, 6%);--warning-border:hsl(60, 100%, 9%);--warning-text:hsl(46, 87%, 65%);--error-bg:hsl(358, 76%, 10%);--error-border:hsl(357, 89%, 16%);--error-text:hsl(358, 100%, 81%)}[data-sonner-toaster][data-sonner-theme=dark] [data-sonner-toast] [data-close-button]{background:var(--normal-bg);border-color:var(--normal-border);color:var(--normal-text)}[data-sonner-toaster][data-sonner-theme=dark] [data-sonner-toast] [data-close-button]:hover{background:var(--normal-bg-hover);border-color:var(--normal-border-hover)}[data-rich-colors=true][data-sonner-toast][data-type=success]{background:var(--success-bg);border-color:var(--success-border);color:var(--success-text)}[data-rich-colors=true][data-sonner-toast][data-type=success] [data-close-button]{background:var(--success-bg);border-color:var(--success-border);color:var(--success-text)}[data-rich-colors=true][data-sonner-toast][data-type=info]{background:var(--info-bg);border-color:var(--info-border);color:var(--info-text)}[data-rich-colors=true][data-sonner-toast][data-type=info] [data-close-button]{background:var(--info-bg);border-color:var(--info-border);color:var(--info-text)}[data-rich-colors=true][data-sonner-toast][data-type=warning]{background:var(--warning-bg);border-color:var(--warning-border);color:var(--warning-text)}[data-rich-colors=true][data-sonner-toast][data-type=warning] [data-close-button]{background:var(--warning-bg);border-color:var(--warning-border);color:var(--warning-text)}[data-rich-colors=true][data-sonner-toast][data-type=error]{background:var(--error-bg);border-color:var(--error-border);color:var(--error-text)}[data-rich-colors=true][data-sonner-toast][data-type=error] [data-close-button]{background:var(--error-bg);border-color:var(--error-border);color:var(--error-text)}.sonner-loading-wrapper{--size:16px;height:var(--size);width:var(--size);position:absolute;inset:0;z-index:10}.sonner-loading-wrapper[data-visible=false]{transform-origin:center;animation:sonner-fade-out .2s ease forwards}.sonner-spinner{position:relative;top:50%;left:50%;height:var(--size);width:var(--size)}.sonner-loading-bar{animation:sonner-spin 1.2s linear infinite;background:var(--gray11);border-radius:6px;height:8%;left:-10%;position:absolute;top:-3.9%;width:24%}.sonner-loading-bar:first-child{animation-delay:-1.2s;transform:rotate(.0001deg) translate(146%)}.sonner-loading-bar:nth-child(2){animation-delay:-1.1s;transform:rotate(30deg) translate(146%)}.sonner-loading-bar:nth-child(3){animation-delay:-1s;transform:rotate(60deg) translate(146%)}.sonner-loading-bar:nth-child(4){animation-delay:-.9s;transform:rotate(90deg) translate(146%)}.sonner-loading-bar:nth-child(5){animation-delay:-.8s;transform:rotate(120deg) translate(146%)}.sonner-loading-bar:nth-child(6){animation-delay:-.7s;transform:rotate(150deg) translate(146%)}.sonner-loading-bar:nth-child(7){animation-delay:-.6s;transform:rotate(180deg) translate(146%)}.sonner-loading-bar:nth-child(8){animation-delay:-.5s;transform:rotate(210deg) translate(146%)}.sonner-loading-bar:nth-child(9){animation-delay:-.4s;transform:rotate(240deg) translate(146%)}.sonner-loading-bar:nth-child(10){animation-delay:-.3s;transform:rotate(270deg) translate(146%)}.sonner-loading-bar:nth-child(11){animation-delay:-.2s;transform:rotate(300deg) translate(146%)}.sonner-loading-bar:nth-child(12){animation-delay:-.1s;transform:rotate(330deg) translate(146%)}@keyframes sonner-fade-in{0%{opacity:0;transform:scale(.8)}100%{opacity:1;transform:scale(1)}}@keyframes sonner-fade-out{0%{opacity:1;transform:scale(1)}100%{opacity:0;transform:scale(.8)}}@keyframes sonner-spin{0%{opacity:1}100%{opacity:.15}}@media (prefers-reduced-motion){.sonner-loading-bar,[data-sonner-toast],[data-sonner-toast]>*{transition:none!important;animation:none!important}}.sonner-loader{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);transform-origin:center;transition:opacity .2s,transform .2s}.sonner-loader[data-visible=false]{opacity:0;transform:scale(.8) translate(-50%,-50%)}</style><script id="hotjar-init-script" crossorigin="anonymous">(function(h,o,t,j,a,r){h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};h._hjSettings={hjid:6382967,hjsv:6,hjdebug:false};a=o.getElementsByTagName('head')[0];r=o.createElement('script');r.async=1;r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;a.appendChild(r);})(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');</script><script async="" src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/hotjar-6382967.js"></script><script async="" src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/modules.b062b42f742f840ab0c4.js" charset="utf-8"></script><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="next-size-adjust" content=""><title>thealeglynne/SOLVO_audio_AI_back | DeepWiki</title><meta name="description" content="This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a"><meta property="og:title" content="thealeglynne/SOLVO_audio_AI_back | DeepWiki"><meta property="og:description" content="This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a"><meta property="og:url" content="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back"><meta property="og:site_name" content="DeepWiki"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="thealeglynne/SOLVO_audio_AI_back | DeepWiki"><meta name="twitter:description" content="This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a"><link rel="icon" href="https://deepwiki.com/favicon.ico" type="image/x-icon" sizes="48x48"><link rel="icon" href="https://deepwiki.com/icon.png?66aaf51e0e68c818" type="image/png" sizes="16x16"><link rel="apple-touch-icon" href="https://deepwiki.com/apple-icon.png?a4f658907db0ab87" type="image/png" sizes="180x180"></head><body class="__variable_188709 font-geist-sans relative min-h-screen __variable_9a8899 bg-background antialiased" style="overflow: auto;"><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section><script>((e,t,r,n,o,a,i,s)=>{let l=document.documentElement,u=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(l.classList.remove(...n),l.classList.add(a&&a[t]?a[t]:t)):l.setAttribute(e,t)}),r=t,s&&u.includes(r)&&(l.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","light",null,["light","dark"],null,true,true)</script><!--$--><div class="flex min-h-screen w-full flex-col text-white" id="codebase-wiki-repo-page"><div class="bg-background border-b-border sticky top-0 z-30 border-b border-dashed"><div class="font-geist-mono relative flex h-8 items-center justify-center text-xs font-medium sm:hidden"><div class="powered-by-devin-gradient absolute inset-0 z-[-1] h-8 w-full"></div><a class="flex items-center gap-2" href="https://deepwiki.com/private-repo"><svg class="size-3 [&amp;_path]:stroke-0 [&amp;_path]:animate-[custom-pulse_1.8s_infinite_var(--delay,0s)]" xmlns="http://www.w3.org/2000/svg" viewBox="110 110 460 500"><path style="fill:#21c19a" class="[--delay:0.6s]" d="M418.73,332.37c9.84-5.68,22.07-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.58,1.06.19.06.37.11.55.16.87.21,1.76.34,2.65.35.04,0,.08.02.13.02.1,0,.19-.03.29-.04.83-.02,1.64-.13,2.45-.32.14-.03.28-.05.42-.09.87-.24,1.7-.59,2.5-1.03.08-.04.17-.06.25-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.06,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.57-1.06-.19-.06-.37-.11-.56-.16-.88-.21-1.76-.34-2.65-.34-.13,0-.26.02-.4.02-.84.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.24.1.8.44,1.64.79,2.5,1.03.14.04.28.06.42.09.81.19,1.62.3,2.45.32.1,0,.19.04.29.04.04,0,.08-.02.13-.02.89,0,1.77-.13,2.65-.35.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.58-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-.08-.04-.16-.06-.24-.1-.8-.44-1.64-.8-2.51-1.04-.13-.04-.26-.05-.39-.09-.82-.2-1.65-.31-2.49-.33-.13,0-.25-.02-.38-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.75.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.07,5.68-31.9,0-9.84-5.68-15.95-16.27-15.95-27.63s6.11-21.95,15.95-27.63Z"></path><path style="fill:#3969ca" d="M141.09,317.65l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c.08-.04.13-.11.2-.16.78-.48,1.51-1.02,2.15-1.66.1-.1.18-.21.28-.31.57-.6,1.08-1.26,1.51-1.97.07-.12.15-.22.22-.34.44-.77.77-1.6,1.03-2.47.05-.19.1-.37.14-.56.22-.89.37-1.81.37-2.76v-29.43c0-11.36,6.11-21.95,15.96-27.63s22.06-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.57,1.06.19.06.37.11.56.16.87.21,1.76.34,2.64.35.04,0,.09.02.13.02.1,0,.19-.04.29-.04.83-.02,1.65-.13,2.45-.32.14-.03.28-.05.41-.09.87-.24,1.71-.6,2.51-1.04.08-.04.16-.06.24-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.07,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.58-1.06-.19-.06-.37-.11-.55-.16-.88-.21-1.76-.34-2.65-.35-.13,0-.26.02-.4.02-.83.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22Z"></path><path style="fill:#0294de" class="[--delay:1.2s]" d="M396.88,484.35l-50.97-29.43c-.08-.04-.17-.06-.24-.1-.8-.44-1.64-.79-2.51-1.03-.14-.04-.27-.06-.41-.09-.81-.19-1.64-.3-2.47-.32-.13,0-.26-.02-.39-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.76.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.06,5.68-31.9,0-9.84-5.68-15.96-16.27-15.96-27.63v-29.43c0-.95-.15-1.87-.37-2.76-.05-.19-.09-.37-.14-.56-.25-.86-.59-1.69-1.03-2.47-.07-.12-.15-.22-.22-.34-.43-.71-.94-1.37-1.51-1.97-.1-.1-.18-.21-.28-.31-.65-.63-1.37-1.18-2.15-1.66-.07-.04-.13-.11-.2-.16l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.25.1.8.44,1.63.79,2.5,1.03.14.04.29.06.43.09.8.19,1.61.3,2.43.32.1,0,.2.04.3.04.04,0,.09-.02.13-.02.88,0,1.77-.13,2.64-.34.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.57-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22Z"></path></svg>Index your code with Devin</a></div><div class="container-wrapper"><div class="container mx-auto flex w-full flex-row items-center gap-2 py-4 md:py-6"><a class="flex items-center gap-3" href="https://deepwiki.com/"><span class="text-base font-medium leading-none md:text-lg hidden sm:block">DeepWiki</span></a><div class="flex-1"><div class="flex flex-row items-center gap-2"><a class="block text-xs font-medium leading-none text-white sm:hidden md:text-lg" href="https://deepwiki.com/">DeepWiki</a><p class="text-sm font-normal leading-none md:text-lg"><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back" target="_blank" rel="noopener noreferrer" title="Open repository" class="text-muted-foreground hover:text-muted-foreground/80 group inline-flex items-center gap-1 transition-colors">thealeglynne/SOLVO_audio_AI_back<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256" class="opacity-0 transition-opacity group-hover:opacity-100"><path d="M224,104a8,8,0,0,1-16,0V59.32l-66.33,66.34a8,8,0,0,1-11.32-11.32L196.68,48H152a8,8,0,0,1,0-16h64a8,8,0,0,1,8,8Zm-40,24a8,8,0,0,0-8,8v72H48V80h72a8,8,0,0,0,0-16H48A16,16,0,0,0,32,80V208a16,16,0,0,0,16,16H176a16,16,0,0,0,16-16V136A8,8,0,0,0,184,128Z"></path></svg></a></p></div></div><div class="flex items-center gap-4"><a class="group hidden items-center gap-1.5 md:flex" href="https://deepwiki.com/private-repo"><div class="relative"><span class="text-foreground/70 group-hover:text-foreground text-xs font-light transition-colors">Index your code with</span><div class="bg-foreground/30 absolute bottom-0 left-0 h-[1px] w-0 transition-all duration-300 group-hover:w-full"></div></div><div class="flex items-center gap-1 transition-transform duration-300 group-hover:translate-x-0.5"><svg class="size-4 transform transition-transform duration-700 group-hover:rotate-180 [&amp;_path]:stroke-0" xmlns="http://www.w3.org/2000/svg" viewBox="110 110 460 500"><path style="fill:#21c19a" class="" d="M418.73,332.37c9.84-5.68,22.07-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.58,1.06.19.06.37.11.55.16.87.21,1.76.34,2.65.35.04,0,.08.02.13.02.1,0,.19-.03.29-.04.83-.02,1.64-.13,2.45-.32.14-.03.28-.05.42-.09.87-.24,1.7-.59,2.5-1.03.08-.04.17-.06.25-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.06,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.57-1.06-.19-.06-.37-.11-.56-.16-.88-.21-1.76-.34-2.65-.34-.13,0-.26.02-.4.02-.84.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.24.1.8.44,1.64.79,2.5,1.03.14.04.28.06.42.09.81.19,1.62.3,2.45.32.1,0,.19.04.29.04.04,0,.08-.02.13-.02.89,0,1.77-.13,2.65-.35.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.58-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-.08-.04-.16-.06-.24-.1-.8-.44-1.64-.8-2.51-1.04-.13-.04-.26-.05-.39-.09-.82-.2-1.65-.31-2.49-.33-.13,0-.25-.02-.38-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.75.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.07,5.68-31.9,0-9.84-5.68-15.95-16.27-15.95-27.63s6.11-21.95,15.95-27.63Z"></path><path style="fill:#3969ca" d="M141.09,317.65l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c.08-.04.13-.11.2-.16.78-.48,1.51-1.02,2.15-1.66.1-.1.18-.21.28-.31.57-.6,1.08-1.26,1.51-1.97.07-.12.15-.22.22-.34.44-.77.77-1.6,1.03-2.47.05-.19.1-.37.14-.56.22-.89.37-1.81.37-2.76v-29.43c0-11.36,6.11-21.95,15.96-27.63s22.06-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.57,1.06.19.06.37.11.56.16.87.21,1.76.34,2.64.35.04,0,.09.02.13.02.1,0,.19-.04.29-.04.83-.02,1.65-.13,2.45-.32.14-.03.28-.05.41-.09.87-.24,1.71-.6,2.51-1.04.08-.04.16-.06.24-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.07,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.58-1.06-.19-.06-.37-.11-.55-.16-.88-.21-1.76-.34-2.65-.35-.13,0-.26.02-.4.02-.83.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22Z"></path><path style="fill:#0294de" class="" d="M396.88,484.35l-50.97-29.43c-.08-.04-.17-.06-.24-.1-.8-.44-1.64-.79-2.51-1.03-.14-.04-.27-.06-.41-.09-.81-.19-1.64-.3-2.47-.32-.13,0-.26-.02-.39-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.76.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.06,5.68-31.9,0-9.84-5.68-15.96-16.27-15.96-27.63v-29.43c0-.95-.15-1.87-.37-2.76-.05-.19-.09-.37-.14-.56-.25-.86-.59-1.69-1.03-2.47-.07-.12-.15-.22-.22-.34-.43-.71-.94-1.37-1.51-1.97-.1-.1-.18-.21-.28-.31-.65-.63-1.37-1.18-2.15-1.66-.07-.04-.13-.11-.2-.16l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.25.1.8.44,1.63.79,2.5,1.03.14.04.29.06.43.09.8.19,1.61.3,2.43.32.1,0,.2.04.3.04.04,0,.09-.02.13-.02.88,0,1.77-.13,2.64-.34.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.57-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22Z"></path></svg><span class="text-sm font-medium">Devin</span></div></a><button class="flex items-center rounded-md !text-white cursor-pointer transition-all border bg-blue-500 hover:bg-blue-600 border-blue-500 hover:border-blue-600 dark:bg-blue-900 dark:hover:bg-blue-800 dark:border-blue-900 dark:hover:border-blue-800 disabled:cursor-default disabled:opacity-50 disabled:hover:bg-blue-500 disabled:hover:border-blue-500 dark:disabled:hover:bg-blue-900 dark:disabled:hover:border-blue-900 gap-1.5 px-3 py-1.5 text-sm" aria-label="Share"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-4 w-4"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg><span>Share</span></button><button class="hover:bg-surface-hover flex h-8 w-8 cursor-pointer items-center justify-center rounded-md transition-colors" aria-label="Switch to dark mode"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-5 w-5 text-gray-700"><path d="M235.54,150.21a104.84,104.84,0,0,1-37,52.91A104,104,0,0,1,32,120,103.09,103.09,0,0,1,52.88,57.48a104.84,104.84,0,0,1,52.91-37,8,8,0,0,1,10,10,88.08,88.08,0,0,0,109.8,109.8,8,8,0,0,1,10,10Z"></path></svg></button></div></div></div></div><!--$--><!--/$--><div class="w-full flex-1"><div class="container-wrapper relative mx-auto h-full px-0"><div class="container relative mx-auto flex h-full w-full flex-col gap-0 max-md:!px-0 md:flex-row md:gap-6 lg:gap-10"><div class="border-r-border hidden max-h-screen border-r border-dashed py-6 pr-4 transition-[border-radius] md:sticky md:left-0 md:top-20 md:block md:h-[calc(100vh-82px)] md:w-64 md:flex-shrink-0 md:overflow-y-auto lg:py-9 xl:w-72"><div class="flex h-full w-full max-w-full flex-shrink-0 flex-col overflow-hidden" style="scrollbar-color: var(--color-border) transparent;"><div class="flex-shrink-0 px-2"><div class="text-secondary pb-1 text-xs">Last indexed: 26 July 2025 (<a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/commits/12cfb168" target="_blank" rel="noopener noreferrer">12cfb1</a>)</div></div><ul class="flex-1 flex-shrink-0 space-y-1 overflow-y-auto py-1" style="scrollbar-width: none;"><li style="padding-left: 0px;"><a data-selected="true" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview">Overview</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1.1-system-components">System Components</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1.2-technology-stack">Technology Stack</a></li><li style="padding-left: 0px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2-fastapi-web-service">FastAPI Web Service</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2.1-application-structure-and-configuration">Application Structure &amp; Configuration</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2.2-audio-transcription-endpoint">Audio Transcription Endpoint</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2.3-file-upload-and-processing-pipeline">File Upload &amp; Processing Pipeline</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2.4-error-handling-and-response-format">Error Handling &amp; Response Format</a></li><li style="padding-left: 0px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/3-audio-processing-engine">Audio Processing Engine</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/3.1-audio-format-conversion">Audio Format Conversion</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/3.2-speech-recognition-engine">Speech Recognition Engine</a></li><li style="padding-left: 0px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/4-system-architecture-and-dependencies">System Architecture &amp; Dependencies</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/4.1-python-dependencies">Python Dependencies</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/4.2-service-architecture">Service Architecture</a></li><li style="padding-left: 0px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/5-development-and-deployment">Development &amp; Deployment</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/5.1-environment-setup">Environment Setup</a></li><li style="padding-left: 12px;"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/5.2-deployment-configuration">Deployment Configuration</a></li></ul></div></div><div class="flex h-full flex-1 flex-col overflow-hidden"><div class="bg-background border-b-border sticky top-0 z-10 border-b border-dashed md:hidden"><div class="flex cursor-pointer items-center gap-2 p-3"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256" class="transition-transform"><path d="M184.49,136.49l-80,80a12,12,0,0,1-17-17L159,128,87.51,56.49a12,12,0,1,1,17-17l80,80A12,12,0,0,1,184.49,136.49Z"></path></svg><span class="truncate text-base font-normal">Menu</span></div></div><div class="relative flex-1 overflow-y-auto px-3 pt-3 md:rounded-md md:px-0 md:pt-0 [&amp;_::selection]:bg-purple-500/40" style="scrollbar-color: var(--color-night) transparent;"><div class="pb-30 mx-auto max-w-2xl md:pb-40 md:pt-6 lg:pt-8"><div class="prose prose-invert dark:prose-invert prose-headings:text-inherit prose-p:text-inherit max-w-none"><div><div class="prose-custom prose-custom-md prose-custom-gray !max-w-none text-neutral-300 [overflow-wrap:anywhere]"><h1 id="overview" class="group" data-header="true">Overview<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h1>
<details>
<summary>Relevant source files</summary>
<ul>
<li><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/.gitignore" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>.gitignore</span></a></li>
<li><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span></a></li>
<li><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span></a></li>
<li><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/requirements.txt" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>requirements.txt</span></a></li>
</ul>
</details>
<h2 id="purpose-and-scope" class="group" data-header="true">Purpose and Scope<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system accepts audio uploads in various formats (MP3, M4A, WAV), converts them to standardized WAV format when necessary, and returns Spanish text transcriptions.</p>
<p>For detailed documentation on specific components, see <a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/2-fastapi-web-service" class="text-neutral-300 hover:text-neutral-200 hover:underline">FastAPI Web Service</a> for the web layer implementation, <a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/3-audio-processing-engine" class="text-neutral-300 hover:text-neutral-200 hover:underline">Audio Processing Engine</a> for the core transcription logic, and <a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/5-development-and-deployment" class="text-neutral-300 hover:text-neutral-200 hover:underline">Development &amp; Deployment</a> for setup instructions.</p>
<h2 id="system-architecture" class="group" data-header="true">System Architecture<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The following diagram shows the core system architecture and maps high-level concepts to their corresponding code entities:</p>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><div class="group relative cursor-pointer overflow-x-auto rounded-md bg-[#f2f1f0] p-4 transition-colors hover:bg-[#ededed] dark:bg-[#1f1f1f] dark:hover:bg-[#242424]" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-r8m" data-state="closed" data-slot="dialog-trigger"><div class="flex justify-center"><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="0 0 1179.1875 781" style="max-width: 100%; touch-action: none; user-select: none; cursor: grab; min-height: fit-content; max-height: 100%;" class="flowchart" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" id="mermaid-yggxy07keo" preserveAspectRatio="xMidYMid meet"><style>#mermaid-yggxy07keo{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-yggxy07keo .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-yggxy07keo .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-yggxy07keo .error-icon{fill:#dddddd;}#mermaid-yggxy07keo .error-text{fill:#222222;stroke:#222222;}#mermaid-yggxy07keo .edge-thickness-normal{stroke-width:1px;}#mermaid-yggxy07keo .edge-thickness-thick{stroke-width:3.5px;}#mermaid-yggxy07keo .edge-pattern-solid{stroke-dasharray:0;}#mermaid-yggxy07keo .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-yggxy07keo .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-yggxy07keo .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-yggxy07keo .marker{fill:#999;stroke:#999;}#mermaid-yggxy07keo .marker.cross{stroke:#999;}#mermaid-yggxy07keo svg{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;}#mermaid-yggxy07keo p{margin:0;}#mermaid-yggxy07keo .label{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;color:#333;}#mermaid-yggxy07keo .cluster-label text{fill:#444;}#mermaid-yggxy07keo .cluster-label span{color:#444;}#mermaid-yggxy07keo .cluster-label span p{background-color:transparent;}#mermaid-yggxy07keo .label text,#mermaid-yggxy07keo span{fill:#333;color:#333;}#mermaid-yggxy07keo .node rect,#mermaid-yggxy07keo .node circle,#mermaid-yggxy07keo .node ellipse,#mermaid-yggxy07keo .node polygon,#mermaid-yggxy07keo .node path{fill:#ffffff;stroke:#dddddd;stroke-width:1px;}#mermaid-yggxy07keo .rough-node .label text,#mermaid-yggxy07keo .node .label text,#mermaid-yggxy07keo .image-shape .label,#mermaid-yggxy07keo .icon-shape .label{text-anchor:middle;}#mermaid-yggxy07keo .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-yggxy07keo .rough-node .label,#mermaid-yggxy07keo .node .label,#mermaid-yggxy07keo .image-shape .label,#mermaid-yggxy07keo .icon-shape .label{text-align:center;}#mermaid-yggxy07keo .node.clickable{cursor:pointer;}#mermaid-yggxy07keo .root .anchor path{fill:#999!important;stroke-width:0;stroke:#999;}#mermaid-yggxy07keo .arrowheadPath{fill:#0b0b0b;}#mermaid-yggxy07keo .edgePath .path{stroke:#999;stroke-width:2.0px;}#mermaid-yggxy07keo .flowchart-link{stroke:#999;fill:none;}#mermaid-yggxy07keo .edgeLabel{background-color:#ffffff;text-align:center;}#mermaid-yggxy07keo .edgeLabel p{background-color:#ffffff;}#mermaid-yggxy07keo .edgeLabel rect{opacity:0.5;background-color:#ffffff;fill:#ffffff;}#mermaid-yggxy07keo .labelBkg{background-color:rgba(255, 255, 255, 0.5);}#mermaid-yggxy07keo .cluster rect{fill:#f8f8f8;stroke:#dddddd;stroke-width:1px;}#mermaid-yggxy07keo .cluster text{fill:#444;}#mermaid-yggxy07keo .cluster span{color:#444;}#mermaid-yggxy07keo div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:12px;background:#dddddd;border:1px solid hsl(0, 0%, 76.6666666667%);border-radius:2px;pointer-events:none;z-index:100;}#mermaid-yggxy07keo .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-yggxy07keo rect.text{fill:none;stroke-width:0;}#mermaid-yggxy07keo .icon-shape,#mermaid-yggxy07keo .image-shape{background-color:#ffffff;text-align:center;}#mermaid-yggxy07keo .icon-shape p,#mermaid-yggxy07keo .image-shape p{background-color:#ffffff;padding:2px;}#mermaid-yggxy07keo .icon-shape rect,#mermaid-yggxy07keo .image-shape rect{opacity:0.5;background-color:#ffffff;fill:#ffffff;}#mermaid-yggxy07keo :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="5" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="mermaid-yggxy07keo_flowchart-v2-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"><g data-look="classic" id="subGraph3" class="cluster"><rect height="128" width="270.71875" y="645" x="239.85546875" style=""></rect><g transform="translate(312.7109375, 645)" class="cluster-label"><foreignobject height="24" width="125.0078125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>External Services</p></span></div></foreignobject></g></g><g data-look="classic" id="subGraph2" class="cluster"><rect height="281" width="498.8515625" y="314" x="8" style=""></rect><g transform="translate(191.96875, 314)" class="cluster-label"><foreignobject height="24" width="130.9140625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>iaModels Package</p></span></div></foreignobject></g></g><g data-look="classic" id="subGraph1" class="cluster"><rect height="128" width="644.3359375" y="314" x="526.8515625" style=""></rect><g transform="translate(763.76953125, 314)" class="cluster-label"><foreignobject height="24" width="170.5"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>File Processing Pipeline</p></span></div></foreignobject></g></g><g data-look="classic" id="subGraph0" class="cluster"><rect height="256" width="1022.59765625" y="8" x="94.7578125" style=""></rect><g transform="translate(514.146484375, 8)" class="cluster-label"><foreignobject height="24" width="183.8203125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>FastAPI Application Layer</p></span></div></foreignobject></g></g></g><g class="edgePaths"><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_app_cors_0" d="M444.068,87.234L407.253,95.362C370.438,103.489,296.807,119.745,259.991,131.372C223.176,143,223.176,150,223.176,153.5L223.176,157"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_app_endpoint_0" d="M582.076,109.089L590.421,113.574C598.766,118.059,615.455,127.03,623.8,135.015C632.145,143,632.145,150,632.145,153.5L632.145,157"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_endpoint_uploads_dir_0" d="M632.145,239L632.145,243.167C632.145,247.333,632.145,255.667,632.145,264C632.145,272.333,632.145,280.667,632.145,289C632.145,297.333,632.145,305.667,632.145,313.333C632.145,321,632.145,328,632.145,331.5L632.145,335"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_endpoint_uuid_gen_0" d="M726.871,231.169L743.501,236.641C760.13,242.113,793.389,253.056,810.019,262.695C826.648,272.333,826.648,280.667,826.648,289C826.648,297.333,826.648,305.667,826.648,313.333C826.648,321,826.648,328,826.648,331.5L826.648,335"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_endpoint_file_write_0" d="M726.871,214.737L779.646,222.948C832.422,231.158,937.973,247.579,990.748,259.956C1043.523,272.333,1043.523,280.667,1043.523,289C1043.523,297.333,1043.523,305.667,1043.523,313.333C1043.523,321,1043.523,328,1043.523,331.5L1043.523,335"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_endpoint_convert_func_0" d="M537.418,212.214L470.48,220.845C403.542,229.476,269.665,246.738,202.727,259.536C135.789,272.333,135.789,280.667,135.789,289C135.789,297.333,135.789,305.667,135.789,313.333C135.789,321,135.789,328,135.789,331.5L135.789,335"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_endpoint_transcribe_func_0" d="M537.418,223.596L510.384,230.33C483.35,237.064,429.283,250.532,402.249,261.433C375.215,272.333,375.215,280.667,375.215,289C375.215,297.333,375.215,305.667,375.215,313.333C375.215,321,375.215,328,375.215,331.5L375.215,335"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_convert_func_pydub_0" d="M135.789,417L135.789,421.167C135.789,425.333,135.789,433.667,135.789,442C135.789,450.333,135.789,458.667,135.789,466.333C135.789,474,135.789,481,135.789,484.5L135.789,488"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_transcribe_func_speech_rec_0" d="M375.215,417L375.215,421.167C375.215,425.333,375.215,433.667,375.215,442C375.215,450.333,375.215,458.667,375.215,466.333C375.215,474,375.215,481,375.215,484.5L375.215,488"></path><path marker-end="url(#mermaid-yggxy07keo_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_speech_rec_google_api_0" d="M375.215,570L375.215,574.167C375.215,578.333,375.215,586.667,375.215,595C375.215,603.333,375.215,611.667,375.215,620C375.215,628.333,375.215,636.667,375.215,644.333C375.215,652,375.215,659,375.215,662.5L375.215,666"></path></g><g class="edgeLabels"><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g></g><g class="nodes"><g transform="translate(513.072265625, 72)" id="flowchart-app-0" class="node default"><rect height="78" width="138.0078125" y="-39" x="-69.00390625" style="" class="basic label-container"></rect><g transform="translate(-39.00390625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="78.0078125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>FastAPI()<br>main.py:13</p></span></div></foreignobject></g></g><g transform="translate(223.17578125, 200)" id="flowchart-cors-1" class="node default"><rect height="78" width="186.8359375" y="-39" x="-93.41796875" style="" class="basic label-container"></rect><g transform="translate(-63.41796875, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="126.8359375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>CORSMiddleware<br>main.py:16-25</p></span></div></foreignobject></g></g><g transform="translate(632.14453125, 200)" id="flowchart-endpoint-2" class="node default"><rect height="78" width="189.453125" y="-39" x="-94.7265625" style="" class="basic label-container"></rect><g transform="translate(-64.7265625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="129.453125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>/transcribir-audio/<br>main.py:27</p></span></div></foreignobject></g></g><g transform="translate(632.14453125, 378)" id="flowchart-uploads_dir-3" class="node default"><rect height="78" width="140.5859375" y="-39" x="-70.29296875" style="" class="basic label-container"></rect><g transform="translate(-40.29296875, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="80.5859375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>uploads/<br>main.py:30</p></span></div></foreignobject></g></g><g transform="translate(826.6484375, 378)" id="flowchart-uuid_gen-4" class="node default"><rect height="78" width="148.421875" y="-39" x="-74.2109375" style="" class="basic label-container"></rect><g transform="translate(-44.2109375, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="88.421875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>uuid.uuid4()<br>main.py:34</p></span></div></foreignobject></g></g><g transform="translate(1043.5234375, 378)" id="flowchart-file_write-5" class="node default"><rect height="78" width="185.328125" y="-39" x="-92.6640625" style="" class="basic label-container"></rect><g transform="translate(-62.6640625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="125.328125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>UploadFile.read()<br>main.py:38</p></span></div></foreignobject></g></g><g transform="translate(135.7890625, 378)" id="flowchart-convert_func-6" class="node default"><rect height="78" width="185.578125" y="-39" x="-92.7890625" style="" class="basic label-container"></rect><g transform="translate(-62.7890625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="125.578125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>convert_to_wav()<br>transcribir.py:5</p></span></div></foreignobject></g></g><g transform="translate(375.21484375, 378)" id="flowchart-transcribe_func-7" class="node default"><rect height="78" width="193.2734375" y="-39" x="-96.63671875" style="" class="basic label-container"></rect><g transform="translate(-66.63671875, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="133.2734375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>transcribe_audio()<br>transcribir.py:9</p></span></div></foreignobject></g></g><g transform="translate(135.7890625, 531)" id="flowchart-pydub-8" class="node default"><rect height="78" width="169.1328125" y="-39" x="-84.56640625" style="" class="basic label-container"></rect><g transform="translate(-54.56640625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="109.1328125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>AudioSegment<br>transcribir.py:6</p></span></div></foreignobject></g></g><g transform="translate(375.21484375, 531)" id="flowchart-speech_rec-9" class="node default"><rect height="78" width="176.0859375" y="-39" x="-88.04296875" style="" class="basic label-container"></rect><g transform="translate(-58.04296875, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="116.0859375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>sr.Recognizer()<br>transcribir.py:13</p></span></div></foreignobject></g></g><g transform="translate(375.21484375, 709)" id="flowchart-google_api-10" class="node default"><rect height="78" width="200.71875" y="-39" x="-100.359375" style="" class="basic label-container"></rect><g transform="translate(-70.359375, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="140.71875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>recognize_google()<br>transcribir.py:18</p></span></div></foreignobject></g></g></g></g></g></svg></div><div class="bg-input-dark absolute right-2 top-2 rounded-sm p-1 opacity-0 transition-opacity group-hover:opacity-100"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256"><path d="M216,48V96a8,8,0,0,1-16,0V67.31l-42.34,42.35a8,8,0,0,1-11.32-11.32L188.69,56H160a8,8,0,0,1,0-16h48A8,8,0,0,1,216,48ZM98.34,146.34,56,188.69V160a8,8,0,0,0-16,0v48a8,8,0,0,0,8,8H96a8,8,0,0,0,0-16H67.31l42.35-42.34a8,8,0,0,0-11.32-11.32ZM208,152a8,8,0,0,0-8,8v28.69l-42.34-42.35a8,8,0,0,0-11.32,11.32L188.69,200H160a8,8,0,0,0,0,16h48a8,8,0,0,0,8-8V160A8,8,0,0,0,208,152ZM67.31,56H96a8,8,0,0,0,0-16H48a8,8,0,0,0-8,8V96a8,8,0,0,0,16,0V67.31l42.34,42.35a8,8,0,0,0,11.32-11.32Z"></path></svg></div></div></pre>
<p><strong>Sources</strong>: <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L1-L63" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-63</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py#L1-L23" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-23</span></a></p>
<h2 id="core-components" class="group" data-header="true">Core Components<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The system consists of three primary components that work together to provide audio transcription services:</p>





























<table><thead><tr><th>Component</th><th>Code Entity</th><th>Primary Functions</th><th>Location</th></tr></thead><tbody><tr><td><strong>Web Service Layer</strong></td><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">FastAPI()</code> app instance</td><td>HTTP request handling, CORS, file uploads</td><td><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L13-L13" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">13</span></a></td></tr><tr><td><strong>Audio Processing</strong></td><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">iaModels</code> package</td><td>Format conversion, speech recognition</td><td><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span></a></td></tr><tr><td><strong>External Integration</strong></td><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sr.recognize_google()</code></td><td>Spanish language transcription</td><td><a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py#L18-L18" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">18</span></a></td></tr></tbody></table>
<h3 id="request-processing-flow" class="group" data-header="true">Request Processing Flow<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<p>This diagram shows the actual function call sequence for processing audio transcription requests:</p>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><div class="group relative cursor-pointer overflow-x-auto rounded-md bg-[#f2f1f0] p-4 transition-colors hover:bg-[#ededed] dark:bg-[#1f1f1f] dark:hover:bg-[#242424]" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-r8p" data-state="closed" data-slot="dialog-trigger"><div class="flex justify-center"><svg aria-roledescription="sequence" role="graphics-document document" viewBox="-50 -10 1666.5 1119" style="max-width: 100%; touch-action: none; user-select: none; cursor: grab; min-height: fit-content; max-height: 100%;" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" id="mermaid-43vuvp97372" preserveAspectRatio="xMidYMid meet"><g><rect class="actor actor-bottom" ry="3" rx="3" name="google" height="65" width="170" stroke="#666" fill="#eaeaea" y="1033" x="1396.5"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="1481.5"><tspan dy="0" x="1481.5">"recognize_google()"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="recognizer" height="65" width="150" stroke="#666" fill="#eaeaea" y="1033" x="1196.5"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="1271.5"><tspan dy="0" x="1271.5">"sr.Recognizer()"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="transcriber" height="65" width="163" stroke="#666" fill="#eaeaea" y="1033" x="924"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="1005.5"><tspan dy="0" x="1005.5">"transcribe_audio()"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="converter" height="65" width="157" stroke="#666" fill="#eaeaea" y="1033" x="717"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="795.5"><tspan dy="0" x="795.5">"convert_to_wav()"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="filesystem" height="65" width="162" stroke="#666" fill="#eaeaea" y="1033" x="505"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="586"><tspan dy="0" x="586">"os.makedirs/open"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="endpoint" height="65" width="238" stroke="#666" fill="#eaeaea" y="1033" x="217"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="336"><tspan dy="0" x="336">"transcribir_audio_endpoint()"</tspan></text></g><g><rect class="actor actor-bottom" ry="3" rx="3" name="client" height="65" width="150" stroke="#666" fill="#eaeaea" y="1033" x="0"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="1065.5" x="75"><tspan dy="0" x="75">"HTTP Client"</tspan></text></g><g><line name="google" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="1481.5" y1="65" x1="1481.5" id="actor53"></line><g id="root-53"><rect class="actor actor-top" ry="3" rx="3" name="google" height="65" width="170" stroke="#666" fill="#eaeaea" y="0" x="1396.5"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="1481.5"><tspan dy="0" x="1481.5">"recognize_google()"</tspan></text></g></g><g><line name="recognizer" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="1271.5" y1="65" x1="1271.5" id="actor52"></line><g id="root-52"><rect class="actor actor-top" ry="3" rx="3" name="recognizer" height="65" width="150" stroke="#666" fill="#eaeaea" y="0" x="1196.5"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="1271.5"><tspan dy="0" x="1271.5">"sr.Recognizer()"</tspan></text></g></g><g><line name="transcriber" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="1005.5" y1="65" x1="1005.5" id="actor51"></line><g id="root-51"><rect class="actor actor-top" ry="3" rx="3" name="transcriber" height="65" width="163" stroke="#666" fill="#eaeaea" y="0" x="924"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="1005.5"><tspan dy="0" x="1005.5">"transcribe_audio()"</tspan></text></g></g><g><line name="converter" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="795.5" y1="65" x1="795.5" id="actor50"></line><g id="root-50"><rect class="actor actor-top" ry="3" rx="3" name="converter" height="65" width="157" stroke="#666" fill="#eaeaea" y="0" x="717"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="795.5"><tspan dy="0" x="795.5">"convert_to_wav()"</tspan></text></g></g><g><line name="filesystem" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="586" y1="65" x1="586" id="actor49"></line><g id="root-49"><rect class="actor actor-top" ry="3" rx="3" name="filesystem" height="65" width="162" stroke="#666" fill="#eaeaea" y="0" x="505"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="586"><tspan dy="0" x="586">"os.makedirs/open"</tspan></text></g></g><g><line name="endpoint" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="336" y1="65" x1="336" id="actor48"></line><g id="root-48"><rect class="actor actor-top" ry="3" rx="3" name="endpoint" height="65" width="238" stroke="#666" fill="#eaeaea" y="0" x="217"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="336"><tspan dy="0" x="336">"transcribir_audio_endpoint()"</tspan></text></g></g><g><line name="client" stroke="#999" stroke-width="0.5px" class="actor-line 200" y2="1033" x2="75" y1="65" x1="75" id="actor47"></line><g id="root-47"><rect class="actor actor-top" ry="3" rx="3" name="client" height="65" width="150" stroke="#666" fill="#eaeaea" y="0" x="0"></rect><text style="text-anchor: middle; font-size: 16px; font-weight: 400;" class="actor actor-box" alignment-baseline="central" dominant-baseline="central" y="32.5" x="75"><tspan dy="0" x="75">"HTTP Client"</tspan></text></g></g><style>#mermaid-43vuvp97372{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-43vuvp97372 .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-43vuvp97372 .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-43vuvp97372 .error-icon{fill:#dddddd;}#mermaid-43vuvp97372 .error-text{fill:#222222;stroke:#222222;}#mermaid-43vuvp97372 .edge-thickness-normal{stroke-width:1px;}#mermaid-43vuvp97372 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-43vuvp97372 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-43vuvp97372 .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-43vuvp97372 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-43vuvp97372 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-43vuvp97372 .marker{fill:#999;stroke:#999;}#mermaid-43vuvp97372 .marker.cross{stroke:#999;}#mermaid-43vuvp97372 svg{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;}#mermaid-43vuvp97372 p{margin:0;}#mermaid-43vuvp97372 .actor{stroke:#cccccc;fill:#ffffff;}#mermaid-43vuvp97372 text.actor&gt;tspan{fill:#333;stroke:none;}#mermaid-43vuvp97372 .actor-line{stroke:#cccccc;}#mermaid-43vuvp97372 .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#999999;}#mermaid-43vuvp97372 .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#999999;}#mermaid-43vuvp97372 #arrowhead path{fill:#999999;stroke:#999999;}#mermaid-43vuvp97372 .sequenceNumber{fill:#666666;}#mermaid-43vuvp97372 #sequencenumber{fill:#999999;}#mermaid-43vuvp97372 #crosshead path{fill:#999999;stroke:#999999;}#mermaid-43vuvp97372 .messageText{fill:#333333;stroke:none;}#mermaid-43vuvp97372 .labelBox{stroke:#dddddd;fill:#ffffff;}#mermaid-43vuvp97372 .labelText,#mermaid-43vuvp97372 .labelText&gt;tspan{fill:#333;stroke:none;}#mermaid-43vuvp97372 .loopText,#mermaid-43vuvp97372 .loopText&gt;tspan{fill:#333;stroke:none;}#mermaid-43vuvp97372 .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:#dddddd;fill:#dddddd;}#mermaid-43vuvp97372 .note{stroke:#e6d280;fill:#fff5ad;}#mermaid-43vuvp97372 .noteText,#mermaid-43vuvp97372 .noteText&gt;tspan{fill:#333;stroke:none;}#mermaid-43vuvp97372 .activation0{fill:hsl(-120, 0%, 91.7647058824%);stroke:hsl(-120, 0%, 81.7647058824%);}#mermaid-43vuvp97372 .activation1{fill:hsl(-120, 0%, 91.7647058824%);stroke:hsl(-120, 0%, 81.7647058824%);}#mermaid-43vuvp97372 .activation2{fill:hsl(-120, 0%, 91.7647058824%);stroke:hsl(-120, 0%, 81.7647058824%);}#mermaid-43vuvp97372 .actorPopupMenu{position:absolute;}#mermaid-43vuvp97372 .actorPopupMenuPanel{position:absolute;fill:#ffffff;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#mermaid-43vuvp97372 .actor-man line{stroke:#cccccc;fill:#ffffff;}#mermaid-43vuvp97372 .actor-man circle,#mermaid-43vuvp97372 line{stroke:#cccccc;fill:#ffffff;stroke-width:2px;}#mermaid-43vuvp97372 :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g></g><defs><symbol height="24" width="24" id="computer"><path d="M2 2v13h20v-13h-20zm18 11h-16v-9h16v9zm-10.228 6l.466-1h3.524l.467 1h-4.457zm14.228 3h-24l2-6h2.104l-1.33 4h18.45l-1.297-4h2.073l2 6zm-5-10h-14v-7h14v7z" transform="scale(.5)"></path></symbol></defs><defs><symbol clip-rule="evenodd" fill-rule="evenodd" id="database"><path d="M12.258.001l.256.004.255.005.253.008.251.01.249.012.247.015.246.016.242.019.241.02.239.023.236.024.233.027.231.028.229.031.225.032.223.034.22.036.217.038.214.04.211.041.208.043.205.045.201.046.198.048.194.05.191.051.187.053.183.054.18.056.175.057.172.059.168.06.163.061.16.063.155.064.15.066.074.033.073.033.071.034.07.034.069.035.068.035.067.035.066.035.064.036.064.036.062.036.06.036.06.037.058.037.058.037.055.038.055.038.053.038.052.038.051.039.05.039.048.039.047.039.045.04.044.04.043.04.041.04.04.041.039.041.037.041.036.041.034.041.033.042.032.042.03.042.029.042.027.042.026.043.024.043.023.043.021.043.02.043.018.044.017.043.015.044.013.044.012.044.011.045.009.044.007.045.006.045.004.045.002.045.001.045v17l-.001.045-.002.045-.004.045-.006.045-.007.045-.009.044-.011.045-.012.044-.013.044-.015.044-.017.043-.018.044-.02.043-.021.043-.023.043-.024.043-.026.043-.027.042-.029.042-.03.042-.032.042-.033.042-.034.041-.036.041-.037.041-.039.041-.04.041-.041.04-.043.04-.044.04-.045.04-.047.039-.048.039-.05.039-.051.039-.052.038-.053.038-.055.038-.055.038-.058.037-.058.037-.06.037-.06.036-.062.036-.064.036-.064.036-.066.035-.067.035-.068.035-.069.035-.07.034-.071.034-.073.033-.074.033-.15.066-.155.064-.16.063-.163.061-.168.06-.172.059-.175.057-.18.056-.183.054-.187.053-.191.051-.194.05-.198.048-.201.046-.205.045-.208.043-.211.041-.214.04-.217.038-.22.036-.223.034-.225.032-.229.031-.231.028-.233.027-.236.024-.239.023-.241.02-.242.019-.246.016-.247.015-.249.012-.251.01-.253.008-.255.005-.256.004-.258.001-.258-.001-.256-.004-.255-.005-.253-.008-.251-.01-.249-.012-.247-.015-.245-.016-.243-.019-.241-.02-.238-.023-.236-.024-.234-.027-.231-.028-.228-.031-.226-.032-.223-.034-.22-.036-.217-.038-.214-.04-.211-.041-.208-.043-.204-.045-.201-.046-.198-.048-.195-.05-.19-.051-.187-.053-.184-.054-.179-.056-.176-.057-.172-.059-.167-.06-.164-.061-.159-.063-.155-.064-.151-.066-.074-.033-.072-.033-.072-.034-.07-.034-.069-.035-.068-.035-.067-.035-.066-.035-.064-.036-.063-.036-.062-.036-.061-.036-.06-.037-.058-.037-.057-.037-.056-.038-.055-.038-.053-.038-.052-.038-.051-.039-.049-.039-.049-.039-.046-.039-.046-.04-.044-.04-.043-.04-.041-.04-.04-.041-.039-.041-.037-.041-.036-.041-.034-.041-.033-.042-.032-.042-.03-.042-.029-.042-.027-.042-.026-.043-.024-.043-.023-.043-.021-.043-.02-.043-.018-.044-.017-.043-.015-.044-.013-.044-.012-.044-.011-.045-.009-.044-.007-.045-.006-.045-.004-.045-.002-.045-.001-.045v-17l.001-.045.002-.045.004-.045.006-.045.007-.045.009-.044.011-.045.012-.044.013-.044.015-.044.017-.043.018-.044.02-.043.021-.043.023-.043.024-.043.026-.043.027-.042.029-.042.03-.042.032-.042.033-.042.034-.041.036-.041.037-.041.039-.041.04-.041.041-.04.043-.04.044-.04.046-.04.046-.039.049-.039.049-.039.051-.039.052-.038.053-.038.055-.038.056-.038.057-.037.058-.037.06-.037.061-.036.062-.036.063-.036.064-.036.066-.035.067-.035.068-.035.069-.035.07-.034.072-.034.072-.033.074-.033.151-.066.155-.064.159-.063.164-.061.167-.06.172-.059.176-.057.179-.056.184-.054.187-.053.19-.051.195-.05.198-.048.201-.046.204-.045.208-.043.211-.041.214-.04.217-.038.22-.036.223-.034.226-.032.228-.031.231-.028.234-.027.236-.024.238-.023.241-.02.243-.019.245-.016.247-.015.249-.012.251-.01.253-.008.255-.005.256-.004.258-.001.258.001zm-9.258 20.499v.01l.001.021.003.021.004.022.005.021.006.022.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.023.018.024.019.024.021.024.022.025.023.024.024.025.052.049.056.05.061.051.066.051.07.051.075.051.079.052.084.052.088.052.092.052.097.052.102.051.105.052.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.048.144.049.147.047.152.047.155.047.16.045.163.045.167.043.171.043.176.041.178.041.183.039.187.039.19.037.194.035.197.035.202.033.204.031.209.03.212.029.216.027.219.025.222.024.226.021.23.02.233.018.236.016.24.015.243.012.246.01.249.008.253.005.256.004.259.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.021.224-.024.22-.026.216-.027.212-.028.21-.031.205-.031.202-.034.198-.034.194-.036.191-.037.187-.039.183-.04.179-.04.175-.042.172-.043.168-.044.163-.045.16-.046.155-.046.152-.047.148-.048.143-.049.139-.049.136-.05.131-.05.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.053.083-.051.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.05.023-.024.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.023.01-.022.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.127l-.077.055-.08.053-.083.054-.085.053-.087.052-.09.052-.093.051-.095.05-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.045-.118.044-.12.043-.122.042-.124.042-.126.041-.128.04-.13.04-.132.038-.134.038-.135.037-.138.037-.139.035-.142.035-.143.034-.144.033-.147.032-.148.031-.15.03-.151.03-.153.029-.154.027-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.01-.179.008-.179.008-.181.006-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.006-.179-.008-.179-.008-.178-.01-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.027-.153-.029-.151-.03-.15-.03-.148-.031-.146-.032-.145-.033-.143-.034-.141-.035-.14-.035-.137-.037-.136-.037-.134-.038-.132-.038-.13-.04-.128-.04-.126-.041-.124-.042-.122-.042-.12-.044-.117-.043-.116-.045-.113-.045-.112-.046-.109-.047-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.05-.093-.052-.09-.051-.087-.052-.085-.053-.083-.054-.08-.054-.077-.054v4.127zm0-5.654v.011l.001.021.003.021.004.021.005.022.006.022.007.022.009.022.01.022.011.023.012.023.013.023.015.024.016.023.017.024.018.024.019.024.021.024.022.024.023.025.024.024.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.052.11.051.114.051.119.052.123.05.127.051.131.05.135.049.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.044.171.042.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.022.23.02.233.018.236.016.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.012.241-.015.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.048.139-.05.136-.049.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.051.051-.049.023-.025.023-.024.021-.025.02-.024.019-.024.018-.024.017-.024.015-.023.014-.023.013-.024.012-.022.01-.023.01-.023.008-.022.006-.022.006-.022.004-.021.004-.022.001-.021.001-.021v-4.139l-.077.054-.08.054-.083.054-.085.052-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.044-.118.044-.12.044-.122.042-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.035-.143.033-.144.033-.147.033-.148.031-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.009-.179.009-.179.007-.181.007-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.007-.179-.007-.179-.009-.178-.009-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.031-.146-.033-.145-.033-.143-.033-.141-.035-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.04-.126-.041-.124-.042-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.051-.093-.051-.09-.051-.087-.053-.085-.052-.083-.054-.08-.054-.077-.054v4.139zm0-5.666v.011l.001.02.003.022.004.021.005.022.006.021.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.024.018.023.019.024.021.025.022.024.023.024.024.025.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.051.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.043.171.043.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.021.23.02.233.018.236.017.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.013.241-.014.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.049.139-.049.136-.049.131-.051.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.049.023-.025.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.022.01-.023.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.153l-.077.054-.08.054-.083.053-.085.053-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.048-.105.048-.106.048-.109.046-.111.046-.114.046-.115.044-.118.044-.12.043-.122.043-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.034-.143.034-.144.033-.147.032-.148.032-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.024-.161.024-.162.023-.163.023-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.01-.178.01-.179.009-.179.007-.181.006-.182.006-.182.004-.184.003-.184.001-.185.001-.185-.001-.184-.001-.184-.003-.182-.004-.182-.006-.181-.006-.179-.007-.179-.009-.178-.01-.176-.01-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.023-.162-.023-.161-.024-.159-.024-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.032-.146-.032-.145-.033-.143-.034-.141-.034-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.041-.126-.041-.124-.041-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.048-.105-.048-.102-.048-.1-.05-.097-.049-.095-.051-.093-.051-.09-.052-.087-.052-.085-.053-.083-.053-.08-.054-.077-.054v4.153zm8.74-8.179l-.257.004-.254.005-.25.008-.247.011-.244.012-.241.014-.237.016-.233.018-.231.021-.226.022-.224.023-.22.026-.216.027-.212.028-.21.031-.205.032-.202.033-.198.034-.194.036-.191.038-.187.038-.183.04-.179.041-.175.042-.172.043-.168.043-.163.045-.16.046-.155.046-.152.048-.148.048-.143.048-.139.049-.136.05-.131.05-.126.051-.123.051-.118.051-.114.052-.11.052-.106.052-.101.052-.096.052-.092.052-.088.052-.083.052-.079.052-.074.051-.07.052-.065.051-.06.05-.056.05-.051.05-.023.025-.023.024-.021.024-.02.025-.019.024-.018.024-.017.023-.015.024-.014.023-.013.023-.012.023-.01.023-.01.022-.008.022-.006.023-.006.021-.004.022-.004.021-.001.021-.001.021.001.021.001.021.004.021.004.022.006.021.006.023.008.022.01.022.01.023.012.023.013.023.014.023.015.024.017.023.018.024.019.024.02.025.021.024.023.024.023.025.051.05.056.05.06.05.065.051.07.052.074.051.079.052.083.052.088.052.092.052.096.052.101.052.106.052.11.052.114.052.118.051.123.051.126.051.131.05.136.05.139.049.143.048.148.048.152.048.155.046.16.046.163.045.168.043.172.043.175.042.179.041.183.04.187.038.191.038.194.036.198.034.202.033.205.032.21.031.212.028.216.027.22.026.224.023.226.022.231.021.233.018.237.016.241.014.244.012.247.011.25.008.254.005.257.004.26.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.022.224-.023.22-.026.216-.027.212-.028.21-.031.205-.032.202-.033.198-.034.194-.036.191-.038.187-.038.183-.04.179-.041.175-.042.172-.043.168-.043.163-.045.16-.046.155-.046.152-.048.148-.048.143-.048.139-.049.136-.05.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.05.051-.05.023-.025.023-.024.021-.024.02-.025.019-.024.018-.024.017-.023.015-.024.014-.023.013-.023.012-.023.01-.023.01-.022.008-.022.006-.023.006-.021.004-.022.004-.021.001-.021.001-.021-.001-.021-.001-.021-.004-.021-.004-.022-.006-.021-.006-.023-.008-.022-.01-.022-.01-.023-.012-.023-.013-.023-.014-.023-.015-.024-.017-.023-.018-.024-.019-.024-.02-.025-.021-.024-.023-.024-.023-.025-.051-.05-.056-.05-.06-.05-.065-.051-.07-.052-.074-.051-.079-.052-.083-.052-.088-.052-.092-.052-.096-.052-.101-.052-.106-.052-.11-.052-.114-.052-.118-.051-.123-.051-.126-.051-.131-.05-.136-.05-.139-.049-.143-.048-.148-.048-.152-.048-.155-.046-.16-.046-.163-.045-.168-.043-.172-.043-.175-.042-.179-.041-.183-.04-.187-.038-.191-.038-.194-.036-.198-.034-.202-.033-.205-.032-.21-.031-.212-.028-.216-.027-.22-.026-.224-.023-.226-.022-.231-.021-.233-.018-.237-.016-.241-.014-.244-.012-.247-.011-.25-.008-.254-.005-.257-.004-.26-.001-.26.001z" transform="scale(.5)"></path></symbol></defs><defs><symbol height="24" width="24" id="clock"><path d="M12 2c5.514 0 10 4.486 10 10s-4.486 10-10 10-10-4.486-10-10 4.486-10 10-10zm0-2c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm5.848 12.459c.202.038.202.333.001.372-1.907.361-6.045 1.111-6.547 1.111-.719 0-1.301-.582-1.301-1.301 0-.512.77-5.447 1.125-7.445.034-.192.312-.181.343.014l.985 6.238 5.394 1.011z" transform="scale(.5)"></path></symbol></defs><defs><marker orient="auto-start-reverse" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="7.9" id="arrowhead"><path d="M -1 0 L 10 5 L 0 10 z"></path></marker></defs><defs><marker refY="4.5" refX="4" orient="auto" markerHeight="8" markerWidth="15" id="crosshead"><path style="stroke-dasharray: 0, 0;" d="M 1,2 L 6,7 M 6,2 L 1,7" stroke-width="1pt" stroke="#000000" fill="none"></path></marker></defs><defs><marker orient="auto" markerHeight="28" markerWidth="20" refY="7" refX="15.5" id="filled-head"><path d="M 18,7 L9,13 L14,7 L9,1 Z"></path></marker></defs><defs><marker orient="auto" markerHeight="40" markerWidth="60" refY="15" refX="15" id="sequencenumber"><circle r="6" cy="15" cx="15"></circle></marker></defs><g><rect class="activation0" height="896" width="10" stroke="#666" fill="#EDF2AE" y="117" x="331"></rect></g><g><rect class="activation0" height="214" width="10" stroke="#666" fill="#EDF2AE" y="373" x="790.5"></rect></g><g><line class="loopLine" y2="283" x2="911.5" y1="283" x1="321"></line><line class="loopLine" y2="597" x2="911.5" y1="283" x1="911.5"></line><line class="loopLine" y2="597" x2="911.5" y1="597" x1="321"></line><line class="loopLine" y2="597" x2="321" y1="283" x1="321"></line><polygon class="labelBox" points="321,283 371,283 371,296 362.6,303 321,303"></polygon><text style="font-size: 16px; font-weight: 400;" class="labelText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="296" x="346">alt</text><text style="font-size: 16px; font-weight: 400;" class="loopText" text-anchor="middle" y="301" x="641.25"><tspan x="641.25">["not input_path.endswith('.wav')"]</tspan></text></g><g><rect class="activation0" height="258" width="10" stroke="#666" fill="#EDF2AE" y="651" x="1000.5"></rect></g><g></g><g><rect class="activation0" height="50" width="10" stroke="#666" fill="#EDF2AE" y="807" x="1476.5"></rect></g><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="80" x="202">"POST /transcribir-audio/"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="117" x2="328" y1="117" x1="76"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="132" x="462">"os.makedirs('uploads')"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="169" x2="582" y1="169" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="184" x="462">"open(input_path, 'wb')"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="221" x2="582" y1="221" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="236" x="462">"file.read()"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="273" x2="582" y1="273" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="334" x="564">"convert_to_wav(input_path, wav_path)"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="371" x2="787.5" y1="371" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="386" x="801">"AudioSegment.from_file()"</text><path style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" d="M 800.5,423 C 860.5,413 860.5,453 800.5,443"></path><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="468" x="801">"audio.export(format='wav')"</text><path style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" d="M 800.5,505 C 860.5,495 860.5,535 800.5,525"></path><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="550" x="567">"WAV file created"</text><line style="stroke-dasharray: 3, 3; fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine1" y2="587" x2="344" y1="587" x1="790.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="612" x="669">"transcribe_audio(wav_path)"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="649" x2="997.5" y1="649" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="664" x="1137">"sr.Recognizer()"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="701" x2="1263.5" y1="701" x1="1010.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="716" x="1137">"recognizer.record(source)"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="753" x2="1263.5" y1="753" x1="1010.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="768" x="1242">"recognize_google(audio, language='es-ES')"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="805" x2="1473.5" y1="805" x1="1010.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="820" x="1245">"Spanish text"</text><line style="stroke-dasharray: 3, 3; fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine1" y2="857" x2="1013.5" y1="857" x1="1476.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="872" x="672">"texto"</text><line style="stroke-dasharray: 3, 3; fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine1" y2="909" x2="344" y1="909" x1="1000.5"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="924" x="462">"os.remove(input_path)"</text><line style="fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine0" y2="961" x2="582" y1="961" x1="341"></line><text style="font-size: 16px; font-weight: 400;" dy="1em" class="messageText" alignment-baseline="middle" dominant-baseline="middle" text-anchor="middle" y="976" x="205">"{'transcripcion': texto}"</text><line style="stroke-dasharray: 3, 3; fill: none;" marker-end="url(#arrowhead)" stroke="none" stroke-width="2" class="messageLine1" y2="1013" x2="79" y1="1013" x1="331"></line></svg></div><div class="bg-input-dark absolute right-2 top-2 rounded-sm p-1 opacity-0 transition-opacity group-hover:opacity-100"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256"><path d="M216,48V96a8,8,0,0,1-16,0V67.31l-42.34,42.35a8,8,0,0,1-11.32-11.32L188.69,56H160a8,8,0,0,1,0-16h48A8,8,0,0,1,216,48ZM98.34,146.34,56,188.69V160a8,8,0,0,0-16,0v48a8,8,0,0,0,8,8H96a8,8,0,0,0,0-16H67.31l42.35-42.34a8,8,0,0,0-11.32-11.32ZM208,152a8,8,0,0,0-8,8v28.69l-42.34-42.35a8,8,0,0,0-11.32,11.32L188.69,200H160a8,8,0,0,0,0,16h48a8,8,0,0,0,8-8V160A8,8,0,0,0,208,152ZM67.31,56H96a8,8,0,0,0,0-16H48a8,8,0,0,0-8,8V96a8,8,0,0,0,16,0V67.31l42.34,42.35a8,8,0,0,0,11.32-11.32Z"></path></svg></div></div></pre>
<p><strong>Sources</strong>: <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L27-L58" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">27-58</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py#L9-L22" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">9-22</span></a></p>
<h2 id="technology-stack-mapping" class="group" data-header="true">Technology Stack Mapping<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The system leverages the following key technologies, each mapped to their implementation in the codebase:</p>
<h3 id="core-dependencies" class="group" data-header="true">Core Dependencies<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><div class="group relative cursor-pointer overflow-x-auto rounded-md bg-[#f2f1f0] p-4 transition-colors hover:bg-[#ededed] dark:bg-[#1f1f1f] dark:hover:bg-[#242424]" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-r8s" data-state="closed" data-slot="dialog-trigger"><div class="flex justify-center"><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="0 0 897.28125 786" style="max-width: 100%; touch-action: none; user-select: none; cursor: grab; min-height: fit-content; max-height: 100%;" class="flowchart" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" id="mermaid-iapycqvv0kl" preserveAspectRatio="xMidYMid meet"><style>#mermaid-iapycqvv0kl{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-iapycqvv0kl .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-iapycqvv0kl .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-iapycqvv0kl .error-icon{fill:#dddddd;}#mermaid-iapycqvv0kl .error-text{fill:#222222;stroke:#222222;}#mermaid-iapycqvv0kl .edge-thickness-normal{stroke-width:1px;}#mermaid-iapycqvv0kl .edge-thickness-thick{stroke-width:3.5px;}#mermaid-iapycqvv0kl .edge-pattern-solid{stroke-dasharray:0;}#mermaid-iapycqvv0kl .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-iapycqvv0kl .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-iapycqvv0kl .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-iapycqvv0kl .marker{fill:#999;stroke:#999;}#mermaid-iapycqvv0kl .marker.cross{stroke:#999;}#mermaid-iapycqvv0kl svg{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:16px;}#mermaid-iapycqvv0kl p{margin:0;}#mermaid-iapycqvv0kl .label{font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;color:#333;}#mermaid-iapycqvv0kl .cluster-label text{fill:#444;}#mermaid-iapycqvv0kl .cluster-label span{color:#444;}#mermaid-iapycqvv0kl .cluster-label span p{background-color:transparent;}#mermaid-iapycqvv0kl .label text,#mermaid-iapycqvv0kl span{fill:#333;color:#333;}#mermaid-iapycqvv0kl .node rect,#mermaid-iapycqvv0kl .node circle,#mermaid-iapycqvv0kl .node ellipse,#mermaid-iapycqvv0kl .node polygon,#mermaid-iapycqvv0kl .node path{fill:#ffffff;stroke:#dddddd;stroke-width:1px;}#mermaid-iapycqvv0kl .rough-node .label text,#mermaid-iapycqvv0kl .node .label text,#mermaid-iapycqvv0kl .image-shape .label,#mermaid-iapycqvv0kl .icon-shape .label{text-anchor:middle;}#mermaid-iapycqvv0kl .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-iapycqvv0kl .rough-node .label,#mermaid-iapycqvv0kl .node .label,#mermaid-iapycqvv0kl .image-shape .label,#mermaid-iapycqvv0kl .icon-shape .label{text-align:center;}#mermaid-iapycqvv0kl .node.clickable{cursor:pointer;}#mermaid-iapycqvv0kl .root .anchor path{fill:#999!important;stroke-width:0;stroke:#999;}#mermaid-iapycqvv0kl .arrowheadPath{fill:#0b0b0b;}#mermaid-iapycqvv0kl .edgePath .path{stroke:#999;stroke-width:2.0px;}#mermaid-iapycqvv0kl .flowchart-link{stroke:#999;fill:none;}#mermaid-iapycqvv0kl .edgeLabel{background-color:#ffffff;text-align:center;}#mermaid-iapycqvv0kl .edgeLabel p{background-color:#ffffff;}#mermaid-iapycqvv0kl .edgeLabel rect{opacity:0.5;background-color:#ffffff;fill:#ffffff;}#mermaid-iapycqvv0kl .labelBkg{background-color:rgba(255, 255, 255, 0.5);}#mermaid-iapycqvv0kl .cluster rect{fill:#f8f8f8;stroke:#dddddd;stroke-width:1px;}#mermaid-iapycqvv0kl .cluster text{fill:#444;}#mermaid-iapycqvv0kl .cluster span{color:#444;}#mermaid-iapycqvv0kl div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:ui-sans-serif,-apple-system,system-ui,Segoe UI,Helvetica;font-size:12px;background:#dddddd;border:1px solid hsl(0, 0%, 76.6666666667%);border-radius:2px;pointer-events:none;z-index:100;}#mermaid-iapycqvv0kl .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-iapycqvv0kl rect.text{fill:none;stroke-width:0;}#mermaid-iapycqvv0kl .icon-shape,#mermaid-iapycqvv0kl .image-shape{background-color:#ffffff;text-align:center;}#mermaid-iapycqvv0kl .icon-shape p,#mermaid-iapycqvv0kl .image-shape p{background-color:#ffffff;padding:2px;}#mermaid-iapycqvv0kl .icon-shape rect,#mermaid-iapycqvv0kl .image-shape rect{opacity:0.5;background-color:#ffffff;fill:#ffffff;}#mermaid-iapycqvv0kl :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="5" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="mermaid-iapycqvv0kl_flowchart-v2-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"><g data-look="classic" id="subGraph2" class="cluster"><rect height="276" width="605.625" y="8" x="8" style=""></rect><g transform="translate(242.68359375, 8)" class="cluster-label"><foreignobject height="24" width="136.2578125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>System Integration</p></span></div></foreignobject></g></g><g data-look="classic" id="subGraph1" class="cluster"><rect height="148" width="533.2109375" y="342.25" x="356.0703125" style=""></rect><g transform="translate(537.29296875, 342.25)" class="cluster-label"><foreignobject height="24" width="170.765625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Audio Processing Stack</p></span></div></foreignobject></g></g></g><g class="edgePaths"><path marker-end="url(#mermaid-iapycqvv0kl_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_pydub_lib_speech_lib_0" d="M588.625,416.25L592.792,416.25C596.958,416.25,605.292,416.25,613.625,416.25C621.958,416.25,630.292,416.25,637.958,416.25C645.625,416.25,652.625,416.25,656.125,416.25L659.625,416.25"></path><path marker-end="url(#mermaid-iapycqvv0kl_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_os_mod_uuid_mod_0" d="M251.012,82L264.355,82C277.698,82,304.384,82,321.894,82C339.404,82,347.737,82,360.263,82C372.789,82,389.508,82,397.867,82L406.227,82"></path><path marker-end="url(#mermaid-iapycqvv0kl_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_sys_mod_pydub_lib_0" d="M265.465,210L276.399,210C287.333,210,309.202,210,324.303,210C339.404,210,347.737,210,368.955,237.31C390.173,264.619,424.276,319.238,441.327,346.548L458.379,373.857"></path></g><g class="edgeLabels"><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g></g><g class="nodes"><g transform="translate(25, 311)" class="root"><g class="clusters"><g data-look="classic" id="subGraph0" class="cluster"><rect height="459" width="273.0703125" y="8" x="8" style=""></rect><g transform="translate(63.203125, 8)" class="cluster-label"><foreignobject height="24" width="162.6640625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>Web Framework Stack</p></span></div></foreignobject></g></g></g><g class="edgePaths"><path marker-end="url(#mermaid-iapycqvv0kl_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_fastapi_multipart_0" d="M144.535,276.5L144.535,282.75C144.535,289,144.535,301.5,144.535,313.333C144.535,325.167,144.535,336.333,144.535,341.917L144.535,347.5"></path><path marker-end="url(#mermaid-iapycqvv0kl_flowchart-v2-pointEnd)" style="" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_uvicorn_fastapi_0" d="M144.535,123.5L144.535,129.75C144.535,136,144.535,148.5,144.535,160.333C144.535,172.167,144.535,183.333,144.535,188.917L144.535,194.5"></path></g><g class="edgeLabels"><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignobject height="0" width="0"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" class="labelBkg" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignobject></g></g></g><g class="nodes"><g transform="translate(144.53515625, 237.5)" id="flowchart-fastapi-0" class="node default"><rect height="78" width="167.2265625" y="-39" x="-83.61328125" style="" class="basic label-container"></rect><g transform="translate(-53.61328125, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="107.2265625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>fastapi<br>FastAPI() class</p></span></div></foreignobject></g></g><g transform="translate(144.53515625, 390.5)" id="flowchart-multipart-2" class="node default"><rect height="78" width="203.0703125" y="-39" x="-101.53515625" style="" class="basic label-container"></rect><g transform="translate(-71.53515625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="143.0703125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>python-multipart<br>UploadFile handling</p></span></div></foreignobject></g></g><g transform="translate(144.53515625, 84.5)" id="flowchart-uvicorn-1" class="node default"><rect height="78" width="153.625" y="-39" x="-76.8125" style="" class="basic label-container"></rect><g transform="translate(-46.8125, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="93.625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>uvicorn<br>uvicorn.run()</p></span></div></foreignobject></g></g></g></g><g transform="translate(484.84765625, 416.25)" id="flowchart-pydub_lib-3" class="node default"><rect height="78" width="207.5546875" y="-39" x="-103.77734375" style="" class="basic label-container"></rect><g transform="translate(-73.77734375, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="147.5546875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>pydub<br>AudioSegment class</p></span></div></foreignobject></g></g><g transform="translate(763.953125, 416.25)" id="flowchart-speech_lib-4" class="node default"><rect height="78" width="200.65625" y="-39" x="-100.328125" style="" class="basic label-container"></rect><g transform="translate(-70.328125, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="140.65625"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>SpeechRecognition<br>sr.Recognizer()</p></span></div></foreignobject></g></g><g transform="translate(169.53515625, 82)" id="flowchart-os_mod-5" class="node default"><rect height="78" width="162.953125" y="-39" x="-81.4765625" style="" class="basic label-container"></rect><g transform="translate(-51.4765625, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="102.953125"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>os module<br>file operations</p></span></div></foreignobject></g></g><g transform="translate(484.84765625, 82)" id="flowchart-uuid_mod-6" class="node default"><rect height="78" width="149.2421875" y="-39" x="-74.62109375" style="" class="basic label-container"></rect><g transform="translate(-44.62109375, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="89.2421875"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>uuid module<br>uuid.uuid4()</p></span></div></foreignobject></g></g><g transform="translate(169.53515625, 210)" id="flowchart-sys_mod-7" class="node default"><rect height="78" width="191.859375" y="-39" x="-95.9296875" style="" class="basic label-container"></rect><g transform="translate(-65.9296875, -24)" style="" class="label"><rect></rect><foreignobject height="48" width="131.859375"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p>sys module<br>sys.path.append()</p></span></div></foreignobject></g></g></g></g></g></svg></div><div class="bg-input-dark absolute right-2 top-2 rounded-sm p-1 opacity-0 transition-opacity group-hover:opacity-100"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256"><path d="M216,48V96a8,8,0,0,1-16,0V67.31l-42.34,42.35a8,8,0,0,1-11.32-11.32L188.69,56H160a8,8,0,0,1,0-16h48A8,8,0,0,1,216,48ZM98.34,146.34,56,188.69V160a8,8,0,0,0-16,0v48a8,8,0,0,0,8,8H96a8,8,0,0,0,0-16H67.31l42.35-42.34a8,8,0,0,0-11.32-11.32ZM208,152a8,8,0,0,0-8,8v28.69l-42.34-42.35a8,8,0,0,0-11.32,11.32L188.69,200H160a8,8,0,0,0,0,16h48a8,8,0,0,0,8-8V160A8,8,0,0,0,208,152ZM67.31,56H96a8,8,0,0,0,0-16H48a8,8,0,0,0-8,8V96a8,8,0,0,0,16,0V67.31l42.34,42.35a8,8,0,0,0,11.32-11.32Z"></path></svg></div></div></pre>
<p><strong>Sources</strong>: <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/requirements.txt#L1-L6" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>requirements.txt</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-6</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L1-L10" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-10</span></a></p>
<h3 id="module-structure" class="group" data-header="true">Module Structure<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<p>The application follows a modular architecture with clear separation of concerns:</p>
<ul>
<li><strong><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">main.py</code></strong>: FastAPI application entry point with <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">uvicorn.run()</code> server configuration</li>
<li><strong><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">iaModels/transcribir.py</code></strong>: Core audio processing module containing <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">convert_to_wav()</code> and <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">transcribe_audio()</code> functions</li>
<li><strong><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">uploads/</code> directory</strong>: Temporary file storage managed by <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">os.makedirs()</code> and <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">os.remove()</code> calls</li>
<li><strong>CORS origins</strong>: Configured for <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">localhost:3000</code> and <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">solvo-audio-ai.vercel.app</code> domains</li>
</ul>
<p>The system is specifically optimized for Spanish language transcription through the <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">language="es-ES"</code> parameter in the Google Speech Recognition API calls.</p>
<p><strong>Sources</strong>: <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L8-L10" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">8-10</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/main.py#L18-L21" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>main.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">18-21</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/iaModels/transcribir.py#L18-L18" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>iaModels/transcribir.py</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">18</span></a> <a href="https://github.com/thealeglynne/SOLVO_audio_AI_back/blob/12cfb168/.gitignore#L4-L8" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>.gitignore</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">4-8</span></a></p></div></div></div></div></div></div><div class="hidden overflow-hidden transition-[border-radius] xl:sticky xl:right-0 xl:top-20 xl:block xl:h-[calc(100vh-82px)] xl:w-64 xl:flex-shrink-0 2xl:w-72" style="scrollbar-width: none;"><div class="flex max-h-full w-full flex-shrink-0 flex-col py-6 pt-0 text-sm lg:pb-4 lg:pt-8 xl:w-64 2xl:w-72" style="scrollbar-color: var(--color-night) transparent;"><div><div class="relative mx-4 my-4 rounded-md border border-neutral-200 bg-neutral-100 p-3 text-sm text-neutral-600 dark:border-neutral-800 dark:bg-neutral-900 dark:text-neutral-400"><button class="absolute right-2 top-2 rounded-sm p-1 opacity-70 transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-neutral-400 focus:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M205.66,194.34a8,8,0,0,1-11.32,11.32L128,139.31,61.66,205.66a8,8,0,0,1-11.32-11.32L116.69,128,50.34,61.66A8,8,0,0,1,61.66,50.34L128,116.69l66.34-66.35a8,8,0,0,1,11.32,11.32L139.31,128Z"></path></svg><span class="sr-only">Dismiss</span></button><p class="text-sm font-medium">Refresh this wiki</p><button class="mt-2 flex items-center gap-1 rounded-md bg-neutral-200 px-2 py-1 text-sm font-medium text-neutral-700 transition-colors hover:bg-neutral-300 dark:bg-neutral-800 dark:text-neutral-300 dark:hover:bg-neutral-700">Enter email to refresh</button></div></div><h3 class="px-4 pb-5 text-lg font-medium leading-none">On this page</h3><ul class="min-h-0 flex-1 space-y-3 overflow-y-auto p-4 pt-0" style="scrollbar-width: none;"><li class=""><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#overview" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Overview</a></li><li class="ml-3"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#purpose-and-scope" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Purpose and Scope</a></li><li class="ml-3"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#system-architecture" class="hover:text-primary pr-1 font-normal transition-all text-secondary">System Architecture</a></li><li class="ml-3"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#core-components" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Core Components</a></li><li class="ml-6"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#request-processing-flow" class="hover:text-primary pr-1 transition-all text-primary font-medium">Request Processing Flow</a></li><li class="ml-3"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#technology-stack-mapping" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Technology Stack Mapping</a></li><li class="ml-6"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#core-dependencies" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Core Dependencies</a></li><li class="ml-6"><a href="https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back/1-overview#module-structure" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Module Structure</a></li></ul></div></div><div class="pointer-events-none fixed bottom-2 left-2 right-2 mt-2 md:bottom-4 md:left-0 md:right-0"><div class="z-10 mx-auto max-w-3xl"><form class="z-20 w-full rounded-md backdrop-blur-md transition-shadow [pointer-events:all] focus-within:ring-[.5px] focus-within:ring-indigo-300/40 bg-component/70 border border-indigo-300/20 shadow-lg shadow-indigo-500/20 [backdrop-filter:blur(8px)]"><div class=""><div class="relative text-base font-normal"><div class="relative px-3 pt-3"><div class="pointer-events-none absolute left-3 right-3 top-3 ml-px flex w-full overflow-hidden text-base" aria-hidden="true"><div class="flex items-center gap-1 overflow-hidden text-wrap opacity-60">Ask Devin about thealeglynne/SOLVO_audio_AI_back</div></div><textarea placeholder="" rows="2" class="w-full resize-none rounded-none bg-transparent text-white focus:outline-none text-base"></textarea></div></div></div><div class="dark:border-border flex h-12 items-center justify-between border-t-[0.5px] border-[#c0c0c0] p-3 pl-1.5"><div class="flex items-center text-sm gap-4"><button data-slot="button" class="font-medium disabled:pointer-events-none disabled:opacity-50 shrink-0 focus-visible:border-ring aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:hover:bg-accent/50 has-[&gt;svg]:px-3 data-[placeholder]:text-muted-foreground [&amp;_svg:not([class*=&#39;text-&#39;])]:text-muted-foreground focus-visible:ring-ring/50 hover:bg-accent hover:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex h-9 w-fit cursor-pointer items-center justify-between gap-2 whitespace-nowrap rounded-md bg-transparent px-3 py-2 text-sm text-neutral-700 outline-none transition-all focus-visible:ring-[3px] dark:text-neutral-400 [&amp;_svg:not([class*=&#39;size-&#39;])]:size-4 [&amp;_svg]:pointer-events-none [&amp;_svg]:shrink-0" data-selected="true" type="button" id="radix-r8j" aria-haspopup="menu" aria-expanded="false" data-state="closed"><div class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="size-4 text-current"><path d="M213.85,125.46l-112,120a8,8,0,0,1-13.69-7l14.66-73.33L45.19,143.49a8,8,0,0,1-3-13l112-120a8,8,0,0,1,13.69,7L153.18,90.9l57.63,21.61a8,8,0,0,1,3,12.95Z"></path></svg><span>Fast</span></div><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="size-4 text-current opacity-50"><path d="M213.66,101.66l-80,80a8,8,0,0,1-11.32,0l-80-80A8,8,0,0,1,53.66,90.34L128,164.69l74.34-74.35a8,8,0,0,1,11.32,11.32Z"></path></svg></button></div><div class="flex items-center gap-2"><button class="rounded-full bg-[#e0e0e0] p-1 text-neutral-400 transition-colors dark:bg-neutral-700" disabled="" data-state="closed" data-slot="tooltip-trigger"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 256 256"><path d="M221.66,133.66l-72,72a8,8,0,0,1-11.32-11.32L196.69,136H40a8,8,0,0,1,0-16H196.69L138.34,61.66a8,8,0,0,1,11.32-11.32l72,72A8,8,0,0,1,221.66,133.66Z"></path></svg></button></div></div></form></div></div></div></div></div></div><!--/$--><script src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/webpack-acbbbb548492d4a6.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[51709,[\"9453\",\"static/chunks/b1298b8d-549c141f97a3b262.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"8970\",\"static/chunks/378e5a93-3b0f971d3611a8a5.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"1585\",\"static/chunks/f7f68e2d-40290491c524df5c.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4420\",\"static/chunks/4420-863691215dce8f1b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6417\",\"static/chunks/6417-34cc3208366c5e5f.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"3224\",\"static/chunks/3224-7e9887ea92eab174.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6967\",\"static/chunks/6967-c4b815e71e97ed18.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4348\",\"static/chunks/4348-824485747071bae4.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"7177\",\"static/chunks/app/layout-7e3a468900582ca8.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\"],\"RootProvider\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n6:I[90894,[],\"ClientPageRoot\"]\n7:I[87667,[\"9453\",\"static/chunks/b1298b8d-549c141f97a3b262.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"8970\",\"static/chunks/378e5a93-3b0f971d3611a8a5.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"1585\",\"static/chunks/f7f68e2d-40290491c524df5c.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4129\",\"static/chunks/7bf36345-06f80506190927ed.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2545\",\"static/chunks/c16f53c3-1a60b9b77b3e1d4b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4420\",\"static/chunks/4420-863691215dce8f1b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6417\",\"static/chunks/6417-34cc3208366c5e5f.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"3224\",\"static/chunks/3224-7e9887ea92eab174.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2249\",\"static/chunks/2249-342d7235b3a68051.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"9970\",\"static/chunks/9970-31fea4ade6367f07.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6967\",\"static/chunks/6967-c4b815e71e97ed18.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4348\",\"static/chunks/4348-824485747071bae4.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"1769\",\"static/chunks/1769-6bbc7ae2dcadfa9c.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"655\",\"static/c"])</script><script>self.__next_f.push([1,"hunks/655-b5574efc1f81bad2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4154\",\"static/chunks/4154-f7634cd651686b21.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6835\",\"static/chunks/6835-f6c6803cb93f7a72.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6638\",\"static/chunks/6638-d6e730ba183d02e2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4870\",\"static/chunks/4870-eef7f9c14ec0bbe8.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"3285\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/%5B%5B...wikiRoutes%5D%5D/page-dd78b4aea7a92e3b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\"],\"default\"]\na:I[59665,[],\"OutletBoundary\"]\nd:I[59665,[],\"ViewportBoundary\"]\nf:I[59665,[],\"MetadataBoundary\"]\n11:I[26614,[],\"\"]\n:HL[\"/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/de70bee13400563f.css?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"style\"]\n:HL[\"/_next/static/css/abd485da6d9b13f7.css?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"jMEK13QJGqf_1Y1nXTVHm\",\"p\":\"\",\"c\":[\"\",\"thealeglynne\",\"SOLVO_audio_AI_back\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"org\",\"thealeglynne\",\"d\"],{\"children\":[[\"repo\",\"SOLVO_audio_AI_back\",\"d\"],{\"children\":[[\"wikiRoutes\",\"\",\"oc\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/de70bee13400563f.css?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/abd485da6d9b13f7.css?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{}],[\"$\",\"body\",null,{\"className\":\"__variable_188709 font-geist-sans relative min-h-screen __variable_9a8899 bg-background antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]]}],{\"children\":[[\"org\",\"thealeglynne\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"repo\",\"SOLVO_audio_AI_back\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,\"$L5\"]}],{\"children\":[[\"wikiRoutes\",\"\",\"oc\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L6\",null,{\"Component\":\"$7\",\"searchParams\":{},\"params\":{\"org\":\"thealeglynne\",\"repo\":\"SOLVO_audio_AI_back\"},\"promises\":[\"$@8\",\"$@9\"]}],\"$undefined\",null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",null]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"7CZ0MW1oGiPvWgncXV-VY\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"8:{}\n9:{\"org\":\"thealeglynne\",\"repo\":\"SOLVO_audio_AI_back\"}\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"12:I[87437,[\"9453\",\"static/chunks/b1298b8d-549c141f97a3b262.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"8970\",\"static/chunks/378e5a93-3b0f971d3611a8a5.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"1585\",\"static/chunks/f7f68e2d-40290491c524df5c.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4420\",\"static/chunks/4420-863691215dce8f1b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6417\",\"static/chunks/6417-34cc3208366c5e5f.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2249\",\"static/chunks/2249-342d7235b3a68051.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"9970\",\"static/chunks/9970-31fea4ade6367f07.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4348\",\"static/chunks/4348-824485747071bae4.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"655\",\"static/chunks/655-b5574efc1f81bad2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"3449\",\"static/chunks/3449-11980c1727988a9a.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2307\",\"static/chunks/2307-135a4a3deb6dd18b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"736\",\"static/chunks/736-daf66278216745a2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2933\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/layout-fdd52767083d8076.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\"],\"HeaderWrapperWithSuspense\"]\n13:I[93403,[\"9453\",\"static/chunks/b1298b8d-549c141f97a3b262.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"8970\",\"static/chunks/378e5a93-3b0f971d3611a8a5.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"1585\",\"static/chunks/f7f68e2d-40290491c524df5c.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4420\",\"static/chunks/4420-863691215dce8f1b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"6417\",\"static/chunks/6417-34cc3208366c5e5f.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2249\",\"static/chunks/2249-342d7235b3a68051.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"9970\",\"static/chunks/9970-31fea4ade6367f07.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"4348\",\"static/chunks/4348-824485747071bae4.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"655\",\"static/chunks/655-b5574efc1f81bad2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"3449\",\"static/chunks/3449-11980c1727988a9a.js?dpl=dpl_AUat9smjcfRWLGS11Zovj246"])</script><script>self.__next_f.push([1,"8Een\",\"2307\",\"static/chunks/2307-135a4a3deb6dd18b.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"736\",\"static/chunks/736-daf66278216745a2.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\",\"2933\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/layout-fdd52767083d8076.js?dpl=dpl_AUat9smjcfRWLGS11Zovj2468Een\"],\"WikiContextProvider\"]\n14:T1748,"])</script><script>self.__next_f.push([1,"# Overview\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [.gitignore](.gitignore)\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n- [main.py](main.py)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system accepts audio uploads in various formats (MP3, M4A, WAV), converts them to standardized WAV format when necessary, and returns Spanish text transcriptions.\n\nFor detailed documentation on specific components, see [FastAPI Web Service](#2) for the web layer implementation, [Audio Processing Engine](#3) for the core transcription logic, and [Development \u0026 Deployment](#5) for setup instructions.\n\n## System Architecture\n\nThe following diagram shows the core system architecture and maps high-level concepts to their corresponding code entities:\n\n```mermaid\ngraph TB\n    subgraph \"FastAPI Application Layer\"\n        app[\"FastAPI()\\nmain.py:13\"]\n        cors[\"CORSMiddleware\\nmain.py:16-25\"]\n        endpoint[\"/transcribir-audio/\\nmain.py:27\"]\n    end\n    \n    subgraph \"File Processing Pipeline\"\n        uploads_dir[\"uploads/\\nmain.py:30\"]\n        uuid_gen[\"uuid.uuid4()\\nmain.py:34\"]\n        file_write[\"UploadFile.read()\\nmain.py:38\"]\n    end\n    \n    subgraph \"iaModels Package\"\n        convert_func[\"convert_to_wav()\\ntranscribir.py:5\"]\n        transcribe_func[\"transcribe_audio()\\ntranscribir.py:9\"]\n        pydub[\"AudioSegment\\ntranscribir.py:6\"]\n        speech_rec[\"sr.Recognizer()\\ntranscribir.py:13\"]\n    end\n    \n    subgraph \"External Services\"\n        google_api[\"recognize_google()\\ntranscribir.py:18\"]\n    end\n    \n    app --\u003e cors\n    app --\u003e endpoint\n    endpoint --\u003e uploads_dir\n    endpoint --\u003e uuid_gen\n    endpoint --\u003e file_write\n    endpoint --\u003e convert_func\n    endpoint --\u003e transcribe_func\n    convert_func --\u003e pydub\n    transcribe_func --\u003e speech_rec\n    speech_rec --\u003e google_api\n```\n\n**Sources**: [main.py:1-63](), [iaModels/transcribir.py:1-23]()\n\n## Core Components\n\nThe system consists of three primary components that work together to provide audio transcription services:\n\n| Component | Code Entity | Primary Functions | Location |\n|-----------|-------------|-------------------|----------|\n| **Web Service Layer** | `FastAPI()` app instance | HTTP request handling, CORS, file uploads | [main.py:13]() |\n| **Audio Processing** | `iaModels` package | Format conversion, speech recognition | [iaModels/transcribir.py]() |\n| **External Integration** | `sr.recognize_google()` | Spanish language transcription | [iaModels/transcribir.py:18]() |\n\n### Request Processing Flow\n\nThis diagram shows the actual function call sequence for processing audio transcription requests:\n\n```mermaid\nsequenceDiagram\n    participant client as \"HTTP Client\"\n    participant endpoint as \"transcribir_audio_endpoint()\"\n    participant filesystem as \"os.makedirs/open\"\n    participant converter as \"convert_to_wav()\"\n    participant transcriber as \"transcribe_audio()\"\n    participant recognizer as \"sr.Recognizer()\"\n    participant google as \"recognize_google()\"\n    \n    client-\u003e\u003e+endpoint: \"POST /transcribir-audio/\"\n    endpoint-\u003e\u003efilesystem: \"os.makedirs('uploads')\"\n    endpoint-\u003e\u003efilesystem: \"open(input_path, 'wb')\"\n    endpoint-\u003e\u003efilesystem: \"file.read()\"\n    \n    alt \"not input_path.endswith('.wav')\"\n        endpoint-\u003e\u003e+converter: \"convert_to_wav(input_path, wav_path)\"\n        converter-\u003e\u003econverter: \"AudioSegment.from_file()\"\n        converter-\u003e\u003econverter: \"audio.export(format='wav')\"\n        converter--\u003e\u003e-endpoint: \"WAV file created\"\n    end\n    \n    endpoint-\u003e\u003e+transcriber: \"transcribe_audio(wav_path)\"\n    transcriber-\u003e\u003e+recognizer: \"sr.Recognizer()\"\n    transcriber-\u003e\u003erecognizer: \"recognizer.record(source)\"\n    transcriber-\u003e\u003e+google: \"recognize_google(audio, language='es-ES')\"\n    google--\u003e\u003e-transcriber: \"Spanish text\"\n    transcriber--\u003e\u003e-endpoint: \"texto\"\n    \n    endpoint-\u003e\u003efilesystem: \"os.remove(input_path)\"\n    endpoint--\u003e\u003e-client: \"{'transcripcion': texto}\"\n```\n\n**Sources**: [main.py:27-58](), [iaModels/transcribir.py:9-22]()\n\n## Technology Stack Mapping\n\nThe system leverages the following key technologies, each mapped to their implementation in the codebase:\n\n### Core Dependencies\n\n```mermaid\ngraph LR\n    subgraph \"Web Framework Stack\"\n        fastapi[\"fastapi\\nFastAPI() class\"]\n        uvicorn[\"uvicorn\\nuvicorn.run()\"]\n        multipart[\"python-multipart\\nUploadFile handling\"]\n    end\n    \n    subgraph \"Audio Processing Stack\"\n        pydub_lib[\"pydub\\nAudioSegment class\"]\n        speech_lib[\"SpeechRecognition\\nsr.Recognizer()\"]\n    end\n    \n    subgraph \"System Integration\"\n        os_mod[\"os module\\nfile operations\"]\n        uuid_mod[\"uuid module\\nuuid.uuid4()\"]\n        sys_mod[\"sys module\\nsys.path.append()\"]\n    end\n    \n    fastapi --\u003e multipart\n    uvicorn --\u003e fastapi\n    pydub_lib --\u003e speech_lib\n    os_mod --\u003e uuid_mod\n    sys_mod --\u003e pydub_lib\n```\n\n**Sources**: [requirements.txt:1-6](), [main.py:1-10]()\n\n### Module Structure\n\nThe application follows a modular architecture with clear separation of concerns:\n\n- **`main.py`**: FastAPI application entry point with `uvicorn.run()` server configuration\n- **`iaModels/transcribir.py`**: Core audio processing module containing `convert_to_wav()` and `transcribe_audio()` functions\n- **`uploads/` directory**: Temporary file storage managed by `os.makedirs()` and `os.remove()` calls\n- **CORS origins**: Configured for `localhost:3000` and `solvo-audio-ai.vercel.app` domains\n\nThe system is specifically optimized for Spanish language transcription through the `language=\"es-ES\"` parameter in the Google Speech Recognition API calls.\n\n**Sources**: [main.py:8-10](), [main.py:18-21](), [iaModels/transcribir.py:18](), [.gitignore:4-8]()"])</script><script>self.__next_f.push([1,"15:T23c5,"])</script><script>self.__next_f.push([1,"# System Components\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document provides an overview of the main components and modules that make up the SOLVO Audio AI Backend transcription service. It covers the core architectural elements, their responsibilities, and how they interact to process audio files and return Spanish transcriptions.\n\nFor detailed information about the technology stack and dependencies, see [Technology Stack](#1.2). For specific implementation details of the FastAPI web service, see [FastAPI Web Service](#2). For audio processing engine details, see [Audio Processing Engine](#3).\n\n## Component Architecture Overview\n\nThe SOLVO Audio AI Backend consists of several distinct components that work together to provide audio transcription functionality:\n\n```mermaid\ngraph TB\n    subgraph \"WebService\" [\"Web Service Layer\"]\n        FastAPIApp[\"FastAPI Application\u003cbr/\u003emain.py\"]\n        CORSMiddleware[\"CORSMiddleware\u003cbr/\u003eCross-origin support\"]\n        UvicornServer[\"Uvicorn ASGI Server\u003cbr/\u003ePort 10000\"]\n    end\n    \n    subgraph \"AudioModule\" [\"Audio Processing Module\"]\n        TranscribirPy[\"transcribir.py\u003cbr/\u003eiaModels/\"]\n        ConvertFunction[\"convert_to_wav()\u003cbr/\u003eFormat conversion\"]\n        TranscribeFunction[\"transcribe_audio()\u003cbr/\u003eSpeech recognition\"]\n    end\n    \n    subgraph \"FileSystem\" [\"File Management\"]\n        UploadsDir[\"uploads/ directory\u003cbr/\u003eTemporary storage\"]\n        UUIDGeneration[\"uuid.uuid4().hex\u003cbr/\u003eUnique filenames\"]\n        FileCleanup[\"os.remove()\u003cbr/\u003eAutomatic cleanup\"]\n    end\n    \n    subgraph \"ExternalAPIs\" [\"External Service Integration\"]\n        GoogleSpeechAPI[\"Google Speech Recognition\u003cbr/\u003erecognize_google()\"]\n        PyDubLibrary[\"PyDub AudioSegment\u003cbr/\u003eFormat conversion\"]\n    end\n    \n    FastAPIApp --\u003e TranscribirPy\n    FastAPIApp --\u003e UploadsDir\n    TranscribirPy --\u003e ConvertFunction\n    TranscribirPy --\u003e TranscribeFunction\n    ConvertFunction --\u003e PyDubLibrary\n    TranscribeFunction --\u003e GoogleSpeechAPI\n    UploadsDir --\u003e UUIDGeneration\n    UploadsDir --\u003e FileCleanup\n    \n    FastAPIApp --\u003e CORSMiddleware\n    UvicornServer --\u003e FastAPIApp\n```\n\n**Sources:** [main.py:1-63](), [iaModels/transcribir.py:1-23]()\n\n## Core Web Service Components\n\nThe web service layer handles HTTP requests and orchestrates the audio processing pipeline:\n\n| Component | File Location | Primary Responsibility |\n|-----------|---------------|------------------------|\n| `FastAPI` app instance | [main.py:13]() | Main application object and request routing |\n| `CORSMiddleware` | [main.py:16-25]() | Cross-origin request handling for web frontends |\n| `/transcribir-audio/` endpoint | [main.py:27-58]() | Audio file upload and transcription orchestration |\n| `uvicorn` server | [main.py:61-62]() | ASGI server for hosting the FastAPI application |\n\n### FastAPI Application Structure\n\n```mermaid\ngraph LR\n    subgraph \"FastAPIInstance\" [\"app = FastAPI()\"]\n        CORSConfig[\"CORSMiddleware\u003cbr/\u003elocalhost:3000\u003cbr/\u003esolvo-audio-ai.vercel.app\"]\n        PostEndpoint[\"/transcribir-audio/\u003cbr/\u003ePOST endpoint\"]\n        UploadFileParam[\"UploadFile parameter\u003cbr/\u003efile: UploadFile = File(...)\"]\n    end\n    \n    subgraph \"RequestFlow\" [\"Request Processing\"]\n        FileUpload[\"file.read()\u003cbr/\u003eMultipart data\"]\n        TempStorage[\"uploads/{uuid}.{ext}\u003cbr/\u003eTemporary file\"]\n        AudioProcessing[\"iaModels functions\u003cbr/\u003econvert_to_wav, transcribe_audio\"]\n        JSONResponse[\"{'transcripcion': texto}\u003cbr/\u003eResponse format\"]\n    end\n    \n    PostEndpoint --\u003e UploadFileParam\n    UploadFileParam --\u003e FileUpload\n    FileUpload --\u003e TempStorage\n    TempStorage --\u003e AudioProcessing\n    AudioProcessing --\u003e JSONResponse\n```\n\n**Sources:** [main.py:13-25](), [main.py:27-58]()\n\n## Audio Processing Module Components\n\nThe `iaModels` package contains the core audio processing functionality:\n\n| Function | File Location | Purpose |\n|----------|---------------|---------|\n| `convert_to_wav()` | [iaModels/transcribir.py:5-7]() | Audio format standardization using PyDub |\n| `transcribe_audio()` | [iaModels/transcribir.py:9-22]() | Spanish speech recognition via Google API |\n\n### Audio Processing Pipeline\n\n```mermaid\nflowchart TD\n    InputFile[\"Input Audio File\u003cbr/\u003eVarious formats\"]\n    FormatCheck{\"file.endswith('.wav')?\u003cbr/\u003emain.py:41\"}\n    ConvertToWav[\"convert_to_wav(input_path, wav_path)\u003cbr/\u003etranscribir.py:5-7\"]\n    AudioSegmentLoad[\"AudioSegment.from_file(input_path)\u003cbr/\u003ePyDub processing\"]\n    WavExport[\"audio.export(output_path, format='wav')\u003cbr/\u003eFormat conversion\"]\n    \n    TranscribeAudio[\"transcribe_audio(wav_path)\u003cbr/\u003etranscribir.py:9-22\"]\n    SpeechRecognizer[\"sr.Recognizer()\u003cbr/\u003eSpeechRecognition setup\"]\n    AudioFileLoad[\"sr.AudioFile(file_path)\u003cbr/\u003eWAV file loading\"]\n    GoogleRecognition[\"recognizer.recognize_google(audio, language='es-ES')\u003cbr/\u003eAPI call\"]\n    \n    InputFile --\u003e FormatCheck\n    FormatCheck --\u003e|No| ConvertToWav\n    FormatCheck --\u003e|Yes| TranscribeAudio\n    ConvertToWav --\u003e AudioSegmentLoad\n    AudioSegmentLoad --\u003e WavExport\n    WavExport --\u003e TranscribeAudio\n    TranscribeAudio --\u003e SpeechRecognizer\n    SpeechRecognizer --\u003e AudioFileLoad\n    AudioFileLoad --\u003e GoogleRecognition\n```\n\n**Sources:** [main.py:40-48](), [iaModels/transcribir.py:5-22]()\n\n## File Management Components\n\nThe system implements temporary file management for processing uploaded audio:\n\n| Component | Implementation | Responsibility |\n|-----------|----------------|----------------|\n| Upload directory creation | [main.py:30]() | `os.makedirs(\"uploads\", exist_ok=True)` |\n| Unique filename generation | [main.py:34]() | `f\"{uuid.uuid4().hex}.{ext}\"` |\n| Temporary file storage | [main.py:35-38]() | Binary file writing in `uploads/` directory |\n| File cleanup | [main.py:51-53]() | `os.remove()` for temporary files |\n\n### File Lifecycle Management\n\n```mermaid\nstateDiagram-v2\n    [*] --\u003e FileUploaded: \"UploadFile received\"\n    FileUploaded --\u003e TempFileCreated: \"write to uploads/{uuid}.{ext}\"\n    TempFileCreated --\u003e FormatConversion: \"if not .wav\"\n    TempFileCreated --\u003e SpeechRecognition: \"if .wav\"\n    FormatConversion --\u003e WavFileCreated: \"convert_to_wav()\"\n    WavFileCreated --\u003e SpeechRecognition: \"transcribe_audio()\"\n    SpeechRecognition --\u003e FilesRemoved: \"os.remove() cleanup\"\n    FilesRemoved --\u003e [*]: \"Response sent\"\n    \n    note right of TempFileCreated\n        File path: uploads/{uuid}.{ext}\n        UUID: uuid.uuid4().hex\n    end note\n    \n    note right of FilesRemoved\n        Remove input file: os.remove(input_path)\n        Remove WAV file: os.remove(wav_path)\n    end note\n```\n\n**Sources:** [main.py:30-38](), [main.py:51-53]()\n\n## External Service Integration Components\n\nThe system integrates with external services for audio processing and speech recognition:\n\n| Service | Library | Configuration | Usage |\n|---------|---------|---------------|-------|\n| Google Speech Recognition | `speech_recognition` | Language: `\"es-ES\"` | [iaModels/transcribir.py:18]() |\n| Audio format conversion | `pydub` | AudioSegment processing | [iaModels/transcribir.py:6]() |\n\n### External Dependencies Integration\n\n```mermaid\ngraph TB\n    subgraph \"SystemImports\" [\"System Imports\"]\n        SpeechRecognitionLib[\"import speech_recognition as sr\u003cbr/\u003etranscribir.py:3\"]\n        PyDubLib[\"from pydub import AudioSegment\u003cbr/\u003etranscribir.py:2\"]\n        FastAPILib[\"from fastapi import FastAPI\u003cbr/\u003emain.py:4\"]\n        UvicornLib[\"import uvicorn\u003cbr/\u003emain.py:6\"]\n    end\n    \n    subgraph \"AudioProcessing\" [\"Audio Processing Functions\"]\n        RecognizerInstance[\"sr.Recognizer()\u003cbr/\u003etranscribir.py:13\"]\n        AudioSegmentUsage[\"AudioSegment.from_file()\u003cbr/\u003etranscribir.py:6\"]\n        GoogleAPICall[\"recognize_google(audio, language='es-ES')\u003cbr/\u003etranscribir.py:18\"]\n    end\n    \n    subgraph \"WebFramework\" [\"Web Framework\"]\n        FastAPIInstance[\"app = FastAPI()\u003cbr/\u003emain.py:13\"]\n        UvicornServer[\"uvicorn.run(app, host='0.0.0.0', port=port)\u003cbr/\u003emain.py:62\"]\n    end\n    \n    SpeechRecognitionLib --\u003e RecognizerInstance\n    SpeechRecognitionLib --\u003e GoogleAPICall\n    PyDubLib --\u003e AudioSegmentUsage\n    FastAPILib --\u003e FastAPIInstance\n    UvicornLib --\u003e UvicornServer\n```\n\n**Sources:** [main.py:4-6](), [iaModels/transcribir.py:2-3](), [iaModels/transcribir.py:13-18]()\n\n## Module Import and Path Configuration\n\nThe system uses custom module path configuration to import the audio processing components:\n\n```mermaid\ngraph LR\n    MainPy[\"main.py\"]\n    SysPathAppend[\"sys.path.append()\u003cbr/\u003emain.py:9\"]\n    IAModelsDir[\"iaModels/ directory\"]\n    TranscribirImport[\"from transcribir import\u003cbr/\u003econvert_to_wav, transcribe_audio\u003cbr/\u003emain.py:10\"]\n    \n    MainPy --\u003e SysPathAppend\n    SysPathAppend --\u003e IAModelsDir\n    IAModelsDir --\u003e TranscribirImport\n    \n    subgraph \"ImportedFunctions\" [\"Available Functions\"]\n        ConvertFunc[\"convert_to_wav()\"]\n        TranscribeFunc[\"transcribe_audio()\"]\n    end\n    \n    TranscribirImport --\u003e ConvertFunc\n    TranscribirImport --\u003e TranscribeFunc\n```\n\n**Sources:** [main.py:8-10]()"])</script><script>self.__next_f.push([1,"16:T2482,"])</script><script>self.__next_f.push([1,"# Technology Stack\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document provides a comprehensive overview of the technology stack and dependencies used in the SOLVO Audio AI Backend system. It covers the core framework components, audio processing libraries, external service integrations, and development environment dependencies that enable the Spanish audio transcription service.\n\nFor detailed information about system components and their interactions, see [System Components](#1.1). For deployment configuration and environment setup, see [Development \u0026 Deployment](#5).\n\n## Core Framework Stack\n\nThe SOLVO Audio AI Backend is built on a modern Python web service stack centered around FastAPI and supporting libraries for asynchronous HTTP processing and cross-origin resource sharing.\n\n### Web Framework Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Python Runtime Environment\"\n        PYTHON[\"Python Interpreter\"]\n        VENV[\"Virtual Environment\"]\n    end\n    \n    subgraph \"Web Service Layer\"\n        FASTAPI[\"FastAPI Application\"]\n        UVICORN[\"Uvicorn ASGI Server\"]\n        CORS[\"CORSMiddleware\"]\n    end\n    \n    subgraph \"HTTP Processing\"\n        UPLOADFILE[\"UploadFile Handler\"]\n        MULTIPART[\"python-multipart\"]\n        FILE_OPS[\"File Operations\"]\n    end\n    \n    PYTHON --\u003e VENV\n    VENV --\u003e FASTAPI\n    FASTAPI --\u003e UVICORN\n    FASTAPI --\u003e CORS\n    FASTAPI --\u003e UPLOADFILE\n    UPLOADFILE --\u003e MULTIPART\n    UPLOADFILE --\u003e FILE_OPS\n```\n\nThe `FastAPI` application serves as the central orchestrator, initialized in [main.py:13]() and configured with `CORSMiddleware` for cross-origin requests [main.py:16-25](). The `uvicorn` ASGI server provides the HTTP runtime, configured to bind to `0.0.0.0` with a configurable port [main.py:62]().\n\n**Sources:** [main.py:1-26](), [requirements.txt:1-2]()\n\n### Request Processing Components\n\n| Component | Library | Purpose | Implementation |\n|-----------|---------|---------|----------------|\n| `FastAPI` | fastapi | Web framework and API routing | Application initialization and endpoint definition |\n| `Uvicorn` | uvicorn | ASGI server runtime | HTTP request handling and async processing |\n| `CORSMiddleware` | fastapi.middleware.cors | Cross-origin request support | Frontend integration for localhost and production |\n| `UploadFile` | fastapi | Multipart file upload handling | Audio file receipt and temporary storage |\n| `python-multipart` | python-multipart | Form data parsing | Multipart/form-data request processing |\n\nThe file upload mechanism uses `UploadFile = File(...)` parameter injection [main.py:28]() and processes uploaded content through temporary file storage with UUID-based naming [main.py:34-38]().\n\n**Sources:** [main.py:4-6](), [main.py:28](), [requirements.txt:1-2,5]()\n\n## Audio Processing Dependencies\n\nThe audio processing pipeline relies on specialized Python libraries for format conversion and speech recognition, integrated through the custom `iaModels` package.\n\n### Audio Processing Pipeline\n\n```mermaid\ngraph LR\n    subgraph \"Audio Input\"\n        UPLOAD_FILE[\"UploadFile\"]\n        TEMP_STORAGE[\"uploads/ directory\"]\n    end\n    \n    subgraph \"iaModels Package\"\n        TRANSCRIBIR_MODULE[\"transcribir.py\"]\n        CONVERT_TO_WAV[\"convert_to_wav()\"]\n        TRANSCRIBE_AUDIO[\"transcribe_audio()\"]\n    end\n    \n    subgraph \"Processing Libraries\"\n        PYDUB[\"PyDub AudioSegment\"]\n        SPEECH_REC[\"SpeechRecognition\"]\n        GOOGLE_API[\"Google Speech API\"]\n    end\n    \n    UPLOAD_FILE --\u003e TEMP_STORAGE\n    TEMP_STORAGE --\u003e TRANSCRIBIR_MODULE\n    TRANSCRIBIR_MODULE --\u003e CONVERT_TO_WAV\n    TRANSCRIBIR_MODULE --\u003e TRANSCRIBE_AUDIO\n    CONVERT_TO_WAV --\u003e PYDUB\n    TRANSCRIBE_AUDIO --\u003e SPEECH_REC\n    SPEECH_REC --\u003e GOOGLE_API\n```\n\nThe audio processing workflow imports functions from the `transcribir` module using explicit path manipulation [main.py:8-10]() to ensure module accessibility. Audio format conversion is handled by `convert_to_wav()` when files are not in WAV format [main.py:41-45](), while speech recognition is performed through `transcribe_audio()` [main.py:48]().\n\n**Sources:** [main.py:8-10](), [main.py:41-48](), [requirements.txt:3-4]()\n\n### Audio Library Dependencies\n\n| Library | Purpose | Integration Point | File Format Support |\n|---------|---------|-------------------|-------------------|\n| `pydub` | Audio format conversion and manipulation | `convert_to_wav()` function | MP3, M4A, WAV, and other formats |\n| `SpeechRecognition` | Speech-to-text API integration | `transcribe_audio()` function | WAV audio processing |\n\nThe `pydub` library provides cross-format audio conversion capabilities, ensuring all audio inputs are standardized to WAV format before speech recognition processing. The `SpeechRecognition` library serves as the interface to Google's Speech Recognition API with Spanish language configuration.\n\n**Sources:** [requirements.txt:3-4]()\n\n## External Service Integration\n\nThe system integrates with Google Cloud Speech Recognition services specifically configured for Spanish language processing, providing the core transcription functionality.\n\n### Service Integration Architecture\n\n```mermaid\ngraph TB\n    subgraph \"SOLVO Backend\"\n        TRANSCRIBE_FUNC[\"transcribe_audio()\"]\n        SPEECH_REC_LIB[\"SpeechRecognition Library\"]\n    end\n    \n    subgraph \"Google Cloud Services\"\n        SPEECH_API[\"Google Speech Recognition API\"]\n        SPANISH_MODEL[\"Spanish Language Model (es-ES)\"]\n    end\n    \n    subgraph \"Network Layer\"\n        HTTPS[\"HTTPS API Calls\"]\n        AUTH[\"API Authentication\"]\n    end\n    \n    TRANSCRIBE_FUNC --\u003e SPEECH_REC_LIB\n    SPEECH_REC_LIB --\u003e HTTPS\n    HTTPS --\u003e SPEECH_API\n    SPEECH_API --\u003e SPANISH_MODEL\n```\n\nThe external service integration is abstracted through the `SpeechRecognition` library, which handles API authentication, request formatting, and response processing for Google's Speech Recognition service. The system is specifically configured for Spanish language recognition (`es-ES` locale).\n\n**Sources:** [requirements.txt:4]()\n\n## Development and Runtime Environment\n\nThe system operates within a Python virtual environment with specific runtime configuration for deployment flexibility and development isolation.\n\n### Runtime Configuration\n\n| Component | Configuration | Implementation | Default Value |\n|-----------|---------------|----------------|---------------|\n| `PORT` | Environment variable | `os.environ.get(\"PORT\", 10000)` | 10000 |\n| `HOST` | Server binding | `uvicorn.run(app, host=\"0.0.0.0\")` | 0.0.0.0 |\n| `uploads/` | Temporary storage | `os.makedirs(\"uploads\", exist_ok=True)` | Created on demand |\n| Module path | Import resolution | `sys.path.append()` | Relative to script directory |\n\nThe application uses environment-based configuration for deployment flexibility [main.py:61]() and ensures temporary storage directory creation [main.py:30](). Module import resolution is handled through dynamic path manipulation [main.py:9]() to locate the `iaModels` package.\n\n**Sources:** [main.py:9](), [main.py:30](), [main.py:61-62]()\n\n### Dependency Management\n\n```mermaid\ngraph TB\n    subgraph \"Requirements\"\n        REQ_TXT[\"requirements.txt\"]\n        FASTAPI_DEP[\"fastapi\"]\n        UVICORN_DEP[\"uvicorn\"] \n        PYDUB_DEP[\"pydub\"]\n        SPEECH_DEP[\"SpeechRecognition\"]\n        MULTIPART_DEP[\"python-multipart\"]\n    end\n    \n    subgraph \"Virtual Environment\"\n        VENV[\"venv/ directory\"]\n        PIP_INSTALL[\"pip install -r requirements.txt\"]\n    end\n    \n    subgraph \"Runtime Dependencies\"\n        OS_MODULE[\"os module\"]\n        UUID_MODULE[\"uuid module\"]\n        SYS_MODULE[\"sys module\"]\n    end\n    \n    REQ_TXT --\u003e FASTAPI_DEP\n    REQ_TXT --\u003e UVICORN_DEP\n    REQ_TXT --\u003e PYDUB_DEP\n    REQ_TXT --\u003e SPEECH_DEP\n    REQ_TXT --\u003e MULTIPART_DEP\n    PIP_INSTALL --\u003e VENV\n    VENV --\u003e OS_MODULE\n    VENV --\u003e UUID_MODULE\n    VENV --\u003e SYS_MODULE\n```\n\nThe dependency specification in `requirements.txt` defines five core packages without version pinning, allowing for flexible dependency resolution. Standard library modules (`os`, `uuid`, `sys`) provide file system operations, unique identifier generation, and Python path manipulation.\n\n**Sources:** [requirements.txt:1-6](), [main.py:1-3]()\n\n## Technology Stack Summary\n\nThe SOLVO Audio AI Backend employs a lightweight, purpose-built technology stack optimized for audio transcription workflows:\n\n- **Web Framework**: FastAPI with Uvicorn ASGI server for high-performance async HTTP processing\n- **Audio Processing**: PyDub for format conversion and SpeechRecognition for Google API integration  \n- **Language Specialization**: Spanish (es-ES) speech recognition configuration\n- **File Handling**: Multipart form upload with temporary storage and automatic cleanup\n- **Cross-Origin Support**: CORS middleware configured for development and production frontends\n- **Deployment**: Environment-configurable port binding with containerization readiness\n\nThis stack provides a focused solution for Spanish audio transcription with minimal overhead and clear separation of concerns between web service handling, audio processing, and external API integration.\n\n**Sources:** [main.py:1-63](), [requirements.txt:1-6]()"])</script><script>self.__next_f.push([1,"17:T1aef,"])</script><script>self.__next_f.push([1,"# FastAPI Web Service\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document covers the FastAPI web service layer that serves as the primary entry point and orchestrator for the SOLVO Audio AI Backend. The web service handles HTTP requests, manages file uploads, and coordinates the audio transcription pipeline.\n\nFor detailed information about the audio processing functionality, see [Audio Processing Engine](#3). For deployment and environment configuration, see [Development \u0026 Deployment](#5).\n\n## Application Architecture\n\nThe FastAPI web service is implemented as a single-file application that provides a REST API for audio transcription. The service integrates CORS middleware for cross-origin support and coordinates with the audio processing engine to deliver transcription results.\n\n### FastAPI Application Structure\n\n```mermaid\ngraph TB\n    subgraph \"main.py Application\"\n        APP[\"app = FastAPI()\"]\n        CORS[\"CORSMiddleware\"]\n        ENDPOINT[\"/transcribir-audio/ POST\"]\n        IMPORTS[\"sys.path.append + imports\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        IAMODELS[\"iaModels.transcribir\"]\n        UVICORN[\"uvicorn server\"]\n    end\n    \n    subgraph \"Allowed Origins\"\n        LOCAL[\"http://localhost:3000\"]\n        PROD[\"https://solvo-audio-ai.vercel.app\"]\n    end\n    \n    IMPORTS --\u003e IAMODELS\n    APP --\u003e CORS\n    APP --\u003e ENDPOINT\n    CORS --\u003e LOCAL\n    CORS --\u003e PROD\n    APP --\u003e UVICORN\n    ENDPOINT --\u003e IAMODELS\n```\n\nSources: [main.py:1-62]()\n\n### Application Initialization and Configuration\n\nThe FastAPI application is initialized with minimal configuration and enhanced with CORS middleware to support web frontend clients. The application uses dynamic module loading to integrate with the audio processing engine.\n\n| Component | Configuration | Purpose |\n|-----------|---------------|---------|\n| FastAPI App | `app = FastAPI()` | Core application instance |\n| CORS Middleware | Origins: localhost:3000, solvo-audio-ai.vercel.app | Cross-origin request support |\n| Module Path | `sys.path.append(\"iaModels\")` | Dynamic module loading |\n| Server Binding | Host: 0.0.0.0, Port: ENV[\"PORT\"] \\|\\| 10000 | Network configuration |\n\nSources: [main.py:12-25, 60-62]()\n\n## Request Processing Flow\n\nThe service implements a single endpoint that handles the complete audio transcription workflow from file upload to text response.\n\n### Audio Transcription Endpoint Flow\n\n```mermaid\nsequenceDiagram\n    participant CLIENT as \"HTTP Client\"\n    participant FASTAPI as \"FastAPI App\"\n    participant FILESYSTEM as \"File System\"\n    participant CONVERTER as \"convert_to_wav\"\n    participant TRANSCRIBER as \"transcribe_audio\"\n    \n    CLIENT-\u003e\u003e+FASTAPI: \"POST /transcribir-audio/\"\n    Note over FASTAPI: \"transcribir_audio_endpoint(file: UploadFile)\"\n    \n    FASTAPI-\u003e\u003eFILESYSTEM: \"os.makedirs('uploads', exist_ok=True)\"\n    FASTAPI-\u003e\u003eFILESYSTEM: \"Save file as UUID.ext\"\n    \n    alt \"File is not WAV\"\n        FASTAPI-\u003e\u003e+CONVERTER: \"convert_to_wav(input_path, wav_path)\"\n        CONVERTER--\u003e\u003e-FASTAPI: \"WAV file created\"\n    end\n    \n    FASTAPI-\u003e\u003e+TRANSCRIBER: \"transcribe_audio(wav_path)\"\n    TRANSCRIBER--\u003e\u003e-FASTAPI: \"Spanish text result\"\n    \n    FASTAPI-\u003e\u003eFILESYSTEM: \"os.remove(input_path)\"\n    FASTAPI-\u003e\u003eFILESYSTEM: \"os.remove(wav_path)\"\n    \n    FASTAPI--\u003e\u003e-CLIENT: \"{'transcripcion': texto}\"\n```\n\nSources: [main.py:27-58]()\n\n## Endpoint Implementation\n\n### POST /transcribir-audio/\n\nThe core endpoint handles multipart file uploads and orchestrates the complete transcription pipeline.\n\n**Request Format:**\n- Method: POST\n- Content-Type: multipart/form-data\n- Parameter: `file` (UploadFile) - Audio file in supported format\n\n**Response Format:**\n```json\n{\n  \"transcripcion\": \"texto transcrito en espaol\"\n}\n```\n\n**Processing Steps:**\n\n| Step | Implementation | Location |\n|------|----------------|----------|\n| File Upload | `await file.read()` | [main.py:38]() |\n| Temporary Storage | `uuid.uuid4().hex + extension` | [main.py:33-35]() |\n| Format Detection | `input_path.endswith(\".wav\")` | [main.py:41]() |\n| Audio Conversion | `convert_to_wav(input_path, wav_path)` | [main.py:43]() |\n| Speech Recognition | `transcribe_audio(wav_path)` | [main.py:48]() |\n| File Cleanup | `os.remove()` calls | [main.py:51-53]() |\n\nSources: [main.py:27-58]()\n\n### File Management Strategy\n\nThe service implements a temporary file management strategy with automatic cleanup to prevent disk space accumulation.\n\n```mermaid\nflowchart LR\n    UPLOAD[\"File Upload\"] --\u003e TEMP[\"uploads/UUID.ext\"]\n    TEMP --\u003e CHECK{\"WAV Format?\"}\n    CHECK --\u003e|\"No\"| CONVERT[\"convert_to_wav()\"]\n    CHECK --\u003e|\"Yes\"| PROCESS[\"transcribe_audio()\"]\n    CONVERT --\u003e WAV[\"uploads/UUID.wav\"]\n    WAV --\u003e PROCESS\n    PROCESS --\u003e CLEANUP[\"File Cleanup\"]\n    CLEANUP --\u003e REMOVE1[\"os.remove(input_path)\"]\n    CLEANUP --\u003e REMOVE2[\"os.remove(wav_path)\"]\n```\n\nSources: [main.py:30-53]()\n\n## Error Handling and Response Management\n\n### Exception Handling Strategy\n\nThe service implements a catch-all exception handler that converts Python exceptions into HTTP 500 responses with error details.\n\n```python\n# Exception handling pattern from main.py\ntry:\n    # ... processing logic\n    return {\"transcripcion\": texto}\nexcept Exception as e:\n    raise HTTPException(status_code=500, detail=str(e))\n```\n\n**Error Response Format:**\n- Status Code: 500 Internal Server Error\n- Body: `{\"detail\": \"error message string\"}`\n\nSources: [main.py:57-58]()\n\n## Server Configuration and Deployment\n\n### Runtime Configuration\n\nThe service supports environment-based configuration for deployment flexibility.\n\n| Configuration | Default Value | Environment Variable | Purpose |\n|---------------|---------------|---------------------|---------|\n| Host | 0.0.0.0 | - | Network binding |\n| Port | 10000 | PORT | Service port |\n| Server | uvicorn | - | ASGI server |\n\n### Development Server Startup\n\nThe application includes a direct execution mode for development:\n\n```python\nif __name__ == \"__main__\":\n    port = int(os.environ.get(\"PORT\", 10000))\n    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n```\n\nSources: [main.py:60-62]()\n\n## Integration Points\n\n### Audio Processing Engine Integration\n\nThe FastAPI service integrates with the audio processing engine through direct function imports and calls:\n\n- **Module Loading**: Dynamic path manipulation for `iaModels` package access\n- **Function Calls**: Direct invocation of `convert_to_wav` and `transcribe_audio`\n- **Error Propagation**: Exception handling allows audio processing errors to bubble up\n\n### Frontend Integration\n\nCORS configuration enables integration with web frontends:\n- **Development**: `http://localhost:3000` for local development\n- **Production**: `https://solvo-audio-ai.vercel.app` for deployed frontend\n\nSources: [main.py:8-10, 16-25]()"])</script><script>self.__next_f.push([1,"18:T1802,"])</script><script>self.__next_f.push([1,"# Application Structure \u0026 Configuration\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document covers the core FastAPI application structure, initialization process, and configuration settings that form the foundation of the SOLVO Audio AI Backend service. It focuses specifically on how the main application is set up, configured for cross-origin requests, and prepared for deployment.\n\nFor information about the specific audio transcription endpoint implementation, see [Audio Transcription Endpoint](#2.2). For deployment and environment setup details, see [Deployment Configuration](#5.2).\n\n## Application Initialization Structure\n\nThe FastAPI application follows a straightforward initialization pattern with middleware configuration and module path setup occurring at startup.\n\n### Core Application Setup\n\nThe application initialization occurs in a specific sequence that establishes the web service foundation:\n\n```mermaid\nflowchart TD\n    A[main.py] --\u003e B[\"import statements\"]\n    B --\u003e C[\"sys.path.append()\"]\n    C --\u003e D[\"from transcribir import...\"]\n    D --\u003e E[\"app = FastAPI()\"]\n    E --\u003e F[\"app.add_middleware(CORSMiddleware)\"]\n    F --\u003e G[\"@app.post('/transcribir-audio/')\"]\n    G --\u003e H[\"uvicorn.run()\"]\n    \n    subgraph \"Module Dependencies\"\n        I[\"iaModels/transcribir.py\"]\n        J[\"convert_to_wav\"]\n        K[\"transcribe_audio\"]\n    end\n    \n    C --\u003e I\n    D --\u003e J\n    D --\u003e K\n```\n\nSources: [main.py:1-13]()\n\nThe application uses a single FastAPI instance created at module level, providing a global application object that can be referenced throughout the service lifecycle.\n\n## CORS Configuration\n\nCross-Origin Resource Sharing (CORS) is configured to support specific frontend origins, enabling the service to accept requests from designated web applications.\n\n### Allowed Origins Configuration\n\nThe CORS middleware is configured with explicit origin allowlisting:\n\n| Configuration Parameter | Value | Purpose |\n|------------------------|-------|---------|\n| `allow_origins` | `[\"http://localhost:3000\", \"https://solvo-audio-ai.vercel.app\"]` | Development and production frontend URLs |\n| `allow_credentials` | `True` | Enable credential passing in CORS requests |\n| `allow_methods` | `[\"*\"]` | Accept all HTTP methods |\n| `allow_headers` | `[\"*\"]` | Accept all request headers |\n\n```mermaid\ngraph LR\n    subgraph \"Allowed Origins\"\n        A[\"localhost:3000\"]\n        B[\"solvo-audio-ai.vercel.app\"]\n    end\n    \n    subgraph \"CORS Middleware\"\n        C[\"CORSMiddleware\"]\n        D[\"allow_credentials=True\"]\n        E[\"allow_methods=['*']\"]\n        F[\"allow_headers=['*']\"]\n    end\n    \n    subgraph \"FastAPI App\"\n        G[\"app.add_middleware()\"]\n    end\n    \n    A --\u003e C\n    B --\u003e C\n    C --\u003e G\n    D --\u003e G\n    E --\u003e G\n    F --\u003e G\n```\n\nSources: [main.py:15-25]()\n\nThe configuration supports both local development (`localhost:3000`) and production deployment (`solvo-audio-ai.vercel.app`), indicating a React-based frontend architecture.\n\n## Module Path Configuration\n\nThe application modifies the Python module search path to enable imports from the `iaModels` package, which contains the core audio processing functionality.\n\n### Dynamic Module Loading\n\n```mermaid\nflowchart TD\n    A[\"sys.path.append()\"] --\u003e B[\"os.path.join()\"]\n    B --\u003e C[\"os.path.dirname(__file__)\"]\n    C --\u003e D[\"'iaModels'\"]\n    D --\u003e E[\"from transcribir import\"]\n    E --\u003e F[\"convert_to_wav\"]\n    E --\u003e G[\"transcribe_audio\"]\n    \n    subgraph \"File System\"\n        H[\"main.py\"]\n        I[\"iaModels/\"]\n        J[\"iaModels/transcribir.py\"]\n    end\n    \n    C --\u003e H\n    D --\u003e I\n    F --\u003e J\n    G --\u003e J\n```\n\nSources: [main.py:8-10]()\n\nThis configuration ensures that the `iaModels` package can be imported regardless of the working directory from which the application is launched, providing deployment flexibility.\n\n## Server Configuration\n\nThe application uses Uvicorn as the ASGI server with environment-based configuration for production deployment compatibility.\n\n### Uvicorn Server Setup\n\nThe server configuration supports both development and production environments through environment variable detection:\n\n```mermaid\ngraph TD\n    subgraph \"Environment Detection\"\n        A[\"os.environ.get('PORT', 10000)\"]\n        B[\"int()\"]\n    end\n    \n    subgraph \"Server Parameters\"\n        C[\"host='0.0.0.0'\"]\n        D[\"port=port\"]\n        E[\"app=app\"]\n    end\n    \n    subgraph \"Uvicorn Server\"\n        F[\"uvicorn.run()\"]\n    end\n    \n    A --\u003e B\n    B --\u003e D\n    C --\u003e F\n    D --\u003e F\n    E --\u003e F\n    \n    subgraph \"Network Binding\"\n        G[\"All Interfaces (0.0.0.0)\"]\n        H[\"Default Port 10000\"]\n    end\n    \n    C --\u003e G\n    D --\u003e H\n```\n\nSources: [main.py:60-62]()\n\n### Server Binding Strategy\n\nThe server binds to all network interfaces (`0.0.0.0`) rather than localhost, enabling container deployment and external access. The port configuration uses environment variable override with a sensible default.\n\n| Configuration | Value | Purpose |\n|---------------|-------|---------|\n| Host | `0.0.0.0` | Accept connections from any network interface |\n| Port | `os.environ.get(\"PORT\", 10000)` | Environment-configurable port with default |\n| App | `app` | FastAPI application instance |\n\n## Application Entry Point\n\nThe application supports both direct execution and import-based deployment through the standard Python `if __name__ == \"__main__\"` pattern.\n\n### Execution Modes\n\n```mermaid\nflowchart TD\n    A[\"python main.py\"] --\u003e B[\"__name__ == '__main__'\"]\n    B --\u003e C[\"port = int(os.environ.get('PORT', 10000))\"]\n    C --\u003e D[\"uvicorn.run(app, host='0.0.0.0', port=port)\"]\n    \n    E[\"import main\"] --\u003e F[\"app instance available\"]\n    F --\u003e G[\"External ASGI server\"]\n    \n    subgraph \"Direct Execution\"\n        A\n        B\n        C\n        D\n    end\n    \n    subgraph \"Module Import\"\n        E\n        F\n        G\n    end\n```\n\nSources: [main.py:60-62]()\n\nThis dual-mode configuration enables both development server execution and production deployment where an external ASGI server may import the `app` instance directly."])</script><script>self.__next_f.push([1,"19:T1c91,"])</script><script>self.__next_f.push([1,"# Audio Transcription Endpoint\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document covers the `/transcribir-audio/` POST endpoint, which serves as the primary entry point for audio transcription requests in the SOLVO Audio AI Backend. The endpoint accepts audio file uploads, processes them through the audio transcription pipeline, and returns Spanish text transcriptions.\n\nFor information about the overall FastAPI application structure, see [Application Structure \u0026 Configuration](#2.1). For details about the underlying audio processing functions, see [Audio Processing Engine](#3).\n\n## Endpoint Overview\n\nThe audio transcription endpoint is implemented as an asynchronous FastAPI route handler that orchestrates the complete audio-to-text conversion workflow. The endpoint handles multipart file uploads, manages temporary file storage, coordinates audio format conversion, and integrates with the Google Speech Recognition service.\n\n### Endpoint Definition\n\n| Property | Value |\n|----------|-------|\n| **Route** | `/transcribir-audio/` |\n| **HTTP Method** | POST |\n| **Content Type** | `multipart/form-data` |\n| **Function Name** | `transcribir_audio_endpoint` |\n| **Response Type** | JSON |\n\nSources: [main.py:27-28]()\n\n## Request Format and Parameters\n\nThe endpoint accepts a single file parameter through multipart form data upload. The file parameter is required and enforced by FastAPI's dependency injection system.\n\n### Request Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `file` | `UploadFile` | Yes | Audio file to transcribe (various formats supported) |\n\nThe `UploadFile` type is provided by FastAPI and includes metadata such as `filename`, `content_type`, and file content accessed via the `read()` method.\n\n```mermaid\nflowchart TD\n    CLIENT[\"HTTP Client\"]\n    ENDPOINT[\"transcribir_audio_endpoint\"]\n    UPLOADFILE[\"UploadFile\"]\n    FILENAME[\"file.filename\"]\n    CONTENT[\"await file.read()\"]\n    \n    CLIENT --\u003e|\"POST /transcribir-audio/\"| ENDPOINT\n    ENDPOINT --\u003e|\"file: UploadFile = File(...)\"| UPLOADFILE\n    UPLOADFILE --\u003e FILENAME\n    UPLOADFILE --\u003e CONTENT\n    \n    FILENAME --\u003e|\"Extract extension\"| TEMP_FILE[\"unique_name.ext\"]\n    CONTENT --\u003e|\"Write to disk\"| TEMP_FILE\n```\n\n**File Upload Parameter Processing**\n\nSources: [main.py:28](), [main.py:33-38]()\n\n## Internal Processing Pipeline\n\nThe endpoint implements a comprehensive processing pipeline that handles file storage, format conversion, transcription, and cleanup operations.\n\n### Processing Flow Architecture\n\n```mermaid\nsequenceDiagram\n    participant CLIENT as \"HTTP Client\"\n    participant ENDPOINT as \"transcribir_audio_endpoint\"\n    participant FS as \"File System\"\n    participant CONVERTER as \"convert_to_wav\"\n    participant TRANSCRIBER as \"transcribe_audio\"\n    participant CLEANUP as \"Cleanup Process\"\n    \n    CLIENT-\u003e\u003e+ENDPOINT: \"POST with audio file\"\n    \n    ENDPOINT-\u003e\u003e+FS: \"os.makedirs('uploads', exist_ok=True)\"\n    FS--\u003e\u003e-ENDPOINT: \"Directory created\"\n    \n    ENDPOINT-\u003e\u003eENDPOINT: \"Generate uuid.uuid4().hex + ext\"\n    ENDPOINT-\u003e\u003e+FS: \"Save to uploads/unique_name.ext\"\n    FS--\u003e\u003e-ENDPOINT: \"File saved as input_path\"\n    \n    alt \"not input_path.endswith('.wav')\"\n        ENDPOINT-\u003e\u003e+CONVERTER: \"convert_to_wav(input_path, wav_path)\"\n        CONVERTER--\u003e\u003e-ENDPOINT: \"WAV file created\"\n    else \"Already WAV format\"\n        ENDPOINT-\u003e\u003eENDPOINT: \"wav_path = input_path\"\n    end\n    \n    ENDPOINT-\u003e\u003e+TRANSCRIBER: \"transcribe_audio(wav_path)\"\n    TRANSCRIBER--\u003e\u003e-ENDPOINT: \"texto (Spanish text)\"\n    \n    ENDPOINT-\u003e\u003e+CLEANUP: \"os.remove(input_path)\"\n    CLEANUP--\u003e\u003e-ENDPOINT: \"Original file deleted\"\n    \n    alt \"wav_path != input_path\"\n        ENDPOINT-\u003e\u003e+CLEANUP: \"os.remove(wav_path)\"\n        CLEANUP--\u003e\u003e-ENDPOINT: \"Converted file deleted\"\n    end\n    \n    ENDPOINT--\u003e\u003e-CLIENT: \"{'transcripcion': texto}\"\n```\n\n**Request Processing Sequence**\n\nSources: [main.py:29-55]()\n\n### Temporary File Management\n\nThe endpoint implements a robust temporary file management system using UUID-based unique filenames and automatic cleanup.\n\n| Operation | Implementation | Code Reference |\n|-----------|----------------|----------------|\n| **Directory Creation** | `os.makedirs(\"uploads\", exist_ok=True)` | [main.py:30]() |\n| **Unique Naming** | `f\"{uuid.uuid4().hex}.{ext}\"` | [main.py:34]() |\n| **File Path Construction** | `os.path.join(\"uploads\", unique_name)` | [main.py:35]() |\n| **File Writing** | `f.write(await file.read())` | [main.py:37-38]() |\n| **Cleanup** | `os.remove(input_path)` | [main.py:51-53]() |\n\nSources: [main.py:30](), [main.py:33-38](), [main.py:51-53]()\n\n### Audio Format Handling\n\nThe endpoint includes conditional logic to handle various audio formats by converting non-WAV files to WAV format before transcription.\n\n```mermaid\nflowchart TD\n    INPUT_PATH[\"input_path\"]\n    FORMAT_CHECK{\"input_path.endswith('.wav')\"}\n    NO_CONVERSION[\"wav_path = input_path\"]\n    CONVERSION_PATH[\"wav_path = input_path.rsplit('.', 1)[0] + '.wav'\"]\n    CONVERT_CALL[\"convert_to_wav(input_path, wav_path)\"]\n    TRANSCRIBE[\"transcribe_audio(wav_path)\"]\n    \n    INPUT_PATH --\u003e FORMAT_CHECK\n    FORMAT_CHECK --\u003e|\"True\"| NO_CONVERSION\n    FORMAT_CHECK --\u003e|\"False\"| CONVERSION_PATH\n    CONVERSION_PATH --\u003e CONVERT_CALL\n    NO_CONVERSION --\u003e TRANSCRIBE\n    CONVERT_CALL --\u003e TRANSCRIBE\n```\n\n**Audio Format Decision Tree**\n\nSources: [main.py:41-48]()\n\n## Response Format\n\nThe endpoint returns a standardized JSON response containing the transcribed text in Spanish.\n\n### Success Response\n\n```json\n{\n  \"transcripcion\": \"texto transcrito en espaol\"\n}\n```\n\nThe response structure uses a single key `transcripcion` that contains the Spanish text output from the `transcribe_audio` function.\n\n### Error Response\n\nError handling is implemented using FastAPI's `HTTPException` with a 500 status code for any processing failures.\n\n```json\n{\n  \"detail\": \"error message string\"\n}\n```\n\nSources: [main.py:55](), [main.py:57-58]()\n\n## Integration Points\n\nThe endpoint serves as an orchestration layer that integrates with multiple system components:\n\n### Core Dependencies\n\n| Component | Function Call | Purpose |\n|-----------|---------------|---------|\n| **Audio Converter** | `convert_to_wav(input_path, wav_path)` | Format standardization |\n| **Speech Recognition** | `transcribe_audio(wav_path)` | Text extraction |\n| **File System** | `os.makedirs()`, `os.remove()` | Storage management |\n| **UUID Generator** | `uuid.uuid4().hex` | Unique file naming |\n\n### Error Propagation\n\nThe endpoint implements a try-catch pattern that captures any exceptions from the audio processing pipeline and converts them to HTTP 500 responses.\n\n```mermaid\ngraph TD\n    TRY_BLOCK[\"try: Processing Pipeline\"]\n    CONVERT_CALL[\"convert_to_wav()\"]\n    TRANSCRIBE_CALL[\"transcribe_audio()\"]\n    EXCEPTION[\"Exception e\"]\n    HTTP_EXCEPTION[\"HTTPException(status_code=500, detail=str(e))\"]\n    \n    TRY_BLOCK --\u003e CONVERT_CALL\n    TRY_BLOCK --\u003e TRANSCRIBE_CALL\n    CONVERT_CALL -.-\u003e|\"Any error\"| EXCEPTION\n    TRANSCRIBE_CALL -.-\u003e|\"Any error\"| EXCEPTION\n    EXCEPTION --\u003e HTTP_EXCEPTION\n```\n\n**Exception Handling Flow**\n\nSources: [main.py:29](), [main.py:57-58]()"])</script><script>self.__next_f.push([1,"1a:T1d18,"])</script><script>self.__next_f.push([1,"# File Upload \u0026 Processing Pipeline\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document covers the file upload handling, temporary storage management, and audio processing workflow within the FastAPI web service. It focuses on how uploaded audio files are received, stored, converted, and managed throughout their lifecycle in the system.\n\nFor information about the speech recognition and transcription functionality, see [Audio Processing Engine](#3). For API endpoint structure and response formats, see [Audio Transcription Endpoint](#2.2).\n\n## File Upload Mechanism\n\nThe system accepts audio file uploads through HTTP POST requests using multipart/form-data encoding. The upload handler is implemented in the `/transcribir-audio/` endpoint using FastAPI's `UploadFile` parameter.\n\n### Upload Parameter Configuration\n\nThe endpoint accepts a single file parameter defined as:\n\n```python\nasync def transcribir_audio_endpoint(file: UploadFile = File(...))\n```\n\nThe `File(...)` parameter with ellipsis makes the file upload mandatory. The `UploadFile` type provides access to the uploaded file's content, filename, and metadata.\n\n### File Reading Process\n\nUploaded files are read asynchronously to handle large audio files efficiently:\n\n```mermaid\nflowchart TD\n    REQUEST[\"HTTP POST Request\"] --\u003e UPLOAD_FILE[\"UploadFile Parameter\"]\n    UPLOAD_FILE --\u003e READ_CONTENT[\"await file.read()\"]\n    READ_CONTENT --\u003e WRITE_DISK[\"Write to Disk\"]\n    WRITE_DISK --\u003e PROCESSING[\"Audio Processing\"]\n```\n\n**File Upload Flow**\n\nSources: [main.py:28-38]()\n\n## Temporary Storage Management\n\nThe system implements a temporary file storage strategy using UUID-based naming to prevent filename conflicts and ensure file isolation between concurrent requests.\n\n### Directory Structure\n\nThe temporary storage uses a dedicated `uploads/` directory:\n\n| Component | Implementation | Purpose |\n|-----------|----------------|---------|\n| Base Directory | `uploads/` | Container for all temporary files |\n| Directory Creation | `os.makedirs(\"uploads\", exist_ok=True)` | Ensures directory exists |\n| File Naming | `f\"{uuid.uuid4().hex}.{ext}\"` | Unique filename generation |\n\n### File Naming Strategy\n\n```mermaid\ngraph LR\n    FILENAME[\"Original Filename\"] --\u003e EXTRACT_EXT[\"Extract Extension\"]\n    EXTRACT_EXT --\u003e UUID_GEN[\"Generate UUID\"]\n    UUID_GEN --\u003e COMBINE[\"Combine UUID + Extension\"]\n    COMBINE --\u003e UNIQUE_NAME[\"Unique Filename\"]\n    \n    EXTRACT_EXT --\u003e EXT[\"file.filename.split('.')[-1]\"]\n    UUID_GEN --\u003e UUID_HEX[\"uuid.uuid4().hex\"]\n    COMBINE --\u003e FINAL[\"UUID.ext\"]\n```\n\n**UUID-Based File Naming Process**\n\nThe implementation extracts the file extension from the original filename and combines it with a hexadecimal UUID to create a unique temporary filename.\n\nSources: [main.py:30-35]()\n\n## Audio Format Processing Pipeline\n\nThe system implements a conditional audio format conversion pipeline that standardizes input files to WAV format when necessary.\n\n### Format Detection and Conversion Logic\n\n```mermaid\nflowchart TD\n    INPUT_FILE[\"Input File Saved\"] --\u003e FORMAT_CHECK{\"File ends with .wav?\"}\n    FORMAT_CHECK --\u003e|Yes| USE_ORIGINAL[\"wav_path = input_path\"]\n    FORMAT_CHECK --\u003e|No| GENERATE_WAV_PATH[\"Generate WAV path\"]\n    GENERATE_WAV_PATH --\u003e CONVERT[\"convert_to_wav(input_path, wav_path)\"]\n    CONVERT --\u003e WAV_READY[\"WAV file ready\"]\n    USE_ORIGINAL --\u003e WAV_READY\n    WAV_READY --\u003e TRANSCRIPTION[\"transcribe_audio(wav_path)\"]\n```\n\n**Audio Format Conversion Decision Tree**\n\n### WAV Path Generation\n\nFor non-WAV files, the system generates a corresponding WAV filename by replacing the original extension:\n\n```python\nwav_path = input_path.rsplit(\".\", 1)[0] + \".wav\"\n```\n\nThis creates a WAV file with the same base name as the original file in the same `uploads/` directory.\n\n### Conversion Process\n\nThe actual audio conversion is handled by the `convert_to_wav` function from the `iaModels.transcribir` module, which uses PyDub's `AudioSegment` to perform format conversion:\n\n```mermaid\ngraph TD\n    INPUT[\"Input Audio File\"] --\u003e PYDUB[\"AudioSegment.from_file()\"]\n    PYDUB --\u003e EXPORT[\"audio.export(format='wav')\"]\n    EXPORT --\u003e OUTPUT[\"WAV Output File\"]\n```\n\n**PyDub Conversion Process**\n\nSources: [main.py:40-45](), [iaModels/transcribir.py:5-7]()\n\n## File Lifecycle Management\n\nThe system implements comprehensive file lifecycle management to prevent disk space accumulation and ensure proper cleanup of temporary files.\n\n### File Creation and Processing Lifecycle\n\n```mermaid\nsequenceDiagram\n    participant Request as \"HTTP Request\"\n    participant Storage as \"File Storage\"\n    participant Converter as \"Format Converter\"\n    participant Processor as \"Audio Processor\"\n    participant Cleanup as \"Cleanup Handler\"\n    \n    Request-\u003e\u003e+Storage: Upload and save original file\n    Storage--\u003e\u003e-Request: input_path created\n    \n    alt File is not WAV\n        Request-\u003e\u003e+Converter: convert_to_wav(input_path, wav_path)\n        Converter--\u003e\u003e-Request: WAV file created\n    end\n    \n    Request-\u003e\u003e+Processor: transcribe_audio(wav_path)\n    Processor--\u003e\u003e-Request: Transcription result\n    \n    Request-\u003e\u003e+Cleanup: Remove temporary files\n    Cleanup-\u003e\u003eStorage: os.remove(input_path)\n    alt WAV file was created separately\n        Cleanup-\u003e\u003eStorage: os.remove(wav_path)\n    end\n    Cleanup--\u003e\u003e-Request: Files cleaned up\n```\n\n**Complete File Lifecycle Sequence**\n\n### Cleanup Strategy\n\nThe cleanup process handles two scenarios:\n\n1. **Original file removal**: Always removes the initially uploaded file\n2. **Converted file removal**: Removes WAV file only if it was created separately from the original\n\n```python\n# Always remove original file\nos.remove(input_path)\n\n# Remove WAV file only if it's different from original\nif os.path.exists(wav_path) and wav_path != input_path:\n    os.remove(wav_path)\n```\n\nThe conditional check `wav_path != input_path` ensures that WAV files uploaded directly are not removed twice.\n\nSources: [main.py:50-53]()\n\n## Error Handling in File Processing\n\nThe entire file processing pipeline is wrapped in exception handling to ensure proper cleanup and error reporting even when processing fails.\n\n### Exception Management Pattern\n\n```mermaid\ngraph TD\n    START[\"Start Processing\"] --\u003e TRY_BLOCK[\"Try Block: File Operations\"]\n    TRY_BLOCK --\u003e SUCCESS{\"Success?\"}\n    SUCCESS --\u003e|Yes| RETURN_RESULT[\"Return transcription result\"]\n    SUCCESS --\u003e|No| CATCH_EXCEPTION[\"Catch Exception\"]\n    CATCH_EXCEPTION --\u003e HTTP_EXCEPTION[\"Raise HTTPException(500)\"]\n    \n    TRY_BLOCK --\u003e UPLOAD[\"File Upload\"]\n    UPLOAD --\u003e CONVERSION[\"Format Conversion\"]\n    CONVERSION --\u003e TRANSCRIPTION[\"Audio Transcription\"]\n    TRANSCRIPTION --\u003e CLEANUP[\"File Cleanup\"]\n    CLEANUP --\u003e RETURN_RESULT\n```\n\n**Error Handling Flow**\n\nThe exception handling ensures that any failure in the pipeline results in a proper HTTP 500 error response with the original exception message, preventing clients from receiving incomplete or misleading responses.\n\n### Error Response Format\n\nWhen exceptions occur, the system raises an `HTTPException` with:\n- **Status Code**: 500 (Internal Server Error)\n- **Detail**: String representation of the original exception\n\nThis provides debugging information while maintaining a consistent API error response format.\n\nSources: [main.py:29, 57-58]()"])</script><script>self.__next_f.push([1,"1b:T1d9a,"])</script><script>self.__next_f.push([1,"# Error Handling \u0026 Response Format\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n\n\u003c/details\u003e\n\n\n\nThis document covers the error handling mechanisms and API response formats implemented in the SOLVO Audio AI Backend service. It details how exceptions are managed, how responses are structured, and the error propagation patterns used throughout the transcription pipeline.\n\nFor information about the audio transcription endpoint implementation, see [Audio Transcription Endpoint](#2.2). For details about the file processing workflow, see [File Upload \u0026 Processing Pipeline](#2.3).\n\n## Error Handling Strategy\n\nThe SOLVO Audio AI Backend employs a centralized error handling approach using FastAPI's built-in exception mechanisms. All errors within the transcription pipeline are caught at the endpoint level and converted to standardized HTTP responses.\n\n### Exception Catching Pattern\n\nThe main transcription endpoint uses a comprehensive try-catch block that wraps the entire processing pipeline:\n\n```mermaid\nflowchart TD\n    START[\"POST /transcribir-audio/\"] --\u003e TRY[\"try block starts\"]\n    TRY --\u003e MKDIR[\"os.makedirs('uploads')\"]\n    MKDIR --\u003e SAVE[\"Save uploaded file\"]\n    SAVE --\u003e CONVERT[\"convert_to_wav()\"]\n    CONVERT --\u003e TRANSCRIBE[\"transcribe_audio()\"]\n    TRANSCRIBE --\u003e CLEANUP[\"File cleanup\"]\n    CLEANUP --\u003e SUCCESS[\"Return success response\"]\n    \n    MKDIR --\u003e EXCEPT[\"Exception caught\"]\n    SAVE --\u003e EXCEPT\n    CONVERT --\u003e EXCEPT\n    TRANSCRIBE --\u003e EXCEPT\n    CLEANUP --\u003e EXCEPT\n    \n    EXCEPT --\u003e HTTP_EXC[\"HTTPException(status_code=500)\"]\n    HTTP_EXC --\u003e ERROR_RESP[\"Error response returned\"]\n    SUCCESS --\u003e JSON_RESP[\"JSON response returned\"]\n```\n\n*Sources: [main.py:28-58]()*\n\nThe error handling implementation catches all exceptions generically and converts them to HTTP 500 Internal Server Error responses with the original exception message as the detail.\n\n### Exception Conversion Mechanism\n\nAll exceptions within the processing pipeline are handled uniformly:\n\n| Exception Source | Handling Method | HTTP Status Code | Response Format |\n|------------------|-----------------|------------------|-----------------|\n| File I/O operations | Generic catch-all | 500 | `{\"detail\": \"error_message\"}` |\n| Audio conversion | Generic catch-all | 500 | `{\"detail\": \"error_message\"}` |\n| Speech recognition | Generic catch-all | 500 | `{\"detail\": \"error_message\"}` |\n| System errors | Generic catch-all | 500 | `{\"detail\": \"error_message\"}` |\n\n*Sources: [main.py:57-58]()*\n\n## Success Response Format\n\nSuccessful transcription requests return a standardized JSON response containing the transcribed text.\n\n### Response Structure\n\n```mermaid\ngraph TD\n    ENDPOINT[\"transcribir_audio_endpoint()\"] --\u003e PROCESS[\"Audio processing pipeline\"]\n    PROCESS --\u003e TEXTO[\"texto = transcribe_audio()\"]\n    TEXTO --\u003e RESPONSE[\"return {'transcripcion': texto}\"]\n    \n    subgraph \"JSON Response Object\"\n        TRANSCRIPCION[\"'transcripcion': string\"]\n    end\n    \n    RESPONSE --\u003e TRANSCRIPCION\n```\n\n*Sources: [main.py:48, 55]()*\n\nThe success response format is:\n\n```json\n{\n  \"transcripcion\": \"transcribed_text_content\"\n}\n```\n\nWhere `transcribed_text_content` is the Spanish text output from the Google Speech Recognition service.\n\n## Error Response Format\n\nError responses follow FastAPI's standard HTTPException format, providing consistent error information to clients.\n\n### HTTPException Structure\n\n```mermaid\ngraph TD\n    EXCEPTION[\"Any Exception\"] --\u003e CATCH[\"except Exception as e\"]\n    CATCH --\u003e HTTP_EXC[\"HTTPException(status_code=500, detail=str(e))\"]\n    HTTP_EXC --\u003e FASTAPI[\"FastAPI error handler\"]\n    FASTAPI --\u003e JSON_ERROR[\"JSON error response\"]\n    \n    subgraph \"Error Response Format\"\n        STATUS[\"status_code: 500\"]\n        DETAIL[\"detail: error_message\"]\n    end\n    \n    JSON_ERROR --\u003e STATUS\n    JSON_ERROR --\u003e DETAIL\n```\n\n*Sources: [main.py:57-58]()*\n\nThe error response format is:\n\n```json\n{\n  \"detail\": \"error_message_string\"\n}\n```\n\nWith HTTP status code 500 (Internal Server Error) for all error conditions.\n\n## Exception Flow Through System Components\n\nThe error handling pattern creates a unified exception flow from any component in the processing pipeline to the client response.\n\n### Processing Pipeline Error Propagation\n\n```mermaid\nsequenceDiagram\n    participant Client as \"HTTP Client\"\n    participant Endpoint as \"transcribir_audio_endpoint()\"\n    participant FileSystem as \"File Operations\"\n    participant Converter as \"convert_to_wav()\"\n    participant Transcriber as \"transcribe_audio()\"\n    participant GoogleAPI as \"Google Speech API\"\n    \n    Client-\u003e\u003e+Endpoint: POST /transcribir-audio/\n    Note over Endpoint: try block begins\n    \n    alt File Operation Error\n        Endpoint-\u003e\u003e+FileSystem: Save uploaded file\n        FileSystem--\u003e\u003e-Endpoint: IOException\n        Endpoint-\u003e\u003eEndpoint: except Exception as e\n        Endpoint--\u003e\u003eClient: HTTPException(500, detail=str(e))\n    else Audio Conversion Error\n        Endpoint-\u003e\u003e+Converter: convert_to_wav()\n        Converter--\u003e\u003e-Endpoint: ConversionError\n        Endpoint-\u003e\u003eEndpoint: except Exception as e\n        Endpoint--\u003e\u003eClient: HTTPException(500, detail=str(e))\n    else Speech Recognition Error\n        Endpoint-\u003e\u003e+Transcriber: transcribe_audio()\n        Transcriber-\u003e\u003e+GoogleAPI: API call\n        GoogleAPI--\u003e\u003e-Transcriber: APIError\n        Transcriber--\u003e\u003e-Endpoint: RecognitionError\n        Endpoint-\u003e\u003eEndpoint: except Exception as e\n        Endpoint--\u003e\u003eClient: HTTPException(500, detail=str(e))\n    else Success Path\n        Endpoint-\u003e\u003eFileSystem: File cleanup\n        Endpoint--\u003e\u003e-Client: {\"transcripcion\": \"text\"}\n    end\n```\n\n*Sources: [main.py:29-58]()*\n\n## Error Categories and Handling\n\nWhile the current implementation treats all errors uniformly, the system encounters several categories of potential errors during operation.\n\n### Potential Error Sources\n\n| Error Category | Source Components | Common Causes |\n|----------------|-------------------|---------------|\n| File System Errors | `os.makedirs()`, file I/O operations | Disk space, permissions, path issues |\n| Upload Errors | `UploadFile.read()`, file writing | Network issues, file corruption, size limits |\n| Audio Format Errors | `convert_to_wav()` function | Unsupported formats, corrupted audio files |\n| Recognition Errors | `transcribe_audio()`, Google API | API limits, network issues, audio quality |\n| System Errors | General Python runtime | Memory issues, dependency problems |\n\n*Sources: [main.py:30-48]()*\n\n### Resource Cleanup in Error Scenarios\n\nThe current error handling implementation does not guarantee proper cleanup of temporary files when exceptions occur during processing. File cleanup operations are performed in the success path but not within the exception handling block.\n\n```mermaid\nflowchart TD\n    EXCEPTION[\"Exception occurs\"] --\u003e CATCH[\"Exception caught\"]\n    CATCH --\u003e HTTP_EXC[\"HTTPException raised\"]\n    HTTP_EXC --\u003e RESPONSE[\"Error response sent\"]\n    \n    subgraph \"Cleanup Gap\"\n        TEMP_FILES[\"Temporary files may remain\"]\n        INPUT_FILE[\"input_path file\"]\n        WAV_FILE[\"wav_path file (if converted)\"]\n    end\n    \n    RESPONSE --\u003e TEMP_FILES\n    TEMP_FILES --\u003e INPUT_FILE\n    TEMP_FILES --\u003e WAV_FILE\n    \n    Note[\"File cleanup only occurs in success path\u003cbr/\u003e(lines 51-53)\"]\n```\n\n*Sources: [main.py:51-53, 57-58]()*\n\nThis represents a potential resource leak where temporary files may accumulate in the `uploads/` directory when processing errors occur."])</script><script>self.__next_f.push([1,"1c:T1b6c,"])</script><script>self.__next_f.push([1,"# Audio Processing Engine\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n\n\u003c/details\u003e\n\n\n\nThe Audio Processing Engine serves as the core AI module of the SOLVO Audio AI Backend, providing audio format conversion and speech-to-text transcription capabilities. This module is implemented in the `iaModels` package and handles the fundamental audio processing operations required for Spanish language transcription services.\n\nThis document covers the core audio processing functionality, including format conversion and speech recognition components. For information about how this engine integrates with the web service layer, see [FastAPI Web Service](#2). For specific endpoint implementation details, see [Audio Transcription Endpoint](#2.2).\n\n## Module Architecture\n\nThe Audio Processing Engine is centered around the `iaModels.transcribir` module, which provides two primary functions that work together to process audio files and extract Spanish text content.\n\n### Core Audio Processing Components\n\n```mermaid\ngraph TB\n    subgraph \"iaModels Package\"\n        subgraph \"transcribir.py Module\"\n            convert_to_wav[\"convert_to_wav()\"]\n            transcribe_audio[\"transcribe_audio()\"]\n        end\n    end\n    \n    subgraph \"External Libraries\"\n        pydub[\"PyDub AudioSegment\"]\n        speech_recognition[\"SpeechRecognition Library\"]\n        google_api[\"Google Speech Recognition API\"]\n    end\n    \n    subgraph \"Processing Pipeline\"\n        input_audio[\"Input Audio File\u003cbr/\u003e(MP3, M4A, etc.)\"]\n        wav_file[\"WAV Format File\"]\n        transcribed_text[\"Spanish Transcribed Text\"]\n    end\n    \n    input_audio --\u003e convert_to_wav\n    convert_to_wav --\u003e pydub\n    convert_to_wav --\u003e wav_file\n    wav_file --\u003e transcribe_audio\n    transcribe_audio --\u003e speech_recognition\n    speech_recognition --\u003e google_api\n    transcribe_audio --\u003e transcribed_text\n    \n    style convert_to_wav fill:#e8f5e8\n    style transcribe_audio fill:#e3f2fd\n    style transcribed_text fill:#fff3e0\n```\n\n**Sources:** [iaModels/transcribir.py:1-23]()\n\n## Audio Format Conversion Pipeline\n\nThe `convert_to_wav` function standardizes audio input by converting various audio formats to WAV format, which is required by the speech recognition engine.\n\n### Format Conversion Process\n\n```mermaid\nsequenceDiagram\n    participant Input as \"Input Audio File\"\n    participant convert_to_wav as \"convert_to_wav()\"\n    participant AudioSegment as \"PyDub AudioSegment\"\n    participant Output as \"WAV Output File\"\n    \n    Input-\u003e\u003econvert_to_wav: \"input_path, output_path\"\n    convert_to_wav-\u003e\u003eAudioSegment: \"AudioSegment.from_file(input_path)\"\n    AudioSegment--\u003e\u003econvert_to_wav: \"Audio object loaded\"\n    convert_to_wav-\u003e\u003eAudioSegment: \"audio.export(output_path, format='wav')\"\n    AudioSegment-\u003e\u003eOutput: \"WAV file created\"\n    convert_to_wav--\u003e\u003eInput: \"Conversion complete\"\n```\n\nThe conversion function accepts any audio format supported by PyDub and exports it as a WAV file using the following process:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `input_path` | `str` | Path to the source audio file |\n| `output_path` | `str` | Destination path for the WAV file |\n\n**Sources:** [iaModels/transcribir.py:5-7]()\n\n## Speech Recognition Engine\n\nThe `transcribe_audio` function processes WAV audio files and converts speech content to Spanish text using Google's Speech Recognition API.\n\n### Speech Recognition Process Flow\n\n```mermaid\nflowchart TD\n    wav_input[\"WAV Audio File\"]\n    transcribe_audio[\"transcribe_audio()\"]\n    format_check{\"WAV Format Check\"}\n    sr_recognizer[\"SpeechRecognition Recognizer\"]\n    audio_file[\"sr.AudioFile Context\"]\n    record_audio[\"recognizer.record(source)\"]\n    google_api_call[\"recognizer.recognize_google()\"]\n    language_param[\"language='es-ES'\"]\n    success_result[\"Spanish Text Output\"]\n    unknown_error[\"UnknownValueError\u003cbr/\u003eNo se pudo entender el audio\"]\n    request_error[\"RequestError\u003cbr/\u003eConnection Error\"]\n    \n    wav_input --\u003e transcribe_audio\n    transcribe_audio --\u003e format_check\n    format_check --\u003e|\"Not WAV\"| ValueError[\"ValueError Exception\"]\n    format_check --\u003e|\"WAV Format\"| sr_recognizer\n    sr_recognizer --\u003e audio_file\n    audio_file --\u003e record_audio\n    record_audio --\u003e google_api_call\n    google_api_call --\u003e language_param\n    language_param --\u003e success_result\n    google_api_call --\u003e unknown_error\n    google_api_call --\u003e request_error\n    \n    style transcribe_audio fill:#e3f2fd\n    style google_api_call fill:#fff3e0\n    style success_result fill:#e8f5e8\n```\n\n### Error Handling Strategy\n\nThe speech recognition engine implements comprehensive error handling for common transcription failures:\n\n| Exception Type | Handling | Return Value |\n|----------------|----------|--------------|\n| `ValueError` | Invalid file format | Exception raised |\n| `sr.UnknownValueError` | Audio not understandable | `\"No se pudo entender el audio.\"` |\n| `sr.RequestError` | API connection failure | `\"Error al conectarse a Google Speech Recognition: {e}\"` |\n\n**Sources:** [iaModels/transcribir.py:9-22]()\n\n## Function Specifications\n\n### convert_to_wav Function\n\n```python\ndef convert_to_wav(input_path: str, output_path: str) -\u003e None\n```\n\nThis function handles audio format standardization using PyDub's `AudioSegment` class. It loads the input audio file and exports it in WAV format to the specified output path.\n\n**Implementation Details:**\n- Uses `AudioSegment.from_file()` for flexible input format support\n- Exports with explicit `format=\"wav\"` parameter\n- No return value (writes directly to file system)\n\n### transcribe_audio Function\n\n```python\ndef transcribe_audio(file_path: str) -\u003e str\n```\n\nThis function processes WAV audio files and returns Spanish transcribed text. It enforces WAV format requirements and integrates with Google Speech Recognition API.\n\n**Implementation Details:**\n- Validates WAV format using file extension check\n- Creates `sr.Recognizer()` instance for each transcription\n- Uses `sr.AudioFile` context manager for audio loading\n- Calls `recognize_google()` with `language=\"es-ES\"` parameter\n- Returns transcribed text string or error message\n\n**Sources:** [iaModels/transcribir.py:5-22]()\n\n## Integration Points\n\nThe Audio Processing Engine integrates with the broader system through the following touchpoints:\n\n### FastAPI Integration\nThe engine functions are called from the FastAPI endpoint handler in the main application, where temporary file paths are passed as parameters.\n\n### Temporary File Management\nBoth functions operate on file paths rather than in-memory objects, requiring coordination with the file upload and cleanup processes managed by the web service layer.\n\n### Language Configuration\nThe speech recognition is hardcoded for Spanish language (`es-ES`), reflecting the system's specialization for Spanish-speaking users and content.\n\n**Sources:** [iaModels/transcribir.py:1-23]()"])</script><script>self.__next_f.push([1,"1d:T1764,"])</script><script>self.__next_f.push([1,"# Audio Format Conversion\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document covers the audio format conversion functionality within the SOLVO Audio AI Backend system. The conversion process standardizes input audio files to WAV format as a prerequisite for speech recognition processing. This module handles the transformation of various audio formats (MP3, M4A, and others) into the WAV format required by the Google Speech Recognition API.\n\nFor information about the speech recognition processing that follows format conversion, see [Speech Recognition Engine](#3.2). For details about the overall file upload and processing pipeline, see [File Upload \u0026 Processing Pipeline](#2.3).\n\n## Conversion Function Overview\n\nThe audio format conversion is implemented through the `convert_to_wav` function in the `iaModels` package. This function serves as the standardization layer that ensures all audio inputs are in the correct format for downstream processing.\n\n### Function Signature and Implementation\n\nThe conversion process is handled by a single, focused function:\n\n| Function | Parameters | Return Type | Purpose |\n|----------|------------|-------------|---------|\n| `convert_to_wav` | `input_path: str`, `output_path: str` | `None` | Converts any supported audio format to WAV |\n\n**Implementation Details:**\n- Uses PyDub's `AudioSegment.from_file()` to read input audio\n- Exports the audio data using `audio.export()` with WAV format specification\n- Performs in-place conversion without returning audio data\n\nSources: [iaModels/transcribir.py:5-7]()\n\n## Audio Conversion Flow Diagram\n\n```mermaid\nflowchart TD\n    INPUT_FILE[\"Input Audio File\u003cbr/\u003e(MP3, M4A, etc.)\"]\n    CONVERT_FUNC[\"convert_to_wav()\u003cbr/\u003eiaModels.transcribir\"]\n    PYDUB_LOAD[\"AudioSegment.from_file()\u003cbr/\u003ePyDub Processing\"]\n    AUDIO_DATA[\"In-Memory Audio Data\u003cbr/\u003eAudioSegment Object\"]\n    EXPORT_WAV[\"audio.export()\u003cbr/\u003eformat='wav'\"]\n    OUTPUT_FILE[\"WAV Audio File\u003cbr/\u003eReady for Recognition\"]\n    \n    INPUT_FILE --\u003e CONVERT_FUNC\n    CONVERT_FUNC --\u003e PYDUB_LOAD\n    PYDUB_LOAD --\u003e AUDIO_DATA\n    AUDIO_DATA --\u003e EXPORT_WAV\n    EXPORT_WAV --\u003e OUTPUT_FILE\n    \n    style CONVERT_FUNC fill:#f9f9f9\n    style PYDUB_LOAD fill:#e8f4f8\n    style EXPORT_WAV fill:#e8f4f8\n```\n\nSources: [iaModels/transcribir.py:5-7]()\n\n## Technical Implementation Details\n\n### PyDub Integration\n\nThe conversion process relies on the PyDub library for audio format handling:\n\n- **Format Detection**: PyDub automatically detects the input format based on file content and extension\n- **Codec Support**: Supports common audio formats including MP3, M4A, FLAC, and others\n- **Memory Efficiency**: Loads audio data into memory as an `AudioSegment` object for processing\n- **Export Control**: Provides precise control over output format parameters\n\n### Conversion Process\n\nThe conversion follows a three-step process:\n\n1. **Audio Loading**: `AudioSegment.from_file(input_path)` reads the source file\n2. **Format Processing**: Audio data is held in memory as an `AudioSegment` object\n3. **WAV Export**: `audio.export(output_path, format=\"wav\")` writes the standardized output\n\nSources: [iaModels/transcribir.py:5-7]()\n\n## Integration with Processing Pipeline\n\n### Pre-Recognition Workflow\n\n```mermaid\nsequenceDiagram\n    participant MAIN as \"main.py\"\n    participant CONVERTER as \"convert_to_wav()\"\n    participant PYDUB as \"PyDub AudioSegment\"\n    participant FILESYSTEM as \"File System\"\n    participant TRANSCRIBER as \"transcribe_audio()\"\n    \n    MAIN-\u003e\u003e+CONVERTER: convert_to_wav(input_path, wav_path)\n    CONVERTER-\u003e\u003e+PYDUB: AudioSegment.from_file(input_path)\n    PYDUB--\u003e\u003e-CONVERTER: AudioSegment object\n    CONVERTER-\u003e\u003e+PYDUB: audio.export(wav_path, format=\"wav\")\n    PYDUB-\u003e\u003eFILESYSTEM: Write WAV file\n    PYDUB--\u003e\u003e-CONVERTER: Export complete\n    CONVERTER--\u003e\u003e-MAIN: Conversion finished\n    MAIN-\u003e\u003eTRANSCRIBER: transcribe_audio(wav_path)\n```\n\n### Pipeline Integration Points\n\nThe format conversion integrates with the broader audio processing pipeline at these key points:\n\n- **Input**: Receives file paths from the FastAPI upload handler\n- **Processing**: Transforms audio data using PyDub\n- **Output**: Provides WAV files to the speech recognition engine\n- **Cleanup**: Temporary files are managed by the calling application\n\nSources: [iaModels/transcribir.py:5-7]()\n\n## Format Support and Limitations\n\n### Supported Input Formats\n\nThe conversion function supports all formats that PyDub can handle:\n\n| Format | Extension | Notes |\n|--------|-----------|-------|\n| MP3 | `.mp3` | Most common input format |\n| M4A | `.m4a` | Apple audio format |\n| FLAC | `.flac` | Lossless audio format |\n| OGG | `.ogg` | Open source audio format |\n| WAV | `.wav` | Already supported (no conversion needed) |\n\n### Technical Requirements\n\n- **PyDub Dependency**: Requires PyDub library for audio processing\n- **Codec Availability**: Some formats may require additional codecs on the system\n- **Memory Usage**: Audio files are loaded entirely into memory during conversion\n- **File System Access**: Requires read access to input files and write access to output location\n\n### Processing Constraints\n\n- **File Size**: Limited by available system memory for large audio files\n- **Format Validation**: No explicit format validation before conversion attempt\n- **Error Propagation**: PyDub exceptions are not caught within the conversion function\n\nSources: [iaModels/transcribir.py:5-7]()\n\n## Function Dependencies and Imports\n\nThe format conversion functionality depends on:\n\n```\npydub.AudioSegment - Core audio processing functionality\nos - File system operations (imported but not used in convert_to_wav)\n```\n\nThe conversion function is imported and used by the main FastAPI application through the `iaModels.transcribir` module path.\n\nSources: [iaModels/transcribir.py:1-3]()"])</script><script>self.__next_f.push([1,"1e:T1afa,"])</script><script>self.__next_f.push([1,"# Speech Recognition Engine\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [iaModels/transcribir.py](iaModels/transcribir.py)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document covers the core speech recognition functionality of the SOLVO Audio AI Backend, specifically the `transcribe_audio` function and its integration with Google's Speech Recognition API for Spanish language processing. This engine converts WAV audio files into Spanish text transcriptions.\n\nFor information about audio format conversion that precedes speech recognition, see [Audio Format Conversion](#3.1). For the complete FastAPI endpoint that orchestrates the transcription workflow, see [Audio Transcription Endpoint](#2.2).\n\n## Core Speech Recognition Function\n\nThe speech recognition engine is implemented in the `transcribe_audio` function within the `iaModels` package. This function serves as the primary interface between the application and Google's Speech Recognition service.\n\n### Function Architecture\n\n```mermaid\nflowchart TD\n    input[\"file_path: str\"] --\u003e validation{\"file_path.endswith('.wav')\"}\n    validation --\u003e|False| error_output[\"ValueError: El archivo debe estar en formato WAV\"]\n    validation --\u003e|True| recognizer[\"sr.Recognizer()\"]\n    recognizer --\u003e audio_file[\"sr.AudioFile(file_path)\"]\n    audio_file --\u003e record[\"recognizer.record(source)\"]\n    record --\u003e google_api[\"recognizer.recognize_google(audio, language='es-ES')\"]\n    google_api --\u003e success_output[\"Spanish text transcription\"]\n    google_api --\u003e unknown_error[\"sr.UnknownValueError\"]\n    google_api --\u003e request_error[\"sr.RequestError\"]\n    unknown_error --\u003e unknown_output[\"'No se pudo entender el audio.'\"]\n    request_error --\u003e request_output[\"'Error al conectarse a Google Speech Recognition: {e}'\"]\n```\n\n**Sources:** [iaModels/transcribir.py:9-22]()\n\n### Implementation Details\n\nThe `transcribe_audio` function follows a structured approach to audio processing:\n\n| Step | Operation | Code Entity | Purpose |\n|------|-----------|-------------|---------|\n| 1 | Input Validation | `file_path.lower().endswith('.wav')` | Ensures WAV format requirement |\n| 2 | Recognizer Initialization | `sr.Recognizer()` | Creates speech recognition instance |\n| 3 | Audio Loading | `sr.AudioFile(file_path)` | Loads WAV file as audio source |\n| 4 | Audio Recording | `recognizer.record(source)` | Extracts audio data from file |\n| 5 | Speech Recognition | `recognizer.recognize_google(audio, language=\"es-ES\")` | Converts audio to Spanish text |\n\n**Sources:** [iaModels/transcribir.py:9-18]()\n\n## Google Speech Recognition Integration\n\nThe engine integrates with Google's Speech Recognition API through the `speech_recognition` library. The integration is specifically configured for Spanish language processing.\n\n### API Configuration\n\n```mermaid\ngraph LR\n    transcribe_audio[\"transcribe_audio()\"] --\u003e recognizer[\"sr.Recognizer()\"]\n    recognizer --\u003e google_call[\"recognize_google()\"]\n    google_call --\u003e language_param[\"language='es-ES'\"]\n    google_call --\u003e audio_param[\"audio data\"]\n    language_param --\u003e google_api[\"Google Speech Recognition API\"]\n    audio_param --\u003e google_api\n    google_api --\u003e spanish_text[\"Spanish transcription text\"]\n```\n\n**Sources:** [iaModels/transcribir.py:18]()\n\nThe `recognize_google` method is called with two key parameters:\n- `audio`: The recorded audio data from the WAV file\n- `language=\"es-ES\"`: Specifies Spanish (Spain) as the recognition language\n\nThis configuration ensures that the speech recognition engine is optimized for Spanish language audio content, aligning with the system's primary use case.\n\n**Sources:** [iaModels/transcribir.py:18]()\n\n## Error Handling Strategy\n\nThe speech recognition engine implements comprehensive error handling to manage various failure scenarios that can occur during the transcription process.\n\n### Error Flow Diagram\n\n```mermaid\nflowchart TD\n    recognize_google[\"recognizer.recognize_google(audio, language='es-ES')\"] --\u003e try_block[\"Try Block\"]\n    try_block --\u003e success[\"Return transcribed text\"]\n    try_block --\u003e unknown_value[\"sr.UnknownValueError\"]\n    try_block --\u003e request_error[\"sr.RequestError\"]\n    unknown_value --\u003e unknown_msg[\"'No se pudo entender el audio.'\"]\n    request_error --\u003e request_msg[\"'Error al conectarse a Google Speech Recognition: {e}'\"]\n```\n\n**Sources:** [iaModels/transcribir.py:17-22]()\n\n### Error Types and Responses\n\n| Error Type | Trigger Condition | Response Message | Code Reference |\n|------------|------------------|------------------|----------------|\n| `ValueError` | Non-WAV file input | \"El archivo debe estar en formato WAV para SpeechRecognition.\" | [iaModels/transcribir.py:11]() |\n| `sr.UnknownValueError` | Audio content not recognizable | \"No se pudo entender el audio.\" | [iaModels/transcribir.py:20]() |\n| `sr.RequestError` | API connection/service failure | \"Error al conectarse a Google Speech Recognition: {e}\" | [iaModels/transcribir.py:22]() |\n\n**Sources:** [iaModels/transcribir.py:10-22]()\n\n## Language Configuration\n\nThe speech recognition engine is explicitly configured for Spanish language processing through the `language=\"es-ES\"` parameter. This configuration choice reflects the system's specialization for Spanish-speaking users or Spanish audio content.\n\n### Language Specification Details\n\n- **Language Code**: `es-ES` (Spanish - Spain)\n- **Implementation**: Passed as parameter to `recognizer.recognize_google()`\n- **Scope**: Applied to all transcription requests processed by this engine\n\n**Sources:** [iaModels/transcribir.py:18]()\n\n## Dependencies and External Services\n\nThe speech recognition engine relies on specific Python libraries and external services to function properly.\n\n### Dependency Architecture\n\n```mermaid\ngraph TD\n    transcribe_audio[\"transcribe_audio()\"] --\u003e speech_recognition[\"speech_recognition library\"]\n    speech_recognition --\u003e sr_recognizer[\"sr.Recognizer\"]\n    speech_recognition --\u003e sr_audiofile[\"sr.AudioFile\"]\n    speech_recognition --\u003e sr_exceptions[\"sr.UnknownValueError, sr.RequestError\"]\n    sr_recognizer --\u003e google_service[\"Google Speech Recognition Service\"]\n    google_service --\u003e internet[\"Internet Connection Required\"]\n```\n\n**Sources:** [iaModels/transcribir.py:3,13-14,17-22]()\n\n### Required External Dependencies\n\n| Component | Type | Purpose | Import Statement |\n|-----------|------|---------|------------------|\n| `speech_recognition` | Python Library | Speech-to-text functionality | `import speech_recognition as sr` |\n| Google Speech Recognition API | External Service | Cloud-based speech processing | Accessed via `sr.recognize_google()` |\n\n**Sources:** [iaModels/transcribir.py:3]()\n\nThe engine requires an active internet connection to communicate with Google's Speech Recognition API, making it dependent on external service availability and network connectivity."])</script><script>self.__next_f.push([1,"1f:T2c98,"])</script><script>self.__next_f.push([1,"# System Architecture \u0026 Dependencies\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document provides a comprehensive analysis of the SOLVO Audio AI Backend's system architecture, technology stack, and external service dependencies. It covers the overall architectural patterns, component interactions, and technology choices that enable the Spanish audio transcription service.\n\nFor detailed information about the FastAPI web service implementation, see [FastAPI Web Service](#2). For audio processing specifics, see [Audio Processing Engine](#3). For development and deployment procedures, see [Development \u0026 Deployment](#5).\n\n## Architectural Overview\n\nThe SOLVO Audio AI Backend follows a **layered microservice architecture** with clear separation of concerns across three primary layers: web service, business logic, and external service integration.\n\n### High-Level System Architecture\n\n```mermaid\ngraph TB\n    subgraph ClientLayer[\"Client Layer\"]\n        WebClient[\"Web Frontend\u003cbr/\u003elocalhost:3000\"]\n        ProdClient[\"Production Client\u003cbr/\u003esolvo-audio-ai.vercel.app\"]\n        APIClient[\"API Clients\"]\n    end\n    \n    subgraph WebServiceLayer[\"Web Service Layer\"]\n        FastAPIApp[\"FastAPI Application\u003cbr/\u003emain.py\"]\n        CORSMiddleware[\"CORSMiddleware\u003cbr/\u003eOrigin Control\"]\n        UvicornServer[\"Uvicorn ASGI Server\u003cbr/\u003ePort 10000\"]\n    end\n    \n    subgraph BusinessLogicLayer[\"Business Logic Layer\"]\n        TranscribirEndpoint[\"transcribir_audio_endpoint()\u003cbr/\u003e/transcribir-audio/\"]\n        FileManager[\"File Upload Handler\u003cbr/\u003eUploadFile Processing\"]\n        TempStorage[\"Temporary Storage\u003cbr/\u003euploads/ directory\"]\n    end\n    \n    subgraph AudioProcessingLayer[\"Audio Processing Layer\"]\n        iaModelsPackage[\"iaModels Package\u003cbr/\u003etranscribir.py\"]\n        ConvertToWav[\"convert_to_wav()\u003cbr/\u003eFormat Conversion\"]\n        TranscribeAudio[\"transcribe_audio()\u003cbr/\u003eSpeech Recognition\"]\n    end\n    \n    subgraph ExternalServices[\"External Services\"]\n        GoogleSpeechAPI[\"Google Speech Recognition API\u003cbr/\u003eSpanish (es-ES)\"]\n    end\n    \n    WebClient --\u003e FastAPIApp\n    ProdClient --\u003e FastAPIApp\n    APIClient --\u003e FastAPIApp\n    FastAPIApp --\u003e CORSMiddleware\n    FastAPIApp --\u003e UvicornServer\n    FastAPIApp --\u003e TranscribirEndpoint\n    TranscribirEndpoint --\u003e FileManager\n    FileManager --\u003e TempStorage\n    TranscribirEndpoint --\u003e iaModelsPackage\n    iaModelsPackage --\u003e ConvertToWav\n    iaModelsPackage --\u003e TranscribeAudio\n    TranscribeAudio --\u003e GoogleSpeechAPI\n```\n\nSources: [main.py:1-63](), [requirements.txt:1-6]()\n\n### Component Interaction Flow\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant FastAPIApp as \"FastAPI App\u003cbr/\u003emain.py\"\n    participant CORSMiddleware as \"CORS Middleware\"\n    participant TranscribirEndpoint as \"transcribir_audio_endpoint\"\n    participant FileSystem as \"uploads/ Directory\"\n    participant iaModels as \"iaModels.transcribir\"\n    participant GoogleAPI as \"Google Speech API\"\n    \n    Client-\u003e\u003e+FastAPIApp: \"POST /transcribir-audio/\"\n    FastAPIApp-\u003e\u003e+CORSMiddleware: \"Origin Validation\"\n    CORSMiddleware--\u003e\u003e-FastAPIApp: \"CORS Headers Added\"\n    FastAPIApp-\u003e\u003e+TranscribirEndpoint: \"UploadFile Processing\"\n    \n    TranscribirEndpoint-\u003e\u003e+FileSystem: \"os.makedirs('uploads', exist_ok=True)\"\n    TranscribirEndpoint-\u003e\u003eFileSystem: \"Save UUID.ext file\"\n    FileSystem--\u003e\u003e-TranscribirEndpoint: \"File Saved\"\n    \n    alt \"File is not WAV\"\n        TranscribirEndpoint-\u003e\u003e+iaModels: \"convert_to_wav(input_path, wav_path)\"\n        iaModels--\u003e\u003e-TranscribirEndpoint: \"WAV File Created\"\n    end\n    \n    TranscribirEndpoint-\u003e\u003e+iaModels: \"transcribe_audio(wav_path)\"\n    iaModels-\u003e\u003e+GoogleAPI: \"Speech Recognition Request\"\n    GoogleAPI--\u003e\u003e-iaModels: \"Spanish Text Result\"\n    iaModels--\u003e\u003e-TranscribirEndpoint: \"Transcribed Text\"\n    \n    TranscribirEndpoint-\u003e\u003eFileSystem: \"os.remove() Cleanup\"\n    TranscribirEndpoint--\u003e\u003e-FastAPIApp: \"{'transcripcion': texto}\"\n    FastAPIApp--\u003e\u003e-Client: \"JSON Response\"\n```\n\nSources: [main.py:27-58]()\n\n## Technology Stack Analysis\n\n### Core Framework Dependencies\n\n| Component | Library | Version Constraint | Purpose |\n|-----------|---------|-------------------|---------|\n| Web Framework | `fastapi` | Latest | ASGI web application framework |\n| ASGI Server | `uvicorn` | Latest | Production ASGI server implementation |\n| Audio Processing | `pydub` | Latest | Audio format conversion and manipulation |\n| Speech Recognition | `SpeechRecognition` | Latest | Google Speech API integration |\n| File Upload Support | `python-multipart` | Latest | Multipart form data parsing |\n\nSources: [requirements.txt:1-6]()\n\n### Dependency Architecture\n\n```mermaid\ngraph TD\n    subgraph PythonRuntime[\"Python Runtime Environment\"]\n        MainApplication[\"main.py\u003cbr/\u003eApplication Entry Point\"]\n        iaModelsPackage[\"iaModels Package\u003cbr/\u003eAudio Processing Logic\"]\n    end\n    \n    subgraph WebFramework[\"Web Framework Stack\"]\n        FastAPIFramework[\"fastapi\u003cbr/\u003eWeb Framework\"]\n        UvicornServer[\"uvicorn\u003cbr/\u003eASGI Server\"]\n        PythonMultipart[\"python-multipart\u003cbr/\u003eFile Upload Support\"]\n    end\n    \n    subgraph AudioStack[\"Audio Processing Stack\"]\n        PyDubLibrary[\"pydub\u003cbr/\u003eAudio Format Conversion\"]\n        SpeechRecognitionLib[\"SpeechRecognition\u003cbr/\u003eGoogle API Client\"]\n    end\n    \n    subgraph SystemLibraries[\"System Libraries\"]\n        OSModule[\"os\u003cbr/\u003eFile System Operations\"]\n        UUIDModule[\"uuid\u003cbr/\u003eUnique File Names\"]\n        SysModule[\"sys\u003cbr/\u003ePath Management\"]\n    end\n    \n    MainApplication --\u003e FastAPIFramework\n    MainApplication --\u003e UvicornServer\n    MainApplication --\u003e OSModule\n    MainApplication --\u003e UUIDModule\n    MainApplication --\u003e SysModule\n    MainApplication --\u003e iaModelsPackage\n    \n    FastAPIFramework --\u003e PythonMultipart\n    iaModelsPackage --\u003e PyDubLibrary\n    iaModelsPackage --\u003e SpeechRecognitionLib\n```\n\nSources: [main.py:1-10](), [requirements.txt:1-6]()\n\n## Service Layer Architecture\n\n### Module Import and Path Configuration\n\nThe application uses a custom module loading strategy to access the `iaModels` package:\n\n```python\n# sys.path.append configuration\nsys.path.append(os.path.join(os.path.dirname(__file__), \"iaModels\"))\nfrom transcribir import convert_to_wav, transcribe_audio\n```\n\nThis approach enables the main application to import audio processing functions directly from the `iaModels` package located in a subdirectory.\n\nSources: [main.py:8-10]()\n\n### CORS Configuration Architecture\n\nThe system implements cross-origin resource sharing with specific allowed origins:\n\n| Origin Type | URL | Purpose |\n|-------------|-----|---------|\n| Development | `http://localhost:3000` | Local frontend development |\n| Production | `https://solvo-audio-ai.vercel.app` | Production web application |\n\nAdditional CORS settings:\n- `allow_credentials=True` - Enables credential sharing\n- `allow_methods=[\"*\"]` - Permits all HTTP methods\n- `allow_headers=[\"*\"]` - Allows all request headers\n\nSources: [main.py:15-25]()\n\n## External Service Dependencies\n\n### Google Speech Recognition Integration\n\nThe system integrates with Google's Speech Recognition service through the `SpeechRecognition` library. The integration is specifically configured for Spanish language processing:\n\n```mermaid\ngraph LR\n    subgraph LocalSystem[\"SOLVO Audio AI Backend\"]\n        TranscribeFunction[\"transcribe_audio()\u003cbr/\u003eiaModels.transcribir\"]\n        SpeechRecognitionLib[\"SpeechRecognition Library\"]\n    end\n    \n    subgraph GoogleCloud[\"Google Cloud Services\"]\n        SpeechAPI[\"Speech-to-Text API\u003cbr/\u003eLanguage: es-ES\"]\n    end\n    \n    TranscribeFunction --\u003e SpeechRecognitionLib\n    SpeechRecognitionLib --\u003e SpeechAPI\n    SpeechAPI --\u003e SpeechRecognitionLib\n    SpeechRecognitionLib --\u003e TranscribeFunction\n```\n\n**Key Characteristics:**\n- **Language Target**: Spanish (es-ES) speech recognition\n- **Audio Format**: Requires WAV format input\n- **Network Dependency**: Requires internet connectivity to Google services\n- **Authentication**: Uses default Google Speech Recognition API access\n\nSources: [main.py:47-48](), iaModels/transcribir.py (referenced)\n\n## File System \u0026 Storage Architecture\n\n### Temporary File Management\n\nThe system implements a temporary file storage pattern for audio processing:\n\n```mermaid\nflowchart TD\n    subgraph FileSystemLayer[\"File System Layer\"]\n        UploadsDirectory[\"uploads/\u003cbr/\u003eTemporary Storage Directory\"]\n        InputFile[\"UUID.{ext}\u003cbr/\u003eOriginal Upload\"]\n        WAVFile[\"UUID.wav\u003cbr/\u003eConverted Audio\"]\n    end\n    \n    subgraph ProcessingFlow[\"Processing Flow\"]\n        FileUpload[\"UploadFile\u003cbr/\u003eMultipart Form Data\"]\n        UUIDGeneration[\"uuid.uuid4().hex\u003cbr/\u003eUnique Filename\"]\n        FormatCheck[\"Extension Check\u003cbr/\u003e.wav validation\"]\n        ConversionProcess[\"convert_to_wav()\u003cbr/\u003eFormat Standardization\"]\n        TranscriptionProcess[\"transcribe_audio()\u003cbr/\u003eSpeech Recognition\"]\n        CleanupProcess[\"os.remove()\u003cbr/\u003eFile Deletion\"]\n    end\n    \n    FileUpload --\u003e UUIDGeneration\n    UUIDGeneration --\u003e InputFile\n    InputFile --\u003e FormatCheck\n    FormatCheck --\u003e|\"Not WAV\"| ConversionProcess\n    FormatCheck --\u003e|\"Already WAV\"| TranscriptionProcess\n    ConversionProcess --\u003e WAVFile\n    WAVFile --\u003e TranscriptionProcess\n    TranscriptionProcess --\u003e CleanupProcess\n    CleanupProcess --\u003e UploadsDirectory\n```\n\n**File Lifecycle Management:**\n1. **Creation**: Files saved with UUID-based names to prevent conflicts\n2. **Processing**: Original files converted to WAV format if necessary\n3. **Cleanup**: Both original and converted files removed after transcription\n\nSources: [main.py:30-53]()\n\n## Network \u0026 Deployment Architecture\n\n### Server Configuration\n\nThe application uses environment-based configuration for deployment flexibility:\n\n| Configuration | Default Value | Source |\n|---------------|---------------|--------|\n| Server Host | `0.0.0.0` | Hard-coded for container compatibility |\n| Server Port | `10000` | Environment variable `PORT` with fallback |\n| Application Server | `uvicorn` | ASGI server implementation |\n\n### Runtime Architecture\n\n```mermaid\ngraph TB\n    subgraph EnvironmentConfig[\"Environment Configuration\"]\n        PORTVariable[\"PORT Environment Variable\u003cbr/\u003eDefault: 10000\"]\n        HostBinding[\"Host: 0.0.0.0\u003cbr/\u003eContainer-Ready\"]\n    end\n    \n    subgraph ApplicationRuntime[\"Application Runtime\"]\n        MainEntry[\"if __name__ == '__main__'\u003cbr/\u003eEntry Point\"]\n        UvicornRun[\"uvicorn.run()\u003cbr/\u003eASGI Server Launch\"]\n        FastAPIInstance[\"FastAPI Application\u003cbr/\u003eRoute Handler\"]\n    end\n    \n    subgraph NetworkLayer[\"Network Layer\"]\n        HTTPListener[\"HTTP Listener\u003cbr/\u003e0.0.0.0:PORT\"]\n        CORSValidation[\"CORS Origin Validation\"]\n        EndpointRouting[\"POST /transcribir-audio/\u003cbr/\u003eRoute Handling\"]\n    end\n    \n    PORTVariable --\u003e MainEntry\n    HostBinding --\u003e MainEntry\n    MainEntry --\u003e UvicornRun\n    UvicornRun --\u003e FastAPIInstance\n    FastAPIInstance --\u003e HTTPListener\n    HTTPListener --\u003e CORSValidation\n    CORSValidation --\u003e EndpointRouting\n```\n\n**Deployment Characteristics:**\n- **Container-Ready**: `0.0.0.0` host binding enables container deployment\n- **Environment-Aware**: Port configuration through environment variables\n- **Production-Ready**: Uvicorn ASGI server for production workloads\n\nSources: [main.py:60-62]()"])</script><script>self.__next_f.push([1,"20:T1aec,"])</script><script>self.__next_f.push([1,"# Python Dependencies\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document provides a detailed breakdown of the Python packages and libraries required by the SOLVO Audio AI Backend system. It covers the core dependencies defined in the project's requirements file and explains their roles in enabling audio transcription functionality.\n\nFor information about the overall system architecture and how these dependencies fit together, see [Service Architecture](#4.2). For development environment setup using these dependencies, see [Environment Setup](#5.1).\n\n## Core Framework Dependencies\n\nThe SOLVO Audio AI Backend is built on a modern Python web framework stack optimized for high-performance API services and asynchronous request handling.\n\n### FastAPI Framework\n\n`fastapi` serves as the primary web framework for the application, providing the foundation for REST API endpoints and request handling. This framework enables the `/transcribir-audio/` endpoint documented in [Audio Transcription Endpoint](#2.2) and supports automatic API documentation generation.\n\nKey capabilities provided by FastAPI in this system:\n- HTTP request routing and parameter validation\n- Automatic OpenAPI/Swagger documentation\n- Dependency injection for request processing\n- JSON serialization for API responses\n\n### ASGI Server\n\n`uvicorn` functions as the ASGI (Asynchronous Server Gateway Interface) server that runs the FastAPI application. It handles HTTP connections and serves the application on the configured port (default 10000).\n\nThe server configuration and startup logic is implemented in [main.py:1-50]() where uvicorn manages the application lifecycle and network binding.\n\n**Sources**: [requirements.txt:1-2]()\n\n## Audio Processing Dependencies\n\nThe core audio transcription functionality relies on specialized libraries for audio format handling and speech recognition processing.\n\n### Audio Format Processing\n\n`pydub` provides comprehensive audio file manipulation capabilities, enabling the system to handle multiple input formats and convert them to the WAV format required by the speech recognition engine.\n\nThis library powers the `convert_to_wav` function in the iaModels package, which standardizes audio input regardless of the original format (MP3, M4A, etc.). The conversion process ensures compatibility with Google's Speech Recognition API requirements.\n\n### Speech Recognition Engine\n\n`SpeechRecognition` serves as the interface layer to Google's Speech-to-Text API, specifically configured for Spanish language processing (`es-ES`). This library abstracts the complexity of audio data preparation and API communication for speech recognition services.\n\nThe library enables the `transcribe_audio` function that performs the actual speech-to-text conversion using Google's cloud-based recognition service.\n\n**Sources**: [requirements.txt:3-4]()\n\n## File Upload Support\n\n### Multipart Form Data Handling\n\n`python-multipart` enables FastAPI to process file uploads sent as multipart/form-data requests. This dependency is essential for the audio file upload functionality that allows clients to submit audio files for transcription.\n\nWithout this package, the FastAPI application cannot parse incoming file uploads, making it a critical dependency for the primary use case of receiving audio files via HTTP POST requests.\n\n**Sources**: [requirements.txt:5]()\n\n## Dependency Relationship Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Web Framework Layer\"\n        fastapi[\"fastapi\"]\n        uvicorn[\"uvicorn\"]\n        multipart[\"python-multipart\"]\n    end\n    \n    subgraph \"Audio Processing Layer\"\n        pydub[\"pydub\"]\n        speechrec[\"SpeechRecognition\"]\n    end\n    \n    subgraph \"Application Modules\"\n        main_py[\"main.py\"]\n        iamodels[\"iaModels/transcribir.py\"]\n        endpoint[\"POST /transcribir-audio/\"]\n    end\n    \n    subgraph \"External Services\"\n        google_api[\"Google Speech Recognition API\"]\n    end\n    \n    uvicorn --\u003e fastapi\n    fastapi --\u003e multipart\n    fastapi --\u003e main_py\n    main_py --\u003e endpoint\n    endpoint --\u003e iamodels\n    iamodels --\u003e pydub\n    iamodels --\u003e speechrec\n    speechrec --\u003e google_api\n    \n    multipart -.-\u003e endpoint\n    pydub -.-\u003e iamodels\n```\n\n**Dependency to Code Entity Mapping**\n\nThis diagram illustrates how each Python dependency enables specific functionality within the codebase:\n\n```mermaid\ngraph LR\n    subgraph \"requirements.txt Dependencies\"\n        dep_fastapi[\"fastapi\"]\n        dep_uvicorn[\"uvicorn\"] \n        dep_pydub[\"pydub\"]\n        dep_speechrec[\"SpeechRecognition\"]\n        dep_multipart[\"python-multipart\"]\n    end\n    \n    subgraph \"Code Functions \u0026 Endpoints\"\n        app_instance[\"FastAPI() app instance\"]\n        transcribir_endpoint[\"@app.post('/transcribir-audio/')\"]\n        convert_to_wav[\"convert_to_wav()\"]\n        transcribe_audio[\"transcribe_audio()\"]\n        file_upload[\"UploadFile parameter\"]\n        uvicorn_run[\"uvicorn.run()\"]\n    end\n    \n    dep_fastapi --\u003e app_instance\n    dep_fastapi --\u003e transcribir_endpoint\n    dep_uvicorn --\u003e uvicorn_run\n    dep_pydub --\u003e convert_to_wav\n    dep_speechrec --\u003e transcribe_audio\n    dep_multipart --\u003e file_upload\n```\n\n**Sources**: [requirements.txt:1-5]()\n\n## Dependency Categories and Purposes\n\n| Category | Package | Primary Purpose | Code Integration |\n|----------|---------|-----------------|------------------|\n| Web Framework | `fastapi` | API endpoint management, request routing | FastAPI app instance, route decorators |\n| ASGI Server | `uvicorn` | HTTP server for FastAPI application | Server startup and configuration |\n| Audio Processing | `pydub` | Audio format conversion and manipulation | `convert_to_wav` function in iaModels |\n| Speech Recognition | `SpeechRecognition` | Interface to Google Speech API | `transcribe_audio` function |\n| File Handling | `python-multipart` | Multipart form data parsing for file uploads | `UploadFile` parameter handling |\n\n## Compatibility and Version Considerations\n\nThe dependencies are specified without version constraints in [requirements.txt:1-5](), indicating the system is designed to work with the latest stable versions of these packages. This approach provides:\n\n- Automatic security updates from package maintainers\n- Access to latest features and performance improvements\n- Simplified dependency management\n\nHowever, this also means the system should be tested regularly to ensure compatibility when dependency versions are updated.\n\n**Critical Integration Points:**\n- `SpeechRecognition` must maintain compatibility with Google's Speech Recognition API\n- `pydub` audio format support must align with common web audio formats\n- `FastAPI` and `uvicorn` versions must remain compatible for ASGI operation\n\n**Sources**: [requirements.txt:1-5]()"])</script><script>self.__next_f.push([1,"21:T1dd6,"])</script><script>self.__next_f.push([1,"# Service Architecture\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document describes the overall service architecture of the SOLVO Audio AI Backend, focusing on how the different components interact to provide audio transcription functionality. This covers the architectural patterns, service boundaries, and integration strategies used throughout the system.\n\nFor detailed information about individual components, see [System Components](#1.1). For implementation details of the FastAPI web service, see [FastAPI Web Service](#2). For audio processing implementation details, see [Audio Processing Engine](#3).\n\n## Architecture Pattern\n\nThe SOLVO Audio AI Backend follows a **layered microservice architecture** with clear separation of concerns. The system is organized into three primary architectural layers that handle different aspects of the audio transcription pipeline.\n\n### Layered Service Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Presentation Layer\"\n        FastAPI[\"FastAPI Application\"]\n        CORSMiddleware[\"CORSMiddleware\"]\n        transcribir_audio_endpoint[\"/transcribir-audio/ Endpoint\"]\n    end\n    \n    subgraph \"Business Logic Layer\"\n        iaModels[\"iaModels Package\"]\n        convert_to_wav[\"convert_to_wav()\"]\n        transcribe_audio[\"transcribe_audio()\"]\n    end\n    \n    subgraph \"Integration Layer\"\n        FileSystem[\"File System (uploads/)\"]\n        GoogleSpeechAPI[\"Google Speech Recognition API\"]\n        TempFileManager[\"Temporary File Management\"]\n    end\n    \n    FastAPI --\u003e CORSMiddleware\n    FastAPI --\u003e transcribir_audio_endpoint\n    transcribir_audio_endpoint --\u003e iaModels\n    iaModels --\u003e convert_to_wav\n    iaModels --\u003e transcribe_audio\n    convert_to_wav --\u003e FileSystem\n    transcribe_audio --\u003e GoogleSpeechAPI\n    transcribir_audio_endpoint --\u003e TempFileManager\n    TempFileManager --\u003e FileSystem\n```\n\n**Sources:** [main.py:1-62](), [requirements.txt:1-6]()\n\n## Service Component Architecture\n\nThe service architecture implements a **single-responsibility microservice** pattern where each layer has distinct responsibilities and well-defined interfaces.\n\n### Component Interaction Model\n\n```mermaid\ngraph LR\n    subgraph \"main.py\"\n        app[\"FastAPI app instance\"]\n        endpoint[\"transcribir_audio_endpoint()\"]\n        uvicorn_run[\"uvicorn.run()\"]\n    end\n    \n    subgraph \"iaModels Package\"\n        transcribir_module[\"transcribir module\"]\n        convert_func[\"convert_to_wav()\"]\n        transcribe_func[\"transcribe_audio()\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        pydub[\"PyDub (Audio Processing)\"]\n        speech_recognition[\"SpeechRecognition (Google API)\"]\n        python_multipart[\"python-multipart (File Upload)\"]\n    end\n    \n    app --\u003e endpoint\n    uvicorn_run --\u003e app\n    endpoint --\u003e transcribir_module\n    transcribir_module --\u003e convert_func\n    transcribir_module --\u003e transcribe_func\n    convert_func --\u003e pydub\n    transcribe_func --\u003e speech_recognition\n    endpoint --\u003e python_multipart\n```\n\n**Sources:** [main.py:13](), [main.py:10](), [main.py:61-62](), [requirements.txt:1-6]()\n\n## Request Processing Architecture\n\nThe system implements a **synchronous request-response pattern** with stateless processing and automatic resource cleanup.\n\n### Request Flow Architecture\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant FastAPI as \"FastAPI app\"\n    participant CORSMiddleware as \"CORSMiddleware\"\n    participant Endpoint as \"transcribir_audio_endpoint\"\n    participant FileManager as \"File Management\"\n    participant iaModels as \"iaModels.transcribir\"\n    participant GoogleAPI as \"Google Speech API\"\n    \n    Client-\u003e\u003eFastAPI: \"POST /transcribir-audio/\"\n    FastAPI-\u003e\u003eCORSMiddleware: \"Origin validation\"\n    CORSMiddleware-\u003e\u003eEndpoint: \"Request forwarded\"\n    Endpoint-\u003e\u003eFileManager: \"os.makedirs('uploads')\"\n    Endpoint-\u003e\u003eFileManager: \"Save UploadFile as UUID.ext\"\n    \n    alt \"File is not WAV\"\n        Endpoint-\u003e\u003eiaModels: \"convert_to_wav(input_path, wav_path)\"\n    end\n    \n    Endpoint-\u003e\u003eiaModels: \"transcribe_audio(wav_path)\"\n    iaModels-\u003e\u003eGoogleAPI: \"Speech recognition request\"\n    GoogleAPI--\u003e\u003eiaModels: \"Transcribed text\"\n    iaModels--\u003e\u003eEndpoint: \"texto\"\n    \n    Endpoint-\u003e\u003eFileManager: \"os.remove(input_path)\"\n    Endpoint-\u003e\u003eFileManager: \"os.remove(wav_path)\"\n    Endpoint--\u003e\u003eClient: '{\"transcripcion\": texto}'\n```\n\n**Sources:** [main.py:27-58](), [main.py:16-25](), [main.py:30](), [main.py:32-38](), [main.py:41-48](), [main.py:51-53]()\n\n## Integration Patterns\n\nThe service uses several integration patterns to manage external dependencies and maintain loose coupling between components.\n\n### Module Loading Pattern\n\nThe system uses dynamic module path manipulation to integrate the `iaModels` package:\n\n| Pattern | Implementation | Location |\n|---------|---------------|----------|\n| **Path Injection** | `sys.path.append()` | [main.py:9]() |\n| **Dynamic Import** | `from transcribir import convert_to_wav, transcribe_audio` | [main.py:10]() |\n| **Lazy Loading** | Functions imported at startup, called on demand | [main.py:43-48]() |\n\n### CORS Integration Pattern\n\nThe service implements cross-origin resource sharing using FastAPI middleware:\n\n```mermaid\ngraph TD\n    Client[\"Client Request\"]\n    CORS[\"CORSMiddleware\"]\n    Origins[\"Allowed Origins\"]\n    \n    subgraph \"Origin Configuration\"\n        localhost[\"localhost:3000\"]\n        vercel[\"solvo-audio-ai.vercel.app\"]\n    end\n    \n    Client --\u003e CORS\n    CORS --\u003e Origins\n    Origins --\u003e localhost\n    Origins --\u003e vercel\n    CORS --\u003e FastAPI[\"FastAPI Application\"]\n```\n\n**Sources:** [main.py:16-25](), [main.py:18-21]()\n\n### External Service Integration\n\nThe architecture abstracts external service dependencies through the `iaModels` layer:\n\n| Service Type | Integration Method | Abstraction Layer |\n|-------------|-------------------|-------------------|\n| **File System** | Direct OS operations | `transcribir_audio_endpoint()` |\n| **Audio Processing** | PyDub via `convert_to_wav()` | `iaModels.transcribir` |\n| **Speech Recognition** | Google API via `transcribe_audio()` | `iaModels.transcribir` |\n\n**Sources:** [main.py:30](), [main.py:43](), [main.py:48](), [requirements.txt:3-4]()\n\n## Deployment Architecture\n\nThe service implements a **cloud-native deployment pattern** with environment-based configuration and port binding flexibility.\n\n### Runtime Configuration Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Environment Configuration\"\n        PORT_ENV[\"os.environ.get('PORT', 10000)\"]\n        HOST_CONFIG[\"host='0.0.0.0'\"]\n    end\n    \n    subgraph \"Application Runtime\"\n        uvicorn_server[\"uvicorn.run()\"]\n        fastapi_app[\"FastAPI app instance\"]\n        uploads_dir[\"uploads/ directory\"]\n    end\n    \n    PORT_ENV --\u003e uvicorn_server\n    HOST_CONFIG --\u003e uvicorn_server\n    uvicorn_server --\u003e fastapi_app\n    fastapi_app --\u003e uploads_dir\n```\n\n**Sources:** [main.py:61-62](), [main.py:30]()\n\n## Error Handling Architecture\n\nThe service implements a **centralized error handling pattern** with HTTP exception translation:\n\n| Error Source | Handling Strategy | Response Format |\n|-------------|------------------|----------------|\n| **File Operations** | `try/except` with `HTTPException` | HTTP 500 with error detail |\n| **Audio Processing** | Exception propagation through `iaModels` | HTTP 500 with error detail |\n| **API Integration** | Google API errors caught by `transcribe_audio()` | HTTP 500 with error detail |\n\n**Sources:** [main.py:57-58](), [main.py:29]()"])</script><script>self.__next_f.push([1,"22:T1b28,"])</script><script>self.__next_f.push([1,"# Development \u0026 Deployment\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [.gitignore](.gitignore)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document provides comprehensive guidance for setting up the development environment and deploying the SOLVO Audio AI Backend service. It covers the complete workflow from initial environment setup through production deployment, including dependency management, configuration requirements, and deployment architecture. For information about the core audio processing functionality, see [Audio Processing Engine](#3). For details about the FastAPI web service implementation, see [FastAPI Web Service](#2).\n\n## Environment Setup\n\n### Development Environment Architecture\n\nThe SOLVO Audio AI Backend follows a standard Python virtual environment pattern with specific requirements for audio processing capabilities.\n\n**Development Environment Structure**\n```mermaid\ngraph TB\n    subgraph \"Development Environment\"\n        VENV[\"venv/\"]\n        UPLOADS[\"uploads/\"]\n        MAIN[\"main.py\"]\n        REQUIREMENTS[\"requirements.txt\"]\n        GITIGNORE[\".gitignore\"]\n        \n        subgraph \"Python Dependencies\"\n            FASTAPI_DEP[\"fastapi\"]\n            UVICORN_DEP[\"uvicorn\"]\n            PYDUB_DEP[\"pydub\"]\n            SPEECH_DEP[\"SpeechRecognition\"]\n            MULTIPART_DEP[\"python-multipart\"]\n        end\n        \n        subgraph \"Excluded Files\"\n            PYCACHE[\"__pycache__/\"]\n            TEMP_AUDIO[\"*.mp3, *.m4a, *.wav\"]\n            LOGS[\"*.log\"]\n        end\n    end\n    \n    REQUIREMENTS --\u003e FASTAPI_DEP\n    REQUIREMENTS --\u003e UVICORN_DEP\n    REQUIREMENTS --\u003e PYDUB_DEP\n    REQUIREMENTS --\u003e SPEECH_DEP\n    REQUIREMENTS --\u003e MULTIPART_DEP\n    \n    GITIGNORE --\u003e VENV\n    GITIGNORE --\u003e UPLOADS\n    GITIGNORE --\u003e PYCACHE\n    GITIGNORE --\u003e TEMP_AUDIO\n    GITIGNORE --\u003e LOGS\n```\n\nSources: [requirements.txt:1-6](), [.gitignore:1-18]()\n\n### Virtual Environment Setup\n\nThe project uses a Python virtual environment to isolate dependencies and ensure consistent development across different machines.\n\n| Component | Purpose | Location |\n|-----------|---------|----------|\n| `venv/` | Python virtual environment directory | Project root |\n| `requirements.txt` | Python package dependencies | Project root |\n| `uploads/` | Temporary audio file storage | Project root |\n\n**Virtual Environment Configuration:**\n- Virtual environment directory is excluded from version control via [.gitignore:2]()\n- All temporary audio files are excluded to prevent repository bloat [.gitignore:4-8]()\n- Python cache files and compiled bytecode are ignored [.gitignore:10-14]()\n\nSources: [.gitignore:1-18]()\n\n### Dependency Management\n\nThe system relies on five core Python packages for its functionality:\n\n**Core Dependencies**\n```mermaid\ngraph TD\n    subgraph \"Web Framework Stack\"\n        FASTAPI_LIB[\"fastapi\"]\n        UVICORN_LIB[\"uvicorn\"]\n        MULTIPART_LIB[\"python-multipart\"]\n    end\n    \n    subgraph \"Audio Processing Stack\"\n        PYDUB_LIB[\"pydub\"]\n        SPEECH_LIB[\"SpeechRecognition\"]\n    end\n    \n    subgraph \"External Services\"\n        GOOGLE_API[\"Google Speech Recognition API\"]\n    end\n    \n    FASTAPI_LIB --\u003e UVICORN_LIB\n    FASTAPI_LIB --\u003e MULTIPART_LIB\n    PYDUB_LIB --\u003e SPEECH_LIB\n    SPEECH_LIB --\u003e GOOGLE_API\n```\n\nSources: [requirements.txt:1-6]()\n\n| Package | Purpose | Version |\n|---------|---------|---------|\n| `fastapi` | Web framework for API endpoints | Latest |\n| `uvicorn` | ASGI server for FastAPI | Latest |\n| `pydub` | Audio file format conversion | Latest |\n| `SpeechRecognition` | Google Speech API integration | Latest |\n| `python-multipart` | File upload handling | Latest |\n\nThe dependency specification in [requirements.txt:1-6]() intentionally omits version pinning, allowing for the latest compatible versions during installation.\n\nSources: [requirements.txt:1-6]()\n\n### Development Workflow\n\n**File Management Strategy:**\n- Source code is tracked in version control\n- Temporary audio files in `uploads/*` are excluded [.gitignore:5]()\n- Individual audio format files are globally excluded [.gitignore:6-8]()\n- Python artifacts are automatically excluded [.gitignore:11-14]()\n\n**Development File Exclusions:**\n- Virtual environment: `venv/` [.gitignore:2]()\n- Upload directory: `uploads/*` [.gitignore:5]()\n- Audio files: `*.mp3`, `*.m4a`, `*.wav` [.gitignore:6-8]()\n- Log files: `*.log` [.gitignore:17]()\n- System files: `.DS_Store` [.gitignore:18]()\n\nSources: [.gitignore:1-18]()\n\n## Deployment Configuration\n\n### Production Environment Variables\n\nThe deployment configuration relies on environment-based settings for port binding and service configuration.\n\n**Deployment Architecture**\n```mermaid\ngraph TB\n    subgraph \"Runtime Configuration\"\n        PORT_VAR[\"PORT environment variable\"]\n        DEFAULT_PORT[\"Default: 10000\"]\n        BIND_ADDRESS[\"0.0.0.0:PORT\"]\n    end\n    \n    subgraph \"FastAPI Application\"\n        MAIN_PY[\"main.py\"]\n        FASTAPI_APP[\"FastAPI() instance\"]\n        CORS_CONFIG[\"CORS origins configuration\"]\n    end\n    \n    subgraph \"Allowed Origins\"\n        LOCAL_ORIGIN[\"localhost:3000\"]\n        PROD_ORIGIN[\"solvo-audio-ai.vercel.app\"]\n    end\n    \n    subgraph \"Service Endpoints\"\n        TRANSCRIBE_ENDPOINT[\"/transcribir-audio/\"]\n        POST_METHOD[\"POST method\"]\n    end\n    \n    PORT_VAR --\u003e DEFAULT_PORT\n    DEFAULT_PORT --\u003e BIND_ADDRESS\n    BIND_ADDRESS --\u003e MAIN_PY\n    MAIN_PY --\u003e FASTAPI_APP\n    FASTAPI_APP --\u003e CORS_CONFIG\n    CORS_CONFIG --\u003e LOCAL_ORIGIN\n    CORS_CONFIG --\u003e PROD_ORIGIN\n    FASTAPI_APP --\u003e TRANSCRIBE_ENDPOINT\n    TRANSCRIBE_ENDPOINT --\u003e POST_METHOD\n```\n\nSources: Based on system architecture overview\n\n### CORS Configuration\n\nThe service is configured for cross-origin requests from specific domains:\n\n| Origin | Environment | Purpose |\n|--------|-------------|---------|\n| `localhost:3000` | Development | Local frontend development |\n| `solvo-audio-ai.vercel.app` | Production | Deployed frontend application |\n\nThis dual-origin configuration supports both local development workflows and production deployment scenarios.\n\n### Production Deployment Model\n\n**Service Binding Configuration:**\n- Default port: `10000`\n- Bind address: `0.0.0.0` (all interfaces)\n- Protocol: HTTP over ASGI (Uvicorn)\n\n**File System Requirements:**\n- Writable `uploads/` directory for temporary file storage\n- Audio format processing capabilities (requires system audio libraries)\n- Network access to Google Speech Recognition API\n\nThe deployment model assumes a containerized or cloud-native environment where:\n1. The service binds to all network interfaces (`0.0.0.0`)\n2. Port configuration is provided via environment variables\n3. Temporary file storage is ephemeral and automatically cleaned\n4. External API access to Google Cloud Speech Recognition is available\n\nSources: Based on system architecture overview and deployment patterns"])</script><script>self.__next_f.push([1,"23:T1bba,"])</script><script>self.__next_f.push([1,"# Environment Setup\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [.gitignore](.gitignore)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document provides instructions for setting up the development environment for the SOLVO Audio AI Backend project. It covers the installation of Python dependencies, virtual environment configuration, and project structure initialization required to run the FastAPI-based audio transcription service locally.\n\nFor information about deployment configuration and production settings, see [Deployment Configuration](#5.2). For details about the system architecture and service components, see [Service Architecture](#4.2).\n\n## Prerequisites\n\nBefore setting up the development environment, ensure you have the following installed on your system:\n\n| Requirement | Version | Purpose |\n|------------|---------|---------|\n| Python | 3.7+ | Runtime environment for the FastAPI application |\n| pip | Latest | Package manager for Python dependencies |\n| System Audio Libraries | OS-dependent | Required for `pydub` audio processing |\n\n### System Audio Library Requirements\n\nThe `pydub` library requires system-level audio processing capabilities:\n\n- **Linux**: Install `ffmpeg` via package manager\n- **macOS**: Install `ffmpeg` via Homebrew\n- **Windows**: Download and install `ffmpeg` binaries\n\nSources: [requirements.txt:3]()\n\n## Virtual Environment Setup\n\n### Creating the Virtual Environment\n\nThe project uses a Python virtual environment to isolate dependencies. Create and activate the virtual environment:\n\n```bash\n# Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\n# On Linux/macOS:\nsource venv/bin/activate\n\n# On Windows:\nvenv\\Scripts\\activate\n```\n\n### Virtual Environment Structure\n\n```mermaid\ngraph TD\n    PROJECT_ROOT[\"Project Root Directory\"]\n    VENV_DIR[\"venv/\"]\n    BIN_DIR[\"venv/bin/\"]\n    LIB_DIR[\"venv/lib/\"]\n    PYTHON_EXE[\"python executable\"]\n    SITE_PACKAGES[\"site-packages/\"]\n    \n    PROJECT_ROOT --\u003e VENV_DIR\n    VENV_DIR --\u003e BIN_DIR\n    VENV_DIR --\u003e LIB_DIR\n    BIN_DIR --\u003e PYTHON_EXE\n    LIB_DIR --\u003e SITE_PACKAGES\n    \n    style VENV_DIR fill:#f9f9f9\n    style SITE_PACKAGES fill:#e8f4f8\n```\n\nSources: [.gitignore:2]()\n\n## Dependency Installation\n\n### Core Dependencies\n\nInstall the required Python packages using the provided requirements file:\n\n```bash\npip install -r requirements.txt\n```\n\n### Dependency Overview\n\n```mermaid\ngraph LR\n    REQUIREMENTS[\"requirements.txt\"]\n    FASTAPI[\"fastapi\"]\n    UVICORN[\"uvicorn\"]\n    PYDUB[\"pydub\"]\n    SPEECH_REC[\"SpeechRecognition\"]\n    MULTIPART[\"python-multipart\"]\n    \n    REQUIREMENTS --\u003e FASTAPI\n    REQUIREMENTS --\u003e UVICORN\n    REQUIREMENTS --\u003e PYDUB\n    REQUIREMENTS --\u003e SPEECH_REC\n    REQUIREMENTS --\u003e MULTIPART\n    \n    FASTAPI --\u003e WEB_FRAMEWORK[\"Web Framework\"]\n    UVICORN --\u003e ASGI_SERVER[\"ASGI Server\"]\n    PYDUB --\u003e AUDIO_PROCESSING[\"Audio Processing\"]\n    SPEECH_REC --\u003e GOOGLE_API[\"Google Speech API\"]\n    MULTIPART --\u003e FILE_UPLOAD[\"File Upload Support\"]\n```\n\n| Package | Purpose | Version |\n|---------|---------|---------|\n| `fastapi` | Web framework for API endpoints | Latest |\n| `uvicorn` | ASGI server for running FastAPI | Latest |\n| `pydub` | Audio file format conversion | Latest |\n| `SpeechRecognition` | Google Speech Recognition integration | Latest |\n| `python-multipart` | Multipart form data handling | Latest |\n\nSources: [requirements.txt:1-5]()\n\n## Project Structure Setup\n\n### Directory Creation\n\nThe application requires specific directories for temporary file storage. These directories are automatically created by the application but can be pre-created:\n\n```bash\n# Create uploads directory for temporary audio files\nmkdir -p uploads\n```\n\n### Excluded Files and Directories\n\nThe following files and directories are excluded from version control:\n\n```mermaid\ngraph TD\n    GITIGNORE[\".gitignore\"]\n    VENV_EXCLUSION[\"venv/\"]\n    UPLOAD_EXCLUSION[\"uploads/*\"]\n    AUDIO_EXCLUSION[\"Audio Files\u003cbr/\u003e*.mp3, *.m4a, *.wav\"]\n    PYTHON_EXCLUSION[\"Python Cache\u003cbr/\u003e__pycache__/, *.pyc\"]\n    TEMP_EXCLUSION[\"Temporary Files\u003cbr/\u003e*.log, .DS_Store\"]\n    \n    GITIGNORE --\u003e VENV_EXCLUSION\n    GITIGNORE --\u003e UPLOAD_EXCLUSION\n    GITIGNORE --\u003e AUDIO_EXCLUSION\n    GITIGNORE --\u003e PYTHON_EXCLUSION\n    GITIGNORE --\u003e TEMP_EXCLUSION\n    \n    style GITIGNORE fill:#f0f0f0\n    style UPLOAD_EXCLUSION fill:#fff3e0\n    style AUDIO_EXCLUSION fill:#e8f5e8\n```\n\nSources: [.gitignore:2,5-8,11-14,17-18]()\n\n## Environment Variables\n\n### Default Configuration\n\nThe application uses the following default environment configuration:\n\n| Variable | Default Value | Purpose |\n|----------|---------------|---------|\n| `PORT` | `10000` | Server binding port |\n| Host | `0.0.0.0` | Server binding address |\n\n### Setting Environment Variables\n\nFor development, you can override the default port:\n\n```bash\n# Set custom port\nexport PORT=8000\n\n# Run with custom port\nuvicorn main:app --host 0.0.0.0 --port $PORT\n```\n\nSources: System overview diagrams\n\n## Development Environment Verification\n\n### Basic Verification Steps\n\n1. **Verify Virtual Environment Activation**:\n   ```bash\n   which python\n   # Should show: ./venv/bin/python (or similar path)\n   ```\n\n2. **Verify Dependencies Installation**:\n   ```bash\n   pip list\n   # Should show all packages from requirements.txt\n   ```\n\n3. **Test Application Startup**:\n   ```bash\n   python main.py\n   # Should start server on port 10000\n   ```\n\n### Verification Flow\n\n```mermaid\ngraph TD\n    START[\"Start Verification\"]\n    CHECK_VENV[\"Check Virtual Environment\"]\n    CHECK_DEPS[\"Verify Dependencies\"]\n    CHECK_DIRS[\"Check Directory Structure\"]\n    START_APP[\"Test Application Startup\"]\n    SUCCESS[\"Environment Ready\"]\n    \n    START --\u003e CHECK_VENV\n    CHECK_VENV --\u003e CHECK_DEPS\n    CHECK_DEPS --\u003e CHECK_DIRS\n    CHECK_DIRS --\u003e START_APP\n    START_APP --\u003e SUCCESS\n    \n    CHECK_VENV -.-\u003e|\"venv not active\"| ACTIVATE[\"Activate venv\"]\n    CHECK_DEPS -.-\u003e|\"Missing packages\"| INSTALL[\"pip install -r requirements.txt\"]\n    CHECK_DIRS -.-\u003e|\"Missing uploads/\"| CREATE[\"mkdir uploads\"]\n    \n    ACTIVATE --\u003e CHECK_DEPS\n    INSTALL --\u003e CHECK_DIRS\n    CREATE --\u003e START_APP\n```\n\n### Expected Output\n\nWhen the environment is correctly set up, running `python main.py` should produce output similar to:\n\n```\nINFO:     Started server process\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:10000\n```\n\nSources: [requirements.txt:1-5](), [.gitignore:2,5]()\n\n## Troubleshooting Common Setup Issues\n\n| Issue | Symptoms | Solution |\n|-------|----------|----------|\n| Missing audio libraries | `pydub` import errors | Install system audio libraries (ffmpeg) |\n| Permission errors | Cannot create uploads directory | Check file system permissions |\n| Port conflicts | Server startup fails | Use different port via environment variable |\n| Virtual environment issues | Wrong Python interpreter | Reactivate virtual environment |\n\nSources: [requirements.txt:3](), [.gitignore:5]()"])</script><script>self.__next_f.push([1,"24:T2180,"])</script><script>self.__next_f.push([1,"# Deployment Configuration\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [main.py](main.py)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\nThis document covers the deployment configuration settings, environment variables, and runtime requirements for the SOLVO Audio AI Backend service. It focuses on the production deployment setup, server configuration, and external service dependencies required to run the audio transcription service.\n\nFor development environment setup instructions, see [Environment Setup](#5.1). For overall system architecture details, see [Service Architecture](#4.2).\n\n## Environment Variables\n\nThe service uses environment-based configuration to support different deployment environments. The primary configuration is handled through environment variables that control server behavior.\n\n### Port Configuration\n\nThe service port is configurable via the `PORT` environment variable with a default fallback value:\n\n| Variable | Default Value | Purpose | Source Location |\n|----------|---------------|---------|-----------------|\n| `PORT` | `10000` | HTTP server listening port | [main.py:61]() |\n\nThe port configuration is implemented using Python's `os.environ.get()` method with type conversion:\n\n```python\nport = int(os.environ.get(\"PORT\", 10000))\n```\n\n**Port Configuration Flow:**\n```mermaid\nflowchart LR\n    ENV_VAR[\"Environment Variable PORT\"] --\u003e OS_ENVIRON[\"os.environ.get()\"]\n    OS_ENVIRON --\u003e DEFAULT_CHECK{\"PORT exists?\"}\n    DEFAULT_CHECK --\u003e|Yes| USER_PORT[\"User-defined port\"]\n    DEFAULT_CHECK --\u003e|No| DEFAULT_PORT[\"Default: 10000\"]\n    USER_PORT --\u003e INT_CONVERT[\"int() conversion\"]\n    DEFAULT_PORT --\u003e INT_CONVERT\n    INT_CONVERT --\u003e UVICORN[\"uvicorn.run(port=port)\"]\n```\n\nSources: [main.py:61-62]()\n\n## Server Configuration\n\nThe FastAPI application is served using Uvicorn ASGI server with specific binding and runtime parameters.\n\n### Uvicorn Server Settings\n\nThe server configuration is defined in the main application entry point:\n\n| Parameter | Value | Purpose |\n|-----------|-------|---------|\n| `host` | `\"0.0.0.0\"` | Bind to all network interfaces |\n| `port` | Environment-based | Configurable listening port |\n| `app` | FastAPI instance | Application object |\n\nThe server startup configuration:\n\n```python\nuvicorn.run(app, host=\"0.0.0.0\", port=port)\n```\n\n**Server Binding Architecture:**\n```mermaid\ngraph TB\n    subgraph \"Network Binding\"\n        HOST[\"host='0.0.0.0'\"] --\u003e ALL_INTERFACES[\"All Network Interfaces\"]\n        PORT_VAR[\"port=int(os.environ.get('PORT', 10000))\"] --\u003e PORT_BINDING[\"Port Binding\"]\n    end\n    \n    subgraph \"Application Instance\"\n        FASTAPI_APP[\"app = FastAPI()\"] --\u003e UVICORN_RUN[\"uvicorn.run()\"]\n    end\n    \n    subgraph \"Entry Point\"\n        MAIN_CHECK[\"if __name__ == '__main__':\"] --\u003e PORT_CONFIG[\"port configuration\"]\n        PORT_CONFIG --\u003e UVICORN_RUN\n    end\n    \n    ALL_INTERFACES --\u003e UVICORN_RUN\n    PORT_BINDING --\u003e UVICORN_RUN\n```\n\nSources: [main.py:60-62]()\n\n## CORS Configuration\n\nCross-Origin Resource Sharing (CORS) is configured to support specific frontend applications in both development and production environments.\n\n### Allowed Origins\n\nThe service explicitly defines allowed origins for cross-origin requests:\n\n| Origin | Environment | Purpose |\n|--------|-------------|---------|\n| `http://localhost:3000` | Development | Local frontend development server |\n| `https://solvo-audio-ai.vercel.app` | Production | Deployed frontend application |\n\n### CORS Middleware Setup\n\nThe CORS configuration is implemented using FastAPI's `CORSMiddleware`:\n\n```python\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"http://localhost:3000\",\n        \"https://solvo-audio-ai.vercel.app\"\n    ],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n```\n\n**CORS Configuration Structure:**\n```mermaid\ngraph TB\n    subgraph \"CORS Middleware Configuration\"\n        CORS_MW[\"CORSMiddleware\"] --\u003e ORIGINS[\"allow_origins list\"]\n        CORS_MW --\u003e CREDENTIALS[\"allow_credentials=True\"]\n        CORS_MW --\u003e METHODS[\"allow_methods=['*']\"]\n        CORS_MW --\u003e HEADERS[\"allow_headers=['*']\"]\n    end\n    \n    subgraph \"Allowed Origins\"\n        ORIGINS --\u003e DEV_ORIGIN[\"'http://localhost:3000'\"]\n        ORIGINS --\u003e PROD_ORIGIN[\"'https://solvo-audio-ai.vercel.app'\"]\n    end\n    \n    subgraph \"FastAPI Application\"\n        FASTAPI_APP[\"app = FastAPI()\"] --\u003e ADD_MIDDLEWARE[\"app.add_middleware()\"]\n        ADD_MIDDLEWARE --\u003e CORS_MW\n    end\n```\n\nSources: [main.py:15-25]()\n\n## Runtime Dependencies\n\nThe service requires specific Python packages for operation, defined in the requirements specification.\n\n### Required Packages\n\n| Package | Purpose | Usage Context |\n|---------|---------|---------------|\n| `fastapi` | Web framework | HTTP API implementation |\n| `uvicorn` | ASGI server | Application server |\n| `pydub` | Audio processing | Format conversion |\n| `SpeechRecognition` | Speech-to-text | Google API integration |\n| `python-multipart` | File uploads | Multipart form handling |\n\n**Dependency Installation Flow:**\n```mermaid\nflowchart LR\n    REQUIREMENTS[\"requirements.txt\"] --\u003e PIP_INSTALL[\"pip install -r requirements.txt\"]\n    PIP_INSTALL --\u003e FASTAPI[\"fastapi\"]\n    PIP_INSTALL --\u003e UVICORN[\"uvicorn\"]\n    PIP_INSTALL --\u003e PYDUB[\"pydub\"]\n    PIP_INSTALL --\u003e SPEECH_REC[\"SpeechRecognition\"]\n    PIP_INSTALL --\u003e MULTIPART[\"python-multipart\"]\n    \n    subgraph \"Application Imports\"\n        FASTAPI --\u003e MAIN_IMPORTS[\"from fastapi import FastAPI, UploadFile, File\"]\n        UVICORN --\u003e UVICORN_IMPORT[\"import uvicorn\"]\n    end\n```\n\nSources: [requirements.txt:1-5](), [main.py:4-6]()\n\n## File System Requirements\n\nThe application requires specific directory structures and file system permissions for temporary file handling.\n\n### Directory Structure\n\nThe service automatically creates required directories during runtime:\n\n| Directory | Purpose | Creation Method |\n|-----------|---------|-----------------|\n| `uploads/` | Temporary file storage | `os.makedirs(\"uploads\", exist_ok=True)` |\n\n### File Handling Configuration\n\nThe temporary file management system:\n\n```python\nos.makedirs(\"uploads\", exist_ok=True)\n```\n\n**File System Operations:**\n```mermaid\nflowchart TD\n    REQUEST[\"File Upload Request\"] --\u003e MAKEDIRS[\"os.makedirs('uploads', exist_ok=True)\"]\n    MAKEDIRS --\u003e UUID_GEN[\"uuid.uuid4().hex\"]\n    UUID_GEN --\u003e FILE_PATH[\"input_path = os.path.join('uploads', unique_name)\"]\n    FILE_PATH --\u003e WRITE_FILE[\"with open(input_path, 'wb')\"]\n    WRITE_FILE --\u003e PROCESS[\"Audio Processing\"]\n    PROCESS --\u003e CLEANUP[\"os.remove(input_path)\"]\n```\n\nSources: [main.py:30](), [main.py:34-35](), [main.py:51-53]()\n\n## Module Path Configuration\n\nThe application configures Python module paths to enable imports from the `iaModels` package.\n\n### Import Path Setup\n\nThe module path configuration ensures access to the audio processing functionality:\n\n```python\nsys.path.append(os.path.join(os.path.dirname(__file__), \"iaModels\"))\nfrom transcribir import convert_to_wav, transcribe_audio\n```\n\n**Module Import Architecture:**\n```mermaid\ngraph TB\n    subgraph \"Module Path Configuration\"\n        SYS_PATH[\"sys.path.append()\"] --\u003e DIRNAME[\"os.path.dirname(__file__)\"]\n        DIRNAME --\u003e JOIN_PATH[\"os.path.join(dirname, 'iaModels')\"]\n        JOIN_PATH --\u003e IMPORT_ENABLED[\"Import path available\"]\n    end\n    \n    subgraph \"Module Imports\"\n        IMPORT_ENABLED --\u003e TRANSCRIBIR_IMPORT[\"from transcribir import\"]\n        TRANSCRIBIR_IMPORT --\u003e CONVERT_FUNC[\"convert_to_wav\"]\n        TRANSCRIBIR_IMPORT --\u003e TRANSCRIBE_FUNC[\"transcribe_audio\"]\n    end\n    \n    subgraph \"Application Usage\"\n        CONVERT_FUNC --\u003e AUDIO_CONVERSION[\"Audio format conversion\"]\n        TRANSCRIBE_FUNC --\u003e SPEECH_RECOGNITION[\"Speech recognition processing\"]\n    end\n```\n\nSources: [main.py:8-10]()\n\n## Production Deployment Considerations\n\nThe configuration supports cloud deployment patterns with environment-based settings and external service integration.\n\n### Deployment Checklist\n\n| Component | Configuration Required | Status Check |\n|-----------|------------------------|--------------|\n| Environment Variables | `PORT` setting | `os.environ.get(\"PORT\", 10000)` |\n| Network Binding | Host `0.0.0.0` | Fixed in code |\n| CORS Origins | Frontend URLs | Hardcoded list |\n| File Permissions | `uploads/` directory | Runtime creation |\n| Dependencies | Python packages | `requirements.txt` |\n\nSources: [main.py:61](), [main.py:62](), [main.py:18-21](), [main.py:30](), [requirements.txt:1-5]()"])</script><script>self.__next_f.push([1,"5:[\"$\",\"$L12\",null,{\"repoName\":\"thealeglynne/SOLVO_audio_AI_back\",\"hasConfig\":false,\"canSteer\":false,\"children\":[\"$\",\"$L13\",null,{\"wiki\":{\"metadata\":{\"repo_name\":\"thealeglynne/SOLVO_audio_AI_back\",\"commit_hash\":\"12cfb168\",\"generated_at\":\"2025-07-26T00:16:37.925013\",\"config\":null,\"config_source\":\"none\"},\"pages\":[{\"page_plan\":{\"id\":\"1\",\"title\":\"Overview\"},\"content\":\"$14\"},{\"page_plan\":{\"id\":\"1.1\",\"title\":\"System Components\"},\"content\":\"$15\"},{\"page_plan\":{\"id\":\"1.2\",\"title\":\"Technology Stack\"},\"content\":\"$16\"},{\"page_plan\":{\"id\":\"2\",\"title\":\"FastAPI Web Service\"},\"content\":\"$17\"},{\"page_plan\":{\"id\":\"2.1\",\"title\":\"Application Structure \u0026 Configuration\"},\"content\":\"$18\"},{\"page_plan\":{\"id\":\"2.2\",\"title\":\"Audio Transcription Endpoint\"},\"content\":\"$19\"},{\"page_plan\":{\"id\":\"2.3\",\"title\":\"File Upload \u0026 Processing Pipeline\"},\"content\":\"$1a\"},{\"page_plan\":{\"id\":\"2.4\",\"title\":\"Error Handling \u0026 Response Format\"},\"content\":\"$1b\"},{\"page_plan\":{\"id\":\"3\",\"title\":\"Audio Processing Engine\"},\"content\":\"$1c\"},{\"page_plan\":{\"id\":\"3.1\",\"title\":\"Audio Format Conversion\"},\"content\":\"$1d\"},{\"page_plan\":{\"id\":\"3.2\",\"title\":\"Speech Recognition Engine\"},\"content\":\"$1e\"},{\"page_plan\":{\"id\":\"4\",\"title\":\"System Architecture \u0026 Dependencies\"},\"content\":\"$1f\"},{\"page_plan\":{\"id\":\"4.1\",\"title\":\"Python Dependencies\"},\"content\":\"$20\"},{\"page_plan\":{\"id\":\"4.2\",\"title\":\"Service Architecture\"},\"content\":\"$21\"},{\"page_plan\":{\"id\":\"5\",\"title\":\"Development \u0026 Deployment\"},\"content\":\"$22\"},{\"page_plan\":{\"id\":\"5.1\",\"title\":\"Environment Setup\"},\"content\":\"$23\"},{\"page_plan\":{\"id\":\"5.2\",\"title\":\"Deployment Configuration\"},\"content\":\"$24\"}]},\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]\n"])</script><script>self.__next_f.push([1,"c:null\n10:[[\"$\",\"title\",\"0\",{\"children\":\"thealeglynne/SOLVO_audio_AI_back | DeepWiki\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"thealeglynne/SOLVO_audio_AI_back | DeepWiki\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://deepwiki.com/thealeglynne/SOLVO_audio_AI_back\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"DeepWiki\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"thealeglynne/SOLVO_audio_AI_back | DeepWiki\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"This document provides an overview of the SOLVO Audio AI Backend, a FastAPI-based microservice designed to transcribe Spanish language audio files to text using Google Speech Recognition. The system a\"}],[\"$\",\"link\",\"10\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/icon.png?66aaf51e0e68c818\",\"type\":\"image/png\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?a4f658907db0ab87\",\"type\":\"image/png\",\"sizes\":\"180x180\"}]]\n"])</script><next-route-announcer style="position: absolute;"><template shadowrootmode="open"><div aria-live="assertive" id="__next-route-announcer__" role="alert" style="position: absolute; border: 0px; height: 1px; margin: -1px; padding: 0px; width: 1px; clip: rect(0px, 0px, 0px, 0px); overflow: hidden; white-space: nowrap; overflow-wrap: normal;">thealeglynne/SOLVO_audio_AI_back | DeepWiki</div></template></next-route-announcer><iframe id="_hjSafeContext_23622411" title="_hjSafeContext" tabindex="-1" aria-hidden="true" src="./thealeglynne_SOLVO_audio_AI_back _ DeepWiki_files/saved_resource.html" style="display: none !important; width: 1px !important; height: 1px !important; opacity: 0 !important; pointer-events: none !important;"></iframe></body></html>